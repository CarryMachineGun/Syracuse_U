{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "close-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Evolutionary\n",
    "using Flux\n",
    "using Flux: onehot, onecold, logitcrossentropy #, throttle, @epochs\n",
    "using MLDatasets\n",
    "using Random\n",
    "using StableRNGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sharp-mainstream",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>70,692 rows × 22 columns (omitted printing of 14 columns)</p><table class=\"data-frame\"><thead><tr><th></th><th>Diabetes_binary</th><th>HighBP</th><th>HighChol</th><th>CholCheck</th><th>BMI</th><th>Smoker</th><th>Stroke</th><th>HeartDiseaseorAttack</th></tr><tr><th></th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th></tr></thead><tbody><tr><th>1</th><td>0.0</td><td>0.0</td><td>1.0</td><td>1.0</td><td>25.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>2</th><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>25.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>3</th><td>0.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>29.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>4</th><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>26.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>5</th><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>29.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>6</th><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>24.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>7</th><td>0.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>36.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>8</th><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>26.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>9</th><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>21.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>10</th><td>0.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>23.0</td><td>1.0</td><td>0.0</td><td>1.0</td></tr><tr><th>11</th><td>0.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>27.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>12</th><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>24.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>13</th><td>0.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>25.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>14</th><td>0.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>30.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>15</th><td>0.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>31.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>16</th><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>24.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>17</th><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>26.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>18</th><td>0.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>26.0</td><td>1.0</td><td>0.0</td><td>1.0</td></tr><tr><th>19</th><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>35.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>20</th><td>0.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>35.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>21</th><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>31.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>22</th><td>0.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>33.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>23</th><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>25.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>24</th><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>21.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>25</th><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>37.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>26</th><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>23.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>27</th><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>22.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>28</th><td>0.0</td><td>0.0</td><td>1.0</td><td>1.0</td><td>29.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>29</th><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>26.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>30</th><td>0.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>32.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccccc}\n",
       "\t& Diabetes\\_binary & HighBP & HighChol & CholCheck & BMI & Smoker & Stroke & HeartDiseaseorAttack & \\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 0.0 & 0.0 & 1.0 & 1.0 & 25.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t2 & 0.0 & 0.0 & 0.0 & 0.0 & 25.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t3 & 0.0 & 1.0 & 1.0 & 1.0 & 29.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t4 & 0.0 & 0.0 & 0.0 & 1.0 & 26.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t5 & 0.0 & 0.0 & 0.0 & 1.0 & 29.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t6 & 0.0 & 0.0 & 0.0 & 0.0 & 24.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t7 & 0.0 & 1.0 & 1.0 & 1.0 & 36.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t8 & 0.0 & 0.0 & 0.0 & 1.0 & 26.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t9 & 0.0 & 0.0 & 0.0 & 1.0 & 21.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t10 & 0.0 & 1.0 & 1.0 & 1.0 & 23.0 & 1.0 & 0.0 & 1.0 & $\\dots$ \\\\\n",
       "\t11 & 0.0 & 1.0 & 1.0 & 1.0 & 27.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t12 & 0.0 & 0.0 & 0.0 & 0.0 & 24.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t13 & 0.0 & 1.0 & 1.0 & 1.0 & 25.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t14 & 0.0 & 1.0 & 1.0 & 1.0 & 30.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t15 & 0.0 & 1.0 & 1.0 & 1.0 & 31.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t16 & 0.0 & 0.0 & 0.0 & 1.0 & 24.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t17 & 0.0 & 0.0 & 0.0 & 1.0 & 26.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t18 & 0.0 & 1.0 & 1.0 & 1.0 & 26.0 & 1.0 & 0.0 & 1.0 & $\\dots$ \\\\\n",
       "\t19 & 0.0 & 0.0 & 0.0 & 1.0 & 35.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t20 & 0.0 & 1.0 & 0.0 & 1.0 & 35.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t21 & 0.0 & 0.0 & 0.0 & 1.0 & 31.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t22 & 0.0 & 1.0 & 1.0 & 1.0 & 33.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t23 & 0.0 & 0.0 & 0.0 & 1.0 & 25.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t24 & 0.0 & 0.0 & 0.0 & 1.0 & 21.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t25 & 0.0 & 0.0 & 0.0 & 1.0 & 37.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t26 & 0.0 & 0.0 & 0.0 & 1.0 & 23.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t27 & 0.0 & 0.0 & 0.0 & 1.0 & 22.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t28 & 0.0 & 0.0 & 1.0 & 1.0 & 29.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t29 & 0.0 & 0.0 & 0.0 & 1.0 & 26.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t30 & 0.0 & 1.0 & 1.0 & 1.0 & 32.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m70692×22 DataFrame\u001b[0m\n",
       "\u001b[1m   Row \u001b[0m│\u001b[1m Diabetes_binary \u001b[0m\u001b[1m HighBP  \u001b[0m\u001b[1m HighChol \u001b[0m\u001b[1m CholCheck \u001b[0m\u001b[1m BMI     \u001b[0m\u001b[1m Smoker  \u001b[0m\u001b[1m Stro\u001b[0m ⋯\n",
       "\u001b[1m       \u001b[0m│\u001b[90m Float64         \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m Float64   \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Floa\u001b[0m ⋯\n",
       "───────┼────────────────────────────────────────────────────────────────────────\n",
       "     1 │             0.0      0.0       1.0        1.0     25.0      1.0       ⋯\n",
       "     2 │             0.0      0.0       0.0        0.0     25.0      1.0\n",
       "     3 │             0.0      1.0       1.0        1.0     29.0      1.0\n",
       "     4 │             0.0      0.0       0.0        1.0     26.0      1.0\n",
       "     5 │             0.0      0.0       0.0        1.0     29.0      1.0       ⋯\n",
       "     6 │             0.0      0.0       0.0        0.0     24.0      0.0\n",
       "     7 │             0.0      1.0       1.0        1.0     36.0      0.0\n",
       "     8 │             0.0      0.0       0.0        1.0     26.0      1.0\n",
       "     9 │             0.0      0.0       0.0        1.0     21.0      0.0       ⋯\n",
       "    10 │             0.0      1.0       1.0        1.0     23.0      1.0\n",
       "    11 │             0.0      1.0       1.0        1.0     27.0      0.0\n",
       "   ⋮   │        ⋮            ⋮        ⋮          ⋮         ⋮        ⋮        ⋮ ⋱\n",
       " 70683 │             1.0      1.0       0.0        1.0     37.0      0.0\n",
       " 70684 │             1.0      1.0       0.0        1.0     28.0      0.0       ⋯\n",
       " 70685 │             1.0      1.0       1.0        1.0     27.0      0.0\n",
       " 70686 │             1.0      1.0       0.0        1.0     38.0      0.0\n",
       " 70687 │             1.0      0.0       1.0        1.0     27.0      0.0\n",
       " 70688 │             1.0      0.0       1.0        1.0     37.0      0.0       ⋯\n",
       " 70689 │             1.0      0.0       1.0        1.0     29.0      1.0\n",
       " 70690 │             1.0      1.0       1.0        1.0     25.0      0.0\n",
       " 70691 │             1.0      1.0       1.0        1.0     18.0      0.0\n",
       " 70692 │             1.0      1.0       1.0        1.0     25.0      0.0       ⋯\n",
       "\u001b[36m                                               16 columns and 70671 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using ZipFile, CSV, DataFrames, Random, StatsBase , Plots, Statistics\n",
    "\n",
    "# read file from zip archive\n",
    "\n",
    "z = ZipFile.Reader(\"results.zip\")\n",
    "\n",
    "# identify the right file in zip\n",
    "\n",
    "# The diabetes dataset I found through kaggle have done split into 2 classifiers and select 50 percents of result from each \n",
    "# label. So i think there is more work in my dataset\n",
    "\n",
    "a_file_in_zip = filter(x->x.name == \"diabetes_binary_5050split_health_indicators_BRFSS2015.csv\", z.files)[1]\n",
    "\n",
    "#avoid changing the original files in the zip file. However, the dataset will not change but whatever.\n",
    "\n",
    "a_copy = CSV.File(a_file_in_zip) |> DataFrame\n",
    "\n",
    "close(z)\n",
    "\n",
    "#show the dataset\n",
    "\n",
    "a_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "central-circle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35346×22 Matrix{Float64}:\n",
       " 1.0  1.0  1.0  1.0  30.0  1.0  0.0  1.0  …  30.0  1.0  0.0   9.0  5.0  1.0\n",
       " 1.0  0.0  0.0  1.0  25.0  1.0  0.0  0.0      0.0  0.0  1.0  13.0  6.0  8.0\n",
       " 1.0  1.0  1.0  1.0  28.0  0.0  0.0  0.0      0.0  1.0  0.0  11.0  4.0  6.0\n",
       " 1.0  0.0  0.0  1.0  23.0  1.0  0.0  0.0      0.0  0.0  1.0   7.0  5.0  6.0\n",
       " 1.0  1.0  0.0  1.0  27.0  0.0  0.0  0.0      0.0  0.0  0.0  13.0  5.0  4.0\n",
       " 1.0  1.0  1.0  1.0  37.0  1.0  1.0  1.0  …   0.0  1.0  1.0  10.0  6.0  5.0\n",
       " 1.0  1.0  1.0  1.0  28.0  1.0  0.0  1.0      0.0  0.0  1.0  12.0  2.0  4.0\n",
       " 1.0  1.0  1.0  1.0  27.0  1.0  0.0  0.0     20.0  1.0  0.0   8.0  4.0  7.0\n",
       " 1.0  1.0  1.0  1.0  34.0  1.0  1.0  0.0      7.0  1.0  0.0   9.0  5.0  4.0\n",
       " 1.0  1.0  1.0  1.0  24.0  1.0  0.0  0.0      0.0  0.0  0.0  12.0  3.0  3.0\n",
       " 1.0  1.0  0.0  1.0  31.0  0.0  0.0  0.0  …   5.0  0.0  0.0  13.0  4.0  4.0\n",
       " 1.0  1.0  1.0  1.0  33.0  1.0  0.0  0.0     30.0  1.0  0.0  11.0  4.0  2.0\n",
       " 1.0  1.0  1.0  1.0  27.0  1.0  0.0  0.0     30.0  1.0  0.0  10.0  4.0  5.0\n",
       " ⋮                         ⋮              ⋱                        ⋮    \n",
       " 1.0  1.0  1.0  1.0  30.0  0.0  0.0  0.0     30.0  1.0  0.0  11.0  2.0  2.0\n",
       " 1.0  0.0  1.0  1.0  19.0  0.0  0.0  0.0  …   2.0  0.0  0.0   7.0  6.0  6.0\n",
       " 1.0  1.0  0.0  1.0  37.0  0.0  0.0  0.0     30.0  1.0  0.0   9.0  2.0  1.0\n",
       " 1.0  1.0  0.0  1.0  28.0  0.0  0.0  0.0      0.0  0.0  0.0  10.0  4.0  3.0\n",
       " 1.0  1.0  1.0  1.0  27.0  0.0  0.0  1.0      5.0  0.0  1.0   9.0  4.0  5.0\n",
       " 1.0  1.0  0.0  1.0  38.0  0.0  0.0  0.0      0.0  0.0  0.0   7.0  6.0  2.0\n",
       " 1.0  0.0  1.0  1.0  27.0  0.0  0.0  0.0  …  30.0  0.0  1.0  11.0  2.0  3.0\n",
       " 1.0  0.0  1.0  1.0  37.0  0.0  0.0  0.0      0.0  0.0  0.0   6.0  4.0  1.0\n",
       " 1.0  0.0  1.0  1.0  29.0  1.0  0.0  1.0      0.0  1.0  1.0  10.0  3.0  6.0\n",
       " 1.0  1.0  1.0  1.0  25.0  0.0  0.0  1.0      0.0  1.0  0.0  13.0  6.0  4.0\n",
       " 1.0  1.0  1.0  1.0  18.0  0.0  0.0  0.0      0.0  1.0  0.0  11.0  2.0  4.0\n",
       " 1.0  1.0  1.0  1.0  25.0  0.0  0.0  1.0  …   0.0  0.0  0.0   9.0  6.0  2.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transfer DataFrame to matrix form\n",
    "\n",
    "df=a_copy|>Tables.matrix\n",
    "\n",
    "# Transfer the dataset to 2-classifiers. df_0 represents the result is 0, df_1 represents the result is 1.\n",
    "# Due to my datasset is binary problems, and each result is 50 percents of the whole dataset. So i didn't add any other pre-actions for dataset. \n",
    "\n",
    "df_0 = df[df[:,1] .== 0, :]\n",
    "df_1 = df[df[:,1] .== 1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fancy-major",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21374×22 Matrix{Float64}:\n",
       " 0.0  0.0  1.0  1.0  25.0  1.0  0.0  0.0  …   2.0  0.0  0.0  11.0  5.0  7.0\n",
       " 0.0  0.0  0.0  0.0  25.0  1.0  0.0  0.0      0.0  0.0  0.0  11.0  6.0  8.0\n",
       " 0.0  0.0  0.0  1.0  26.0  1.0  0.0  0.0      0.0  0.0  1.0   7.0  6.0  8.0\n",
       " 0.0  0.0  0.0  1.0  26.0  1.0  0.0  0.0     15.0  0.0  0.0   7.0  5.0  8.0\n",
       " 0.0  0.0  0.0  1.0  21.0  0.0  0.0  0.0      0.0  0.0  0.0   8.0  5.0  6.0\n",
       " 0.0  0.0  0.0  1.0  24.0  0.0  0.0  0.0  …   0.0  0.0  0.0   6.0  6.0  8.0\n",
       " 0.0  0.0  0.0  1.0  23.0  0.0  0.0  0.0      3.0  0.0  0.0   2.0  5.0  8.0\n",
       " 0.0  0.0  0.0  1.0  22.0  0.0  0.0  0.0     14.0  0.0  0.0   5.0  6.0  8.0\n",
       " 0.0  0.0  0.0  1.0  25.0  0.0  0.0  0.0      3.0  0.0  1.0   4.0  6.0  8.0\n",
       " 0.0  0.0  0.0  1.0  26.0  1.0  0.0  0.0      0.0  0.0  0.0   5.0  6.0  8.0\n",
       " 0.0  1.0  1.0  1.0  36.0  1.0  0.0  0.0  …   5.0  0.0  0.0   8.0  6.0  8.0\n",
       " 0.0  0.0  1.0  1.0  30.0  1.0  0.0  0.0      0.0  0.0  1.0   3.0  4.0  3.0\n",
       " 0.0  0.0  0.0  1.0  23.0  0.0  0.0  0.0      3.0  0.0  1.0   6.0  6.0  8.0\n",
       " ⋮                         ⋮              ⋱                        ⋮    \n",
       " 1.0  1.0  1.0  1.0  24.0  0.0  0.0  0.0      3.0  0.0  1.0  11.0  4.0  5.0\n",
       " 1.0  1.0  1.0  1.0  26.0  0.0  0.0  0.0     30.0  0.0  0.0  11.0  2.0  2.0\n",
       " 1.0  1.0  0.0  1.0  30.0  0.0  0.0  0.0      0.0  0.0  0.0  11.0  4.0  3.0\n",
       " 1.0  1.0  0.0  1.0  27.0  1.0  0.0  0.0  …   0.0  0.0  1.0   8.0  4.0  6.0\n",
       " 1.0  1.0  1.0  1.0  32.0  0.0  0.0  0.0     30.0  1.0  0.0   9.0  4.0  2.0\n",
       " 1.0  1.0  1.0  1.0  25.0  0.0  0.0  0.0      0.0  0.0  0.0  13.0  5.0  3.0\n",
       " 1.0  1.0  1.0  1.0  36.0  1.0  0.0  0.0      0.0  0.0  1.0   6.0  4.0  1.0\n",
       " 1.0  0.0  0.0  1.0  39.0  0.0  0.0  0.0      0.0  0.0  0.0   4.0  5.0  4.0\n",
       " 1.0  1.0  1.0  1.0  32.0  1.0  1.0  1.0  …  30.0  1.0  1.0   7.0  5.0  2.0\n",
       " 1.0  1.0  0.0  1.0  32.0  0.0  1.0  0.0      0.0  0.0  1.0   9.0  6.0  8.0\n",
       " 1.0  1.0  0.0  1.0  30.0  0.0  0.0  0.0      1.0  0.0  0.0   8.0  6.0  2.0\n",
       " 1.0  1.0  0.0  1.0  24.0  0.0  0.0  1.0     30.0  1.0  1.0  12.0  4.0  4.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The columns of matrix is 35346(here just using 35000 is the same), using random sub-sequence to select 70 percents of \n",
    "# columns as the train data.\n",
    "\n",
    "sample = randsubseq(1:35000, 0.7)\n",
    "train_df = vcat(df_0[sample, :], df_1[sample, :])\n",
    "\n",
    "# Then from the not selected columns (which is 30 percents) to select the test data.\n",
    "\n",
    "notsample = [i for i in 1:35000 if isempty(searchsorted(sample, i))]\n",
    "test_df = vcat(df_0[notsample, :], df_1[notsample, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "obvious-springer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21374-element Vector{Float64}:\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " ⋮\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Divide the columns into features and result. From my dataset, From 2 to 22 columns are the attributes of whether diabetes or not.\n",
    "\n",
    "X_train = train_df[:, 2:22]\n",
    "X_test = test_df[:, 2:22]\n",
    "\n",
    "y_train = train_df[:, 1]\n",
    "y_test = test_df[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aerial-briefs",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.872736083714709 -1.1457982012316115 … 0.872736083714709 0.872736083714709; 0.9479550747216559 -1.0548806178012746 … 0.9479550747216559 -1.0548806178012746; … ; 0.07995124657570614 -0.8902781809237422 … -0.8902781809237422 -1.8605076084231906; 1.0624065850073117 -0.775574099782753 … -2.154059613375302 -0.775574099782753], [-1.1457982012316115 -1.1457982012316115 … 0.872736083714709 0.872736083714709; 0.9479550747216559 -1.0548806178012746 … -1.0548806178012746 -1.0548806178012746; … ; 0.07995124657570614 1.0501806740751545 … 1.0501806740751545 -0.8902781809237422; 0.6029114138097955 1.0624065850073117 … -1.6945644421777855 -0.775574099782753])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Distributions\n",
    "\n",
    "# Transfer the X_train to 1 diminension.\n",
    "\n",
    "dt = fit(ZScoreTransform, X_train, dims=1)\n",
    "\n",
    "# Using StateBase package to transfer X_train and X_test(make them standard) to the same formate as dt.\n",
    "\n",
    "X_train_std = StatsBase.transform(dt, X_train)\n",
    "X_test_std = StatsBase.transform(dt, X_test)\n",
    "\n",
    "# Transpose the X_train_std and X_test_std.\n",
    "    \n",
    "X_train_std, X_test_std= transpose(X_train_std), transpose(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "satisfied-diving",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Dense(21, 8, σ),                      \u001b[90m# 176 parameters\u001b[39m\n",
       "  Dense(8, 1, σ),                       \u001b[90m# 9 parameters\u001b[39m\n",
       ")\u001b[90m                   # Total: 4 arrays, \u001b[39m185 parameters, 996 bytes."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model=Chain(Dense(21, 8, sigmoid), Dense(8, 1, sigmoid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dangerous-boost",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss(X_test_std, y_test) = 0.7028674071437077\n",
      "loss(X_test_std, y_test) = 0.7016774070577106\n",
      "loss(X_test_std, y_test) = 0.7005117403857953\n",
      "loss(X_test_std, y_test) = 0.6993717676088848\n",
      "loss(X_test_std, y_test) = 0.6982585552278701\n",
      "loss(X_test_std, y_test) = 0.6971728214912756\n",
      "loss(X_test_std, y_test) = 0.6961148939996938\n",
      "loss(X_test_std, y_test) = 0.6950846979836849\n",
      "loss(X_test_std, y_test) = 0.6940817788908947\n",
      "loss(X_test_std, y_test) = 0.6931053223916169\n",
      "loss(X_test_std, y_test) = 0.692154199918912\n",
      "loss(X_test_std, y_test) = 0.6912270344973549\n",
      "loss(X_test_std, y_test) = 0.6903222827119988\n",
      "loss(X_test_std, y_test) = 0.6894383365140333\n",
      "loss(X_test_std, y_test) = 0.6885736049900791\n",
      "loss(X_test_std, y_test) = 0.6877265927825519\n",
      "loss(X_test_std, y_test) = 0.6868959476381901\n",
      "loss(X_test_std, y_test) = 0.6860804900613215\n",
      "loss(X_test_std, y_test) = 0.6852792240958887\n",
      "loss(X_test_std, y_test) = 0.6844913221187204\n",
      "loss(X_test_std, y_test) = 0.6837161138319667\n",
      "loss(X_test_std, y_test) = 0.6829530598249542\n",
      "loss(X_test_std, y_test) = 0.6822017253465756\n",
      "loss(X_test_std, y_test) = 0.681461759197721\n",
      "loss(X_test_std, y_test) = 0.6807328730214458\n",
      "loss(X_test_std, y_test) = 0.6800148268840793\n",
      "loss(X_test_std, y_test) = 0.6793074215140951\n",
      "loss(X_test_std, y_test) = 0.6786104824231295\n",
      "loss(X_test_std, y_test) = 0.6779238596841084\n",
      "loss(X_test_std, y_test) = 0.6772474156696798\n",
      "loss(X_test_std, y_test) = 0.6765810266588894\n",
      "loss(X_test_std, y_test) = 0.675924577258917\n",
      "loss(X_test_std, y_test) = 0.6752779585900275\n",
      "loss(X_test_std, y_test) = 0.6746410657709385\n",
      "loss(X_test_std, y_test) = 0.674013797673617\n",
      "loss(X_test_std, y_test) = 0.673396054843957\n",
      "loss(X_test_std, y_test) = 0.672787739253641\n",
      "loss(X_test_std, y_test) = 0.6721887522872908\n",
      "loss(X_test_std, y_test) = 0.6715989969755003\n",
      "loss(X_test_std, y_test) = 0.671018374735815\n",
      "loss(X_test_std, y_test) = 0.6704467893516288\n",
      "loss(X_test_std, y_test) = 0.6698841398820445\n",
      "loss(X_test_std, y_test) = 0.669330327967211\n",
      "loss(X_test_std, y_test) = 0.6687852535363367\n",
      "loss(X_test_std, y_test) = 0.6682488146715263\n",
      "loss(X_test_std, y_test) = 0.6677209100962604\n",
      "loss(X_test_std, y_test) = 0.6672014373833328\n",
      "loss(X_test_std, y_test) = 0.6666902916821986\n",
      "loss(X_test_std, y_test) = 0.6661873699848193\n",
      "loss(X_test_std, y_test) = 0.6656925646395045\n",
      "loss(X_test_std, y_test) = 0.6652057705864357\n",
      "loss(X_test_std, y_test) = 0.6647268806601903\n",
      "loss(X_test_std, y_test) = 0.6642557860672261\n",
      "loss(X_test_std, y_test) = 0.663792379563513\n",
      "loss(X_test_std, y_test) = 0.6633365511416579\n",
      "loss(X_test_std, y_test) = 0.6628881907698375\n",
      "loss(X_test_std, y_test) = 0.662447188033584\n",
      "loss(X_test_std, y_test) = 0.6620134311532766\n",
      "loss(X_test_std, y_test) = 0.6615868106704924\n",
      "loss(X_test_std, y_test) = 0.6611672134094969\n",
      "loss(X_test_std, y_test) = 0.6607545285948885\n",
      "loss(X_test_std, y_test) = 0.6603486424033341\n",
      "loss(X_test_std, y_test) = 0.659949443329063\n",
      "loss(X_test_std, y_test) = 0.6595568179767339\n",
      "loss(X_test_std, y_test) = 0.6591706531822872\n",
      "loss(X_test_std, y_test) = 0.6587908379153319\n",
      "loss(X_test_std, y_test) = 0.6584172570473326\n",
      "loss(X_test_std, y_test) = 0.658049800266991\n",
      "loss(X_test_std, y_test) = 0.6576883556607535\n",
      "loss(X_test_std, y_test) = 0.6573328112510413\n",
      "loss(X_test_std, y_test) = 0.6569830575599156\n",
      "loss(X_test_std, y_test) = 0.6566389847942415\n",
      "loss(X_test_std, y_test) = 0.6563004848779509\n",
      "loss(X_test_std, y_test) = 0.6559674502868998\n",
      "loss(X_test_std, y_test) = 0.6556397723256701\n",
      "loss(X_test_std, y_test) = 0.6553173493246334\n",
      "loss(X_test_std, y_test) = 0.6550000766216154\n",
      "loss(X_test_std, y_test) = 0.6546878516284924\n",
      "loss(X_test_std, y_test) = 0.6543805745315507\n",
      "loss(X_test_std, y_test) = 0.6540781469128008\n",
      "loss(X_test_std, y_test) = 0.6537804689664871\n",
      "loss(X_test_std, y_test) = 0.6534874461144786\n",
      "loss(X_test_std, y_test) = 0.6531989835544367\n",
      "loss(X_test_std, y_test) = 0.6529149900385677\n",
      "loss(X_test_std, y_test) = 0.6526353744637076\n",
      "loss(X_test_std, y_test) = 0.6523600462894962\n",
      "loss(X_test_std, y_test) = 0.6520889206913303\n",
      "loss(X_test_std, y_test) = 0.6518219105853194\n",
      "loss(X_test_std, y_test) = 0.6515589338676059\n",
      "loss(X_test_std, y_test) = 0.6512999075889175\n",
      "loss(X_test_std, y_test) = 0.6510447513151466\n",
      "loss(X_test_std, y_test) = 0.6507933879700086\n",
      "loss(X_test_std, y_test) = 0.6505457404791805\n",
      "loss(X_test_std, y_test) = 0.6503017336247902\n",
      "loss(X_test_std, y_test) = 0.6500612944628414\n",
      "loss(X_test_std, y_test) = 0.6498243515082541\n",
      "loss(X_test_std, y_test) = 0.6495908346266861\n",
      "loss(X_test_std, y_test) = 0.6493606756449856\n",
      "loss(X_test_std, y_test) = 0.6491338075495429\n",
      "loss(X_test_std, y_test) = 0.6489101661009418\n",
      "loss(X_test_std, y_test) = 0.6486896880187168\n",
      "loss(X_test_std, y_test) = 0.648472309718454\n",
      "loss(X_test_std, y_test) = 0.6482579710618986\n",
      "loss(X_test_std, y_test) = 0.6480466136167315\n",
      "loss(X_test_std, y_test) = 0.6478381796981412\n",
      "loss(X_test_std, y_test) = 0.6476326120431456\n",
      "loss(X_test_std, y_test) = 0.6474298559924578\n",
      "loss(X_test_std, y_test) = 0.6472298583080979\n",
      "loss(X_test_std, y_test) = 0.6470325660638294\n",
      "loss(X_test_std, y_test) = 0.6468379289932792\n",
      "loss(X_test_std, y_test) = 0.6466458968110099\n",
      "loss(X_test_std, y_test) = 0.6464564198851013\n",
      "loss(X_test_std, y_test) = 0.6462694507786959\n",
      "loss(X_test_std, y_test) = 0.6460849442464709\n",
      "loss(X_test_std, y_test) = 0.6459028543039029\n",
      "loss(X_test_std, y_test) = 0.6457231367953554\n",
      "loss(X_test_std, y_test) = 0.6455457489616833\n",
      "loss(X_test_std, y_test) = 0.6453706476360619\n",
      "loss(X_test_std, y_test) = 0.6451977928636291\n",
      "loss(X_test_std, y_test) = 0.6450271432962993\n",
      "loss(X_test_std, y_test) = 0.6448586603099756\n",
      "loss(X_test_std, y_test) = 0.644692305263483\n",
      "loss(X_test_std, y_test) = 0.6445280416688626\n",
      "loss(X_test_std, y_test) = 0.6443658313229835\n",
      "loss(X_test_std, y_test) = 0.6442056391694466\n",
      "loss(X_test_std, y_test) = 0.6440474306555076\n",
      "loss(X_test_std, y_test) = 0.6438911713579254\n",
      "loss(X_test_std, y_test) = 0.6437368285107126\n",
      "loss(X_test_std, y_test) = 0.6435843685010507\n",
      "loss(X_test_std, y_test) = 0.643433759846851\n",
      "loss(X_test_std, y_test) = 0.6432849713399562\n",
      "loss(X_test_std, y_test) = 0.6431379724477176\n",
      "loss(X_test_std, y_test) = 0.6429927345285162\n",
      "loss(X_test_std, y_test) = 0.6428492274226615\n",
      "loss(X_test_std, y_test) = 0.642707422826114\n",
      "loss(X_test_std, y_test) = 0.6425672934973939\n",
      "loss(X_test_std, y_test) = 0.6424288109650845\n",
      "loss(X_test_std, y_test) = 0.6422919490410226\n",
      "loss(X_test_std, y_test) = 0.6421566819248254\n",
      "loss(X_test_std, y_test) = 0.6420229828416706\n",
      "loss(X_test_std, y_test) = 0.6418908287354874\n",
      "loss(X_test_std, y_test) = 0.6417601941282116\n",
      "loss(X_test_std, y_test) = 0.6416310566928177\n",
      "loss(X_test_std, y_test) = 0.641503391005667\n",
      "loss(X_test_std, y_test) = 0.6413771751647527\n",
      "loss(X_test_std, y_test) = 0.6412523862300084\n",
      "loss(X_test_std, y_test) = 0.6411290022716858\n",
      "loss(X_test_std, y_test) = 0.6410070009228533\n",
      "loss(X_test_std, y_test) = 0.6408863622234138\n",
      "loss(X_test_std, y_test) = 0.6407670660440228\n",
      "loss(X_test_std, y_test) = 0.6406490904816767\n",
      "loss(X_test_std, y_test) = 0.6405324167711847\n",
      "loss(X_test_std, y_test) = 0.6404170246927776\n",
      "loss(X_test_std, y_test) = 0.6403028953438845\n",
      "loss(X_test_std, y_test) = 0.6401900106477024\n",
      "loss(X_test_std, y_test) = 0.6400783509817222\n",
      "loss(X_test_std, y_test) = 0.6399678993208289\n",
      "loss(X_test_std, y_test) = 0.6398586376807084\n",
      "loss(X_test_std, y_test) = 0.6397505487614409\n",
      "loss(X_test_std, y_test) = 0.6396436157333343\n",
      "loss(X_test_std, y_test) = 0.639537820008878\n",
      "loss(X_test_std, y_test) = 0.6394331474411021\n",
      "loss(X_test_std, y_test) = 0.6393295819296488\n",
      "loss(X_test_std, y_test) = 0.639227107519208\n",
      "loss(X_test_std, y_test) = 0.6391257074365351\n",
      "loss(X_test_std, y_test) = 0.6390253672327241\n",
      "loss(X_test_std, y_test) = 0.6389260717876876\n"
     ]
    }
   ],
   "source": [
    "\n",
    "using Flux: logitbinarycrossentropy\n",
    "using BSON: @save\n",
    "opt = ADAM()\n",
    "loss(x, y) = logitbinarycrossentropy(vec(base_model(x)), y)\n",
    "accuracy(x, y) = mean(vec(base_model(x) .> 0.5) .== y)\n",
    "evalcb1() = @show(loss(X_test_std, y_test))\n",
    "throttled_cb = Flux.throttle(evalcb1, 0.01)\n",
    "for i in 1:500\n",
    "    Flux.train!(loss, Flux.params(base_model), [(X_train_std, y_train)], opt, cb = throttled_cb)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "single-landscape",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: MLP\n",
      "│   loss = 0.639469069343596\n",
      "│   accuracy = 0.7090651092008391\n",
      "└ @ Main In[9]:1\n"
     ]
    }
   ],
   "source": [
    "@info \"MLP\" loss=loss(X_train_std,y_train) accuracy = accuracy(X_train_std,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "amino-uncle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fitness (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitness(m) = loss(X_train_std,y_train,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "gothic-method",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy (generic function with 2 methods)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(x, y,m) = logitbinarycrossentropy(vec(m(x)), y)\n",
    "accuracy(x, y,m) = mean(vec(m(x) .> 0.5) .== y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "micro-farming",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.639469069343596"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitness(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "continental-measurement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "average_mlp (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function average_mlp(m1::T, m2::T; rng::Random.AbstractRNG=Random.default_rng()) where {T <: Chain}\n",
    "    θ1, re1 = Flux.destructure(m1);\n",
    "    θ2, re2 = Flux.destructure(m2);\n",
    "    c1, c2 = AX(θ1,θ2; rng=rng)\n",
    "    return re1(c1), re2(c2)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "funky-parliament",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Chain(Dense(21, 8, σ), Dense(8, 1, σ)), Chain(Dense(21, 8, σ), Dense(8, 1, σ)))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_mlp(base_model, base_model; rng=StableRNG(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "reported-stand",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gaussian_mlp (generic function with 2 methods)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function gaussian_mlp(σ::Real = 1.0)\n",
    "    vop = gaussian(σ)\n",
    "    function mutation(recombinant::T,s::NoStrategy; rng::Random.AbstractRNG=Random.default_rng()) where {T <: Chain}  \n",
    "        θ, re = Flux.destructure(recombinant)\n",
    "        return re(convert(Vector{Float64}, vop(θ; rng=rng)))\n",
    "    end\n",
    "    return mutation\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "banned-measure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Dense(21, 8, σ),                      \u001b[90m# 176 parameters\u001b[39m\n",
       "  Dense(8, 1, σ),                       \u001b[90m# 9 parameters\u001b[39m\n",
       ")\u001b[90m                   # Total: 4 arrays, \u001b[39m185 parameters, 1.695 KiB."
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian_mlp(0.5)(base_model,NoStrategy(); rng=StableRNG(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "civilian-approach",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gaussian_mlp (generic function with 2 methods)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function gaussian_mlp(σ::Real = 1.0)\n",
    "    vop = gaussian(σ)\n",
    "    function mutation(recombinant::T; rng::Random.AbstractRNG=Random.default_rng()) where {T <: Chain}  \n",
    "        θ, re = Flux.destructure(recombinant)\n",
    "        return re(convert(Vector{Float32}, vop(θ; rng=rng)))\n",
    "    end\n",
    "    return mutation\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "spiritual-xerox",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "initial_population (generic function with 8 methods)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Evolutionary.initial_population\n",
    "function initial_population(method::M, individual::Chain;\n",
    "                            rng::Random.AbstractRNG=Random.default_rng(),\n",
    "                            kwargs...) where {M<:Evolutionary.AbstractOptimizer}\n",
    "    θ, re = Flux.destructure(individual);\n",
    "    [re(randn(rng, length(θ))) for i in 1:Evolutionary.population_size(method)]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "understanding-training",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EvolutionaryObjective"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Evolutionary.EvolutionaryObjective\n",
    "function EvolutionaryObjective(f, x::Chain; eval::Symbol = :serial)\n",
    "    fval = f(x)\n",
    "    EvolutionaryObjective{typeof(f),typeof(fval),typeof(x),Val{eval}}(f, fval, deepcopy(x), 0)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "systematic-pacific",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EvolutionaryObjective{typeof(fitness), Float64, Chain{Tuple{Dense{typeof(σ), Matrix{Float32}, Vector{Float32}}, Dense{typeof(σ), Matrix{Float32}, Vector{Float32}}}}, Val{:serial}}(fitness, 0.639469069343596, Chain(Dense(21, 8, σ), Dense(8, 1, σ)), 0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EvolutionaryObjective(fitness, base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "thick-despite",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "copy (generic function with 184 methods)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Base: copy\n",
    "\n",
    "copy(ch::Chain) = deepcopy(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "revolutionary-dryer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                  abstol = Inf\n",
       "                  reltol = Inf\n",
       "        successive_f_tol = 25\n",
       "              iterations = 200\n",
       "             store_trace = false\n",
       "              show_trace = false\n",
       "              show_every = 1\n",
       "                callback = nothing\n",
       "              time_limit = NaN\n",
       "         parallelization = serial\n",
       "                     rng = StableRNGs.LehmerRNG(state=0x00000000000000000000000000000055)\n"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opts = Evolutionary.Options(iterations=200, successive_f_tol=25, rng=StableRNG(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "figured-fruit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1/1+1)-ES"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo = ES(\n",
    "        mutation =  gaussian_mlp(),\n",
    "        recombination = average_mlp,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "victorian-kuwait",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GA[P=20,x=0.9,μ=0.2,ɛ=0.03]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo = GA(\n",
    "        selection = rouletteinv,\n",
    "        mutation =  gaussian_mlp(),\n",
    "        crossover = average_mlp,\n",
    "        mutationRate = 0.2,\n",
    "        crossoverRate = 0.9,\n",
    "        populationSize = 20,\n",
    "        ε = 0.03\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "brown-medium",
   "metadata": {},
   "outputs": [],
   "source": [
    "# algo = ES(\n",
    "#         mutation =  gaussian_mlp(),\n",
    "#         recombination = average_mlp,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "velvet-covering",
   "metadata": {},
   "outputs": [],
   "source": [
    "# θ, re = Flux.destructure(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "civilian-cornell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# θ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "incorporated-privilege",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "exempt-moderator",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: \u001b[0mCannot `convert` an object of type \n\u001b[0m  Chain{Tuple{Dense{typeof(σ){},Array{\u001b[92mFloat32\u001b[39m,2},Array{\u001b[92mFloat32\u001b[39m,1}},Dense{typeof(σ){},Array{\u001b[92mFloat32\u001b[39m,2},Array{\u001b[92mFloat32\u001b[39m,1}}}}\u001b[0m to an object of type \n\u001b[0m  Chain{Tuple{Dense{typeof(σ){},Array{\u001b[91mFloat64\u001b[39m,2},Array{\u001b[91mFloat64\u001b[39m,1}},Dense{typeof(σ){},Array{\u001b[91mFloat64\u001b[39m,2},Array{\u001b[91mFloat64\u001b[39m,1}}}}\n\u001b[0mClosest candidates are:\n\u001b[0m  convert(::Type{T}, \u001b[91m::T\u001b[39m) where T at F:\\Julia-1.7.1\\share\\julia\\base\\essentials.jl:218",
     "output_type": "error",
     "traceback": [
      "MethodError: \u001b[0mCannot `convert` an object of type \n\u001b[0m  Chain{Tuple{Dense{typeof(σ){},Array{\u001b[92mFloat32\u001b[39m,2},Array{\u001b[92mFloat32\u001b[39m,1}},Dense{typeof(σ){},Array{\u001b[92mFloat32\u001b[39m,2},Array{\u001b[92mFloat32\u001b[39m,1}}}}\u001b[0m to an object of type \n\u001b[0m  Chain{Tuple{Dense{typeof(σ){},Array{\u001b[91mFloat64\u001b[39m,2},Array{\u001b[91mFloat64\u001b[39m,1}},Dense{typeof(σ){},Array{\u001b[91mFloat64\u001b[39m,2},Array{\u001b[91mFloat64\u001b[39m,1}}}}\n\u001b[0mClosest candidates are:\n\u001b[0m  convert(::Type{T}, \u001b[91m::T\u001b[39m) where T at F:\\Julia-1.7.1\\share\\julia\\base\\essentials.jl:218",
      "",
      "Stacktrace:",
      "  [1] setindex!(A::Vector{Chain{Tuple{Dense{typeof(σ), Matrix{Float64}, Vector{Float64}}, Dense{typeof(σ), Matrix{Float64}, Vector{Float64}}}}}, x::Chain{Tuple{Dense{typeof(σ), Matrix{Float32}, Vector{Float32}}, Dense{typeof(σ), Matrix{Float32}, Vector{Float32}}}}, i1::Int64)",
      "    @ Base .\\array.jl:903",
      "  [2] update_state!(objfun::EvolutionaryObjective{typeof(fitness), Float64, Chain{Tuple{Dense{typeof(σ), Matrix{Float64}, Vector{Float64}}, Dense{typeof(σ), Matrix{Float64}, Vector{Float64}}}}, Val{:serial}}, constraints::Evolutionary.NoConstraints, state::Evolutionary.ESState{Float64, Chain{Tuple{Dense{typeof(σ), Matrix{Float64}, Vector{Float64}}, Dense{typeof(σ), Matrix{Float64}, Vector{Float64}}}}, AbstractStrategy}, population::Vector{Chain{Tuple{Dense{typeof(σ), Matrix{Float64}, Vector{Float64}}, Dense{typeof(σ), Matrix{Float64}, Vector{Float64}}}}}, method::ES{typeof(average_mlp), typeof(first), var\"#mutation#17\"{var\"#mutation#16#18\"{Evolutionary.var\"#mutation#200\"{Evolutionary.var\"#mutation#199#201\"{Float64}}}}, typeof(Evolutionary.nop)}, options::Evolutionary.Options{Nothing, StableRNGs.LehmerRNG}, itr::Int64)",
      "    @ Evolutionary C:\\Users\\DELL\\.julia\\packages\\Evolutionary\\65hL6\\src\\es.jl:111",
      "  [3] optimize(objfun::EvolutionaryObjective{typeof(fitness), Float64, Chain{Tuple{Dense{typeof(σ), Matrix{Float64}, Vector{Float64}}, Dense{typeof(σ), Matrix{Float64}, Vector{Float64}}}}, Val{:serial}}, constraints::Evolutionary.NoConstraints, method::ES{typeof(average_mlp), typeof(first), var\"#mutation#17\"{var\"#mutation#16#18\"{Evolutionary.var\"#mutation#200\"{Evolutionary.var\"#mutation#199#201\"{Float64}}}}, typeof(Evolutionary.nop)}, population::Vector{Chain{Tuple{Dense{typeof(σ), Matrix{Float64}, Vector{Float64}}, Dense{typeof(σ), Matrix{Float64}, Vector{Float64}}}}}, options::Evolutionary.Options{Nothing, StableRNGs.LehmerRNG}, state::Evolutionary.ESState{Float64, Chain{Tuple{Dense{typeof(σ), Matrix{Float64}, Vector{Float64}}, Dense{typeof(σ), Matrix{Float64}, Vector{Float64}}}}, AbstractStrategy})",
      "    @ Evolutionary C:\\Users\\DELL\\.julia\\packages\\Evolutionary\\65hL6\\src\\api\\optimize.jl:105",
      "  [4] optimize(objfun::EvolutionaryObjective{typeof(fitness), Float64, Chain{Tuple{Dense{typeof(σ), Matrix{Float64}, Vector{Float64}}, Dense{typeof(σ), Matrix{Float64}, Vector{Float64}}}}, Val{:serial}}, constraints::Evolutionary.NoConstraints, method::ES{typeof(average_mlp), typeof(first), var\"#mutation#17\"{var\"#mutation#16#18\"{Evolutionary.var\"#mutation#200\"{Evolutionary.var\"#mutation#199#201\"{Float64}}}}, typeof(Evolutionary.nop)}, population::Vector{Chain{Tuple{Dense{typeof(σ), Matrix{Float64}, Vector{Float64}}, Dense{typeof(σ), Matrix{Float64}, Vector{Float64}}}}}, options::Evolutionary.Options{Nothing, StableRNGs.LehmerRNG})",
      "    @ Evolutionary C:\\Users\\DELL\\.julia\\packages\\Evolutionary\\65hL6\\src\\api\\optimize.jl:70",
      "  [5] optimize(f::typeof(fitness), constraints::Evolutionary.NoConstraints, method::ES{typeof(average_mlp), typeof(first), var\"#mutation#17\"{var\"#mutation#16#18\"{Evolutionary.var\"#mutation#200\"{Evolutionary.var\"#mutation#199#201\"{Float64}}}}, typeof(Evolutionary.nop)}, population::Vector{Chain{Tuple{Dense{typeof(σ), Matrix{Float64}, Vector{Float64}}, Dense{typeof(σ), Matrix{Float64}, Vector{Float64}}}}}, opts::Evolutionary.Options{Nothing, StableRNGs.LehmerRNG})",
      "    @ Evolutionary C:\\Users\\DELL\\.julia\\packages\\Evolutionary\\65hL6\\src\\api\\optimize.jl:55",
      "  [6] optimize(f::typeof(fitness), constraints::Evolutionary.NoConstraints, individual::Chain{Tuple{Dense{typeof(σ), Matrix{Float32}, Vector{Float32}}, Dense{typeof(σ), Matrix{Float32}, Vector{Float32}}}}, method::ES{typeof(average_mlp), typeof(first), var\"#mutation#17\"{var\"#mutation#16#18\"{Evolutionary.var\"#mutation#200\"{Evolutionary.var\"#mutation#199#201\"{Float64}}}}, typeof(Evolutionary.nop)}, opts::Evolutionary.Options{Nothing, StableRNGs.LehmerRNG})",
      "    @ Evolutionary C:\\Users\\DELL\\.julia\\packages\\Evolutionary\\65hL6\\src\\api\\optimize.jl:42",
      "  [7] optimize(f::typeof(fitness), individual::Chain{Tuple{Dense{typeof(σ), Matrix{Float32}, Vector{Float32}}, Dense{typeof(σ), Matrix{Float32}, Vector{Float32}}}}, method::ES{typeof(average_mlp), typeof(first), var\"#mutation#17\"{var\"#mutation#16#18\"{Evolutionary.var\"#mutation#200\"{Evolutionary.var\"#mutation#199#201\"{Float64}}}}, typeof(Evolutionary.nop)}, opts::Evolutionary.Options{Nothing, StableRNGs.LehmerRNG})",
      "    @ Evolutionary C:\\Users\\DELL\\.julia\\packages\\Evolutionary\\65hL6\\src\\api\\optimize.jl:15",
      "  [8] top-level scope",
      "    @ In[41]:1",
      "  [9] eval",
      "    @ .\\boot.jl:373 [inlined]",
      " [10] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "    @ Base .\\loading.jl:1196"
     ]
    }
   ],
   "source": [
    "res = Evolutionary.optimize(fitness, base_model, algo, opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "electrical-sculpture",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: MLP\n",
      "│   loss = 0.6678961122418255\n",
      "│   accuracy = 0.5749393328671903\n",
      "└ @ Main In[30]:2\n"
     ]
    }
   ],
   "source": [
    "evomodel= Evolutionary.minimizer(res)\n",
    "@info \"MLP\" loss=loss(X_train_std,y_train, evomodel) accuracy = accuracy(X_train_std,y_train, evomodel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.1",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
