{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "close-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Evolutionary\n",
    "using Flux\n",
    "using Flux: onehot, onecold, logitcrossentropy #, throttle, @epochs\n",
    "using MLDatasets\n",
    "using Random\n",
    "using StableRNGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "sharp-mainstream",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>70,692 rows × 22 columns (omitted printing of 14 columns)</p><table class=\"data-frame\"><thead><tr><th></th><th>Diabetes_binary</th><th>HighBP</th><th>HighChol</th><th>CholCheck</th><th>BMI</th><th>Smoker</th><th>Stroke</th><th>HeartDiseaseorAttack</th></tr><tr><th></th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th></tr></thead><tbody><tr><th>1</th><td>0.0</td><td>0.0</td><td>1.0</td><td>1.0</td><td>25.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>2</th><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>25.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>3</th><td>0.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>29.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>4</th><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>26.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>5</th><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>29.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>6</th><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>24.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>7</th><td>0.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>36.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>8</th><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>26.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>9</th><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>21.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>10</th><td>0.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>23.0</td><td>1.0</td><td>0.0</td><td>1.0</td></tr><tr><th>11</th><td>0.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>27.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>12</th><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>24.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>13</th><td>0.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>25.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>14</th><td>0.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>30.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>15</th><td>0.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>31.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>16</th><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>24.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>17</th><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>26.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>18</th><td>0.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>26.0</td><td>1.0</td><td>0.0</td><td>1.0</td></tr><tr><th>19</th><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>35.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>20</th><td>0.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>35.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>21</th><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>31.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>22</th><td>0.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>33.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>23</th><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>25.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>24</th><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>21.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>25</th><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>37.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>26</th><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>23.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>27</th><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>22.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>28</th><td>0.0</td><td>0.0</td><td>1.0</td><td>1.0</td><td>29.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>29</th><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>26.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>30</th><td>0.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>32.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccccc}\n",
       "\t& Diabetes\\_binary & HighBP & HighChol & CholCheck & BMI & Smoker & Stroke & HeartDiseaseorAttack & \\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 0.0 & 0.0 & 1.0 & 1.0 & 25.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t2 & 0.0 & 0.0 & 0.0 & 0.0 & 25.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t3 & 0.0 & 1.0 & 1.0 & 1.0 & 29.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t4 & 0.0 & 0.0 & 0.0 & 1.0 & 26.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t5 & 0.0 & 0.0 & 0.0 & 1.0 & 29.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t6 & 0.0 & 0.0 & 0.0 & 0.0 & 24.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t7 & 0.0 & 1.0 & 1.0 & 1.0 & 36.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t8 & 0.0 & 0.0 & 0.0 & 1.0 & 26.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t9 & 0.0 & 0.0 & 0.0 & 1.0 & 21.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t10 & 0.0 & 1.0 & 1.0 & 1.0 & 23.0 & 1.0 & 0.0 & 1.0 & $\\dots$ \\\\\n",
       "\t11 & 0.0 & 1.0 & 1.0 & 1.0 & 27.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t12 & 0.0 & 0.0 & 0.0 & 0.0 & 24.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t13 & 0.0 & 1.0 & 1.0 & 1.0 & 25.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t14 & 0.0 & 1.0 & 1.0 & 1.0 & 30.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t15 & 0.0 & 1.0 & 1.0 & 1.0 & 31.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t16 & 0.0 & 0.0 & 0.0 & 1.0 & 24.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t17 & 0.0 & 0.0 & 0.0 & 1.0 & 26.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t18 & 0.0 & 1.0 & 1.0 & 1.0 & 26.0 & 1.0 & 0.0 & 1.0 & $\\dots$ \\\\\n",
       "\t19 & 0.0 & 0.0 & 0.0 & 1.0 & 35.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t20 & 0.0 & 1.0 & 0.0 & 1.0 & 35.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t21 & 0.0 & 0.0 & 0.0 & 1.0 & 31.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t22 & 0.0 & 1.0 & 1.0 & 1.0 & 33.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t23 & 0.0 & 0.0 & 0.0 & 1.0 & 25.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t24 & 0.0 & 0.0 & 0.0 & 1.0 & 21.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t25 & 0.0 & 0.0 & 0.0 & 1.0 & 37.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t26 & 0.0 & 0.0 & 0.0 & 1.0 & 23.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t27 & 0.0 & 0.0 & 0.0 & 1.0 & 22.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t28 & 0.0 & 0.0 & 1.0 & 1.0 & 29.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t29 & 0.0 & 0.0 & 0.0 & 1.0 & 26.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t30 & 0.0 & 1.0 & 1.0 & 1.0 & 32.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m70692×22 DataFrame\u001b[0m\n",
       "\u001b[1m   Row \u001b[0m│\u001b[1m Diabetes_binary \u001b[0m\u001b[1m HighBP  \u001b[0m\u001b[1m HighChol \u001b[0m\u001b[1m CholCheck \u001b[0m\u001b[1m BMI     \u001b[0m\u001b[1m Smoker  \u001b[0m\u001b[1m Stro\u001b[0m ⋯\n",
       "\u001b[1m       \u001b[0m│\u001b[90m Float64         \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m Float64   \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Floa\u001b[0m ⋯\n",
       "───────┼────────────────────────────────────────────────────────────────────────\n",
       "     1 │             0.0      0.0       1.0        1.0     25.0      1.0       ⋯\n",
       "     2 │             0.0      0.0       0.0        0.0     25.0      1.0\n",
       "     3 │             0.0      1.0       1.0        1.0     29.0      1.0\n",
       "     4 │             0.0      0.0       0.0        1.0     26.0      1.0\n",
       "     5 │             0.0      0.0       0.0        1.0     29.0      1.0       ⋯\n",
       "     6 │             0.0      0.0       0.0        0.0     24.0      0.0\n",
       "     7 │             0.0      1.0       1.0        1.0     36.0      0.0\n",
       "     8 │             0.0      0.0       0.0        1.0     26.0      1.0\n",
       "     9 │             0.0      0.0       0.0        1.0     21.0      0.0       ⋯\n",
       "    10 │             0.0      1.0       1.0        1.0     23.0      1.0\n",
       "    11 │             0.0      1.0       1.0        1.0     27.0      0.0\n",
       "   ⋮   │        ⋮            ⋮        ⋮          ⋮         ⋮        ⋮        ⋮ ⋱\n",
       " 70683 │             1.0      1.0       0.0        1.0     37.0      0.0\n",
       " 70684 │             1.0      1.0       0.0        1.0     28.0      0.0       ⋯\n",
       " 70685 │             1.0      1.0       1.0        1.0     27.0      0.0\n",
       " 70686 │             1.0      1.0       0.0        1.0     38.0      0.0\n",
       " 70687 │             1.0      0.0       1.0        1.0     27.0      0.0\n",
       " 70688 │             1.0      0.0       1.0        1.0     37.0      0.0       ⋯\n",
       " 70689 │             1.0      0.0       1.0        1.0     29.0      1.0\n",
       " 70690 │             1.0      1.0       1.0        1.0     25.0      0.0\n",
       " 70691 │             1.0      1.0       1.0        1.0     18.0      0.0\n",
       " 70692 │             1.0      1.0       1.0        1.0     25.0      0.0       ⋯\n",
       "\u001b[36m                                               16 columns and 70671 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using ZipFile, CSV, DataFrames, Random, StatsBase , Plots, Statistics\n",
    "\n",
    "# read file from zip archive\n",
    "\n",
    "z = ZipFile.Reader(\"results.zip\")\n",
    "\n",
    "# identify the right file in zip\n",
    "\n",
    "# The diabetes dataset I found through kaggle have done split into 2 classifiers and select 50 percents of result from each \n",
    "# label. So i think there is more work in my dataset\n",
    "\n",
    "a_file_in_zip = filter(x->x.name == \"diabetes_binary_5050split_health_indicators_BRFSS2015.csv\", z.files)[1]\n",
    "\n",
    "#avoid changing the original files in the zip file. However, the dataset will not change but whatever.\n",
    "\n",
    "a_copy = CSV.File(a_file_in_zip) |> DataFrame\n",
    "\n",
    "close(z)\n",
    "\n",
    "#show the dataset\n",
    "\n",
    "a_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "central-circle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35346×22 Matrix{Float64}:\n",
       " 1.0  1.0  1.0  1.0  30.0  1.0  0.0  1.0  …  30.0  1.0  0.0   9.0  5.0  1.0\n",
       " 1.0  0.0  0.0  1.0  25.0  1.0  0.0  0.0      0.0  0.0  1.0  13.0  6.0  8.0\n",
       " 1.0  1.0  1.0  1.0  28.0  0.0  0.0  0.0      0.0  1.0  0.0  11.0  4.0  6.0\n",
       " 1.0  0.0  0.0  1.0  23.0  1.0  0.0  0.0      0.0  0.0  1.0   7.0  5.0  6.0\n",
       " 1.0  1.0  0.0  1.0  27.0  0.0  0.0  0.0      0.0  0.0  0.0  13.0  5.0  4.0\n",
       " 1.0  1.0  1.0  1.0  37.0  1.0  1.0  1.0  …   0.0  1.0  1.0  10.0  6.0  5.0\n",
       " 1.0  1.0  1.0  1.0  28.0  1.0  0.0  1.0      0.0  0.0  1.0  12.0  2.0  4.0\n",
       " 1.0  1.0  1.0  1.0  27.0  1.0  0.0  0.0     20.0  1.0  0.0   8.0  4.0  7.0\n",
       " 1.0  1.0  1.0  1.0  34.0  1.0  1.0  0.0      7.0  1.0  0.0   9.0  5.0  4.0\n",
       " 1.0  1.0  1.0  1.0  24.0  1.0  0.0  0.0      0.0  0.0  0.0  12.0  3.0  3.0\n",
       " 1.0  1.0  0.0  1.0  31.0  0.0  0.0  0.0  …   5.0  0.0  0.0  13.0  4.0  4.0\n",
       " 1.0  1.0  1.0  1.0  33.0  1.0  0.0  0.0     30.0  1.0  0.0  11.0  4.0  2.0\n",
       " 1.0  1.0  1.0  1.0  27.0  1.0  0.0  0.0     30.0  1.0  0.0  10.0  4.0  5.0\n",
       " ⋮                         ⋮              ⋱                        ⋮    \n",
       " 1.0  1.0  1.0  1.0  30.0  0.0  0.0  0.0     30.0  1.0  0.0  11.0  2.0  2.0\n",
       " 1.0  0.0  1.0  1.0  19.0  0.0  0.0  0.0  …   2.0  0.0  0.0   7.0  6.0  6.0\n",
       " 1.0  1.0  0.0  1.0  37.0  0.0  0.0  0.0     30.0  1.0  0.0   9.0  2.0  1.0\n",
       " 1.0  1.0  0.0  1.0  28.0  0.0  0.0  0.0      0.0  0.0  0.0  10.0  4.0  3.0\n",
       " 1.0  1.0  1.0  1.0  27.0  0.0  0.0  1.0      5.0  0.0  1.0   9.0  4.0  5.0\n",
       " 1.0  1.0  0.0  1.0  38.0  0.0  0.0  0.0      0.0  0.0  0.0   7.0  6.0  2.0\n",
       " 1.0  0.0  1.0  1.0  27.0  0.0  0.0  0.0  …  30.0  0.0  1.0  11.0  2.0  3.0\n",
       " 1.0  0.0  1.0  1.0  37.0  0.0  0.0  0.0      0.0  0.0  0.0   6.0  4.0  1.0\n",
       " 1.0  0.0  1.0  1.0  29.0  1.0  0.0  1.0      0.0  1.0  1.0  10.0  3.0  6.0\n",
       " 1.0  1.0  1.0  1.0  25.0  0.0  0.0  1.0      0.0  1.0  0.0  13.0  6.0  4.0\n",
       " 1.0  1.0  1.0  1.0  18.0  0.0  0.0  0.0      0.0  1.0  0.0  11.0  2.0  4.0\n",
       " 1.0  1.0  1.0  1.0  25.0  0.0  0.0  1.0  …   0.0  0.0  0.0   9.0  6.0  2.0"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transfer DataFrame to matrix form\n",
    "\n",
    "df=a_copy|>Tables.matrix\n",
    "\n",
    "# Transfer the dataset to 2-classifiers. df_0 represents the result is 0, df_1 represents the result is 1.\n",
    "# Due to my datasset is binary problems, and each result is 50 percents of the whole dataset. So i didn't add any other pre-actions for dataset. \n",
    "\n",
    "df_0 = df[df[:,1] .== 0, :]\n",
    "df_1 = df[df[:,1] .== 1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fancy-major",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20904×22 Matrix{Float64}:\n",
       " 0.0  0.0  1.0  1.0  25.0  1.0  0.0  0.0  …   2.0  0.0  0.0  11.0  5.0  7.0\n",
       " 0.0  1.0  1.0  1.0  29.0  1.0  0.0  0.0      1.0  0.0  1.0  13.0  5.0  8.0\n",
       " 0.0  0.0  0.0  1.0  26.0  1.0  0.0  0.0      0.0  0.0  1.0   7.0  6.0  8.0\n",
       " 0.0  0.0  0.0  1.0  29.0  1.0  0.0  0.0      0.0  0.0  1.0   4.0  4.0  4.0\n",
       " 0.0  0.0  0.0  0.0  24.0  0.0  0.0  0.0      0.0  0.0  1.0   7.0  5.0  8.0\n",
       " 0.0  1.0  1.0  1.0  23.0  1.0  0.0  1.0  …   0.0  0.0  0.0   6.0  4.0  6.0\n",
       " 0.0  1.0  1.0  1.0  26.0  1.0  0.0  1.0     15.0  1.0  1.0   9.0  3.0  3.0\n",
       " 0.0  0.0  0.0  1.0  35.0  0.0  0.0  0.0      0.0  0.0  1.0   7.0  4.0  7.0\n",
       " 0.0  0.0  0.0  1.0  25.0  0.0  0.0  0.0      0.0  0.0  1.0   4.0  6.0  7.0\n",
       " 0.0  0.0  0.0  1.0  37.0  1.0  0.0  0.0      0.0  0.0  0.0   5.0  6.0  6.0\n",
       " 0.0  1.0  1.0  1.0  32.0  0.0  0.0  0.0  …   0.0  0.0  0.0  12.0  6.0  6.0\n",
       " 0.0  0.0  0.0  1.0  21.0  0.0  0.0  0.0      0.0  0.0  0.0  11.0  5.0  7.0\n",
       " 0.0  0.0  0.0  1.0  27.0  0.0  0.0  0.0      1.0  0.0  0.0   6.0  6.0  7.0\n",
       " ⋮                         ⋮              ⋱                        ⋮    \n",
       " 1.0  1.0  0.0  1.0  27.0  1.0  0.0  0.0      0.0  0.0  1.0   8.0  4.0  6.0\n",
       " 1.0  0.0  0.0  1.0  21.0  0.0  0.0  0.0      0.0  0.0  0.0   4.0  5.0  6.0\n",
       " 1.0  1.0  1.0  1.0  25.0  0.0  0.0  0.0      0.0  0.0  0.0  13.0  5.0  3.0\n",
       " 1.0  0.0  0.0  1.0  39.0  0.0  0.0  0.0  …   0.0  0.0  0.0   4.0  5.0  4.0\n",
       " 1.0  1.0  1.0  1.0  32.0  1.0  0.0  1.0     30.0  1.0  1.0  10.0  3.0  2.0\n",
       " 1.0  1.0  1.0  1.0  25.0  0.0  0.0  0.0      0.0  0.0  0.0  12.0  5.0  1.0\n",
       " 1.0  1.0  0.0  1.0  30.0  0.0  0.0  1.0      4.0  0.0  0.0  12.0  5.0  2.0\n",
       " 1.0  1.0  1.0  1.0  30.0  1.0  0.0  1.0     30.0  0.0  1.0   9.0  4.0  1.0\n",
       " 1.0  1.0  1.0  1.0  39.0  1.0  0.0  1.0  …  30.0  1.0  1.0  10.0  4.0  1.0\n",
       " 1.0  1.0  1.0  1.0  27.0  0.0  0.0  0.0     30.0  1.0  0.0  13.0  4.0  2.0\n",
       " 1.0  1.0  0.0  1.0  24.0  0.0  0.0  0.0      0.0  0.0  1.0  12.0  3.0  4.0\n",
       " 1.0  1.0  0.0  1.0  24.0  0.0  0.0  1.0     30.0  1.0  1.0  12.0  4.0  4.0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The columns of matrix is 35346(here just using 35000 is the same), using random sub-sequence to select 70 percents of \n",
    "# columns as the train data.\n",
    "\n",
    "sample = randsubseq(1:35000, 0.7)\n",
    "train_df = vcat(df_0[sample, :], df_1[sample, :])\n",
    "\n",
    "# Then from the not selected columns (which is 30 percents) to select the test data.\n",
    "\n",
    "notsample = [i for i in 1:35000 if isempty(searchsorted(sample, i))]\n",
    "test_df = vcat(df_0[notsample, :], df_1[notsample, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "obvious-springer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20904-element Vector{Float64}:\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " ⋮\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Divide the columns into features and result. From my dataset, From 2 to 22 columns are the attributes of whether diabetes or not.\n",
    "\n",
    "X_train = train_df[:, 2:22]\n",
    "X_test = test_df[:, 2:22]\n",
    "\n",
    "y_train = train_df[:, 1]\n",
    "y_test = test_df[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "aerial-briefs",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([-1.1426282880300016 0.8751574262754788 … 0.8751574262754788 0.8751574262754788; -1.0538665481273457 0.9488674192370888 … -1.0538665481273457 0.9488674192370888; … ; 1.0447922748196394 1.0447922748196394 … 1.0447922748196394 -0.8992356765388476; 1.0524142888489678 1.0524142888489678 … -1.713215096249283 -2.1741533270989915], [-1.1426282880300016 0.8751574262754788 … 0.8751574262754788 0.8751574262754788; 0.9488674192370888 0.9488674192370888 … -1.0538665481273457 -1.0538665481273457; … ; 0.07277829914039594 0.07277829914039594 … -1.871249652218091 -0.8992356765388476; 0.5914760579992593 1.0524142888489678 … -0.791338634549866 -0.791338634549866])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Distributions\n",
    "\n",
    "# Transfer the X_train to 1 diminension.\n",
    "\n",
    "dt = fit(ZScoreTransform, X_train, dims=1)\n",
    "\n",
    "# Using StateBase package to transfer X_train and X_test(make them standard) to the same formate as dt.\n",
    "\n",
    "X_train_std = StatsBase.transform(dt, X_train)\n",
    "X_test_std = StatsBase.transform(dt, X_test)\n",
    "\n",
    "# Transpose the X_train_std and X_test_std.\n",
    "    \n",
    "X_train_std, X_test_std= transpose(X_train_std), transpose(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "satisfied-diving",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Dense(21, 18, σ),                     \u001b[90m# 396 parameters\u001b[39m\n",
       "  Dense(18, 16, σ),                     \u001b[90m# 304 parameters\u001b[39m\n",
       "  Dense(16, 12, σ),                     \u001b[90m# 204 parameters\u001b[39m\n",
       "  Dense(12, 8, σ),                      \u001b[90m# 104 parameters\u001b[39m\n",
       "  Dense(8, 1, σ),                       \u001b[90m# 9 parameters\u001b[39m\n",
       ")\u001b[90m                   # Total: 10 arrays, \u001b[39m1_017 parameters, 4.598 KiB."
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model=Chain(Dense(21, 18, sigmoid),Dense(18, 16, sigmoid),Dense(16, 12, sigmoid),Dense(12, 8, sigmoid), Dense(8, 1, sigmoid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "tribal-franklin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Dense(21, 8, σ),                      \u001b[90m# 176 parameters\u001b[39m\n",
       "  Dense(8, 1, σ),                       \u001b[90m# 9 parameters\u001b[39m\n",
       ")\u001b[90m                   # Total: 4 arrays, \u001b[39m185 parameters, 996 bytes."
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model=Chain(Dense(21,8,sigmoid),Dense(8,1,sigmoid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "mathematical-investing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Any[]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "intimate-timothy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Vector{Any}:\n",
       " Chain(Dense(21, 18, σ), Dense(18, 16, σ), Dense(16, 12, σ), Dense(12, 8, σ), Dense(8, 1, σ))  \u001b[90m# 1_017 parameters\u001b[39m\n",
       " Chain(Dense(21, 18, σ), Dense(18, 16, σ), Dense(16, 12, σ), Dense(12, 8, σ), Dense(8, 1, σ))  \u001b[90m# 1_017 parameters\u001b[39m\n",
       " Chain(Dense(21, 18, σ), Dense(18, 16, σ), Dense(16, 12, σ), Dense(12, 8, σ), Dense(8, 1, σ))  \u001b[90m# 1_017 parameters\u001b[39m\n",
       " Chain(Dense(21, 18, σ), Dense(18, 16, σ), Dense(16, 12, σ), Dense(12, 8, σ), Dense(8, 1, σ))  \u001b[90m# 1_017 parameters\u001b[39m\n",
       " Chain(Dense(21, 18, σ), Dense(18, 16, σ), Dense(16, 12, σ), Dense(12, 8, σ), Dense(8, 1, σ))  \u001b[90m# 1_017 parameters\u001b[39m\n",
       " Chain(Dense(21, 18, σ), Dense(18, 16, σ), Dense(16, 12, σ), Dense(12, 8, σ), Dense(8, 1, σ))  \u001b[90m# 1_017 parameters\u001b[39m\n",
       " Chain(Dense(21, 18, σ), Dense(18, 16, σ), Dense(16, 12, σ), Dense(12, 8, σ), Dense(8, 1, σ))  \u001b[90m# 1_017 parameters\u001b[39m\n",
       " Chain(Dense(21, 18, σ), Dense(18, 16, σ), Dense(16, 12, σ), Dense(12, 8, σ), Dense(8, 1, σ))  \u001b[90m# 1_017 parameters\u001b[39m\n",
       " Chain(Dense(21, 18, σ), Dense(18, 16, σ), Dense(16, 12, σ), Dense(12, 8, σ), Dense(8, 1, σ))  \u001b[90m# 1_017 parameters\u001b[39m\n",
       " Chain(Dense(21, 18, σ), Dense(18, 16, σ), Dense(16, 12, σ), Dense(12, 8, σ), Dense(8, 1, σ))  \u001b[90m# 1_017 parameters\u001b[39m"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "push!(base_list,Chain(Dense(21, 18, sigmoid),Dense(18, 16, sigmoid),Dense(16, 12, sigmoid),Dense(12, 8, sigmoid), Dense(8, 1, sigmoid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "split-completion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Vector{Any}:\n",
       " Chain(Dense(21, 18, σ), Dense(18, 16, σ), Dense(16, 12, σ), Dense(12, 8, σ), Dense(8, 1, σ))  \u001b[90m# 1_017 parameters\u001b[39m\n",
       " Chain(Dense(21, 18, σ), Dense(18, 16, σ), Dense(16, 12, σ), Dense(12, 8, σ), Dense(8, 1, σ))  \u001b[90m# 1_017 parameters\u001b[39m\n",
       " Chain(Dense(21, 18, σ), Dense(18, 16, σ), Dense(16, 12, σ), Dense(12, 8, σ), Dense(8, 1, σ))  \u001b[90m# 1_017 parameters\u001b[39m\n",
       " Chain(Dense(21, 18, σ), Dense(18, 16, σ), Dense(16, 12, σ), Dense(12, 8, σ), Dense(8, 1, σ))  \u001b[90m# 1_017 parameters\u001b[39m\n",
       " Chain(Dense(21, 18, σ), Dense(18, 16, σ), Dense(16, 12, σ), Dense(12, 8, σ), Dense(8, 1, σ))  \u001b[90m# 1_017 parameters\u001b[39m\n",
       " Chain(Dense(21, 18, σ), Dense(18, 16, σ), Dense(16, 12, σ), Dense(12, 8, σ), Dense(8, 1, σ))  \u001b[90m# 1_017 parameters\u001b[39m\n",
       " Chain(Dense(21, 18, σ), Dense(18, 16, σ), Dense(16, 12, σ), Dense(12, 8, σ), Dense(8, 1, σ))  \u001b[90m# 1_017 parameters\u001b[39m\n",
       " Chain(Dense(21, 18, σ), Dense(18, 16, σ), Dense(16, 12, σ), Dense(12, 8, σ), Dense(8, 1, σ))  \u001b[90m# 1_017 parameters\u001b[39m\n",
       " Chain(Dense(21, 18, σ), Dense(18, 16, σ), Dense(16, 12, σ), Dense(12, 8, σ), Dense(8, 1, σ))  \u001b[90m# 1_017 parameters\u001b[39m\n",
       " Chain(Dense(21, 18, σ), Dense(18, 16, σ), Dense(16, 12, σ), Dense(12, 8, σ), Dense(8, 1, σ))  \u001b[90m# 1_017 parameters\u001b[39m"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_model=base_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "billion-split",
   "metadata": {},
   "outputs": [],
   "source": [
    "# θ1, re1 = Flux.destructure(NN_model[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "persistent-subject",
   "metadata": {},
   "outputs": [],
   "source": [
    "# θ2, re2 = Flux.destructure(NN_model[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "popular-boards",
   "metadata": {},
   "outputs": [],
   "source": [
    "# θ1, re1 = Flux.destructure(NN_model[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dangerous-boost",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss(X_test_std, y_test) = 0.6984874991435299\n",
      "loss(X_test_std, y_test) = 0.6981087230960934\n",
      "loss(X_test_std, y_test) = 0.6977535618013228\n",
      "loss(X_test_std, y_test) = 0.6974216191181022\n",
      "loss(X_test_std, y_test) = 0.6971121001177346\n",
      "loss(X_test_std, y_test) = 0.6968239154607643\n",
      "loss(X_test_std, y_test) = 0.6965557500500166\n",
      "loss(X_test_std, y_test) = 0.6963061183671804\n",
      "loss(X_test_std, y_test) = 0.696073431727172\n",
      "loss(X_test_std, y_test) = 0.6958560656656965\n",
      "loss(X_test_std, y_test) = 0.6956524116058496\n",
      "loss(X_test_std, y_test) = 0.695460914391614\n",
      "loss(X_test_std, y_test) = 0.6952800967845637\n",
      "loss(X_test_std, y_test) = 0.6951085684908244\n",
      "loss(X_test_std, y_test) = 0.694945033543677\n",
      "loss(X_test_std, y_test) = 0.6947882828442331\n",
      "loss(X_test_std, y_test) = 0.6946371872722317\n",
      "loss(X_test_std, y_test) = 0.6944906849083251\n",
      "loss(X_test_std, y_test) = 0.6943477661390508\n",
      "loss(X_test_std, y_test) = 0.6942074552390244\n",
      "loss(X_test_std, y_test) = 0.6940687942895151\n",
      "loss(X_test_std, y_test) = 0.6939308357423009\n",
      "loss(X_test_std, y_test) = 0.6937926415640486\n",
      "loss(X_test_std, y_test) = 0.6936532802605314\n",
      "loss(X_test_std, y_test) = 0.693511817399983\n",
      "loss(X_test_std, y_test) = 0.6933673024859005\n",
      "loss(X_test_std, y_test) = 0.6932187543206295\n",
      "loss(X_test_std, y_test) = 0.6930651493091388\n",
      "loss(X_test_std, y_test) = 0.692905411696461\n",
      "loss(X_test_std, y_test) = 0.6927384075625733\n",
      "loss(X_test_std, y_test) = 0.692562939456962\n",
      "loss(X_test_std, y_test) = 0.6923777393317069\n",
      "loss(X_test_std, y_test) = 0.6921814612275904\n",
      "loss(X_test_std, y_test) = 0.6919726698539139\n"
     ]
    }
   ],
   "source": [
    "\n",
    "using Flux: logitbinarycrossentropy\n",
    "opt = ADAM()\n",
    "loss(x, y) = logitbinarycrossentropy(vec(NN_model[1](x)), y)\n",
    "accuracy(x, y) = mean(vec(NN_model[1](x) .> 0.5) .== y)\n",
    "evalcb1() = @show(loss(X_test_std, y_test))\n",
    "throttled_cb = Flux.throttle(evalcb1, 0.01)\n",
    "for i in 1:100\n",
    "    Flux.train!(loss, Flux.params(NN_model[1]), [(X_train_std, y_train)], opt, cb = throttled_cb)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "together-flour",
   "metadata": {},
   "outputs": [],
   "source": [
    "# θ1, re1 = Flux.destructure(NN_model[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "single-landscape",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: MLP\n",
      "│   loss = 0.6919544391912889\n",
      "│   accuracy = 0.5\n",
      "└ @ Main In[78]:2\n"
     ]
    }
   ],
   "source": [
    "# for n in 1:10\n",
    "@info \"MLP\" loss=loss(X_train_std,y_train) accuracy = accuracy(X_train_std,y_train)\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "amino-uncle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fitness (generic function with 1 method)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitness(m) = loss(X_train_std,y_train,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "gothic-method",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy (generic function with 2 methods)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(x, y,m) = logitbinarycrossentropy(vec(m(x)), y)\n",
    "accuracy(x, y,m) = mean(vec(m(x) .> 0.5) .== y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "micro-farming",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7093205488376595"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitness(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "continental-measurement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "average_mlp (generic function with 1 method)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Different from the GA\n",
    "function average_mlp(m1::T, m2::T; rng::Random.AbstractRNG=Random.default_rng()) where {T <: Chain}\n",
    "    θ1, re1 = Flux.destructure(m1);\n",
    "    θ2, re2 = Flux.destructure(m2);\n",
    "#   we should use the average to combine the two offspring rather than mutation.\n",
    "#   There is a method named AX which can help us calculate the average of two models and combine them use average.  \n",
    "    c1, c2 = AX(θ1,θ2; rng=rng)\n",
    "    return re1(c1), re2(c2)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "funky-parliament",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Chain(Dense(21, 18, σ), Dense(18, 16, σ), Dense(16, 12, σ), Dense(12, 8, σ), Dense(8, 1, σ)), Chain(Dense(21, 18, σ), Dense(18, 16, σ), Dense(16, 12, σ), Dense(12, 8, σ), Dense(8, 1, σ)))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_mlp(base_model, base_model; rng=StableRNG(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "reported-stand",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gaussian_mlp (generic function with 2 methods)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Different from the GA\n",
    "function gaussian_mlp(σ::Real = 1.0)\n",
    "    vop = gaussian(σ)\n",
    "    # Add a new parameter, NoStrategy.\n",
    "    # I don't optimize the startegy, so i choose NoStrategy for smutation (represents strategy for mutation)\n",
    "    function mutation(recombinant::T,s::NoStrategy; rng::Random.AbstractRNG=Random.default_rng()) where {T <: Chain}  \n",
    "        θ, re = Flux.destructure(recombinant)\n",
    "        # I change the return data type from Float32 to Float64 to make it \n",
    "        return re(convert(Vector{Float64}, vop(θ; rng=rng)))\n",
    "    end\n",
    "    return mutation\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "banned-measure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Dense(21, 18, σ),                     \u001b[90m# 396 parameters\u001b[39m\n",
       "  Dense(18, 16, σ),                     \u001b[90m# 304 parameters\u001b[39m\n",
       "  Dense(16, 12, σ),                     \u001b[90m# 204 parameters\u001b[39m\n",
       "  Dense(12, 8, σ),                      \u001b[90m# 104 parameters\u001b[39m\n",
       "  Dense(8, 1, σ),                       \u001b[90m# 9 parameters\u001b[39m\n",
       ")\u001b[90m                   # Total: 10 arrays, \u001b[39m1_017 parameters, 8.570 KiB."
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian_mlp(0.5)(base_model,NoStrategy(); rng=StableRNG(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "spiritual-xerox",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "initial_population (generic function with 8 methods)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Evolutionary.initial_population\n",
    "function initial_population(method::M, individual::Chain;\n",
    "                            rng::Random.AbstractRNG=Random.default_rng(),\n",
    "                            kwargs...) where {M<:Evolutionary.AbstractOptimizer}\n",
    "    θ, re = Flux.destructure(individual);\n",
    "    [re(randn(rng, length(θ))) for i in 1:Evolutionary.population_size(method)]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "understanding-training",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EvolutionaryObjective"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Evolutionary.EvolutionaryObjective\n",
    "function EvolutionaryObjective(f, x::Chain; eval::Symbol = :serial)\n",
    "    fval = f(x)\n",
    "    EvolutionaryObjective{typeof(f),typeof(fval),typeof(x),Val{eval}}(f, fval, deepcopy(x), 0)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "systematic-pacific",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EvolutionaryObjective{typeof(fitness), Float64, Chain{NTuple{5, Dense{typeof(σ), Matrix{Float32}, Vector{Float32}}}}, Val{:serial}}(fitness, 0.7093205488376595, Chain(Dense(21, 18, σ), Dense(18, 16, σ), Dense(16, 12, σ), Dense(12, 8, σ), Dense(8, 1, σ)), 0)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EvolutionaryObjective(fitness, base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "thick-despite",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "copy (generic function with 184 methods)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Base: copy\n",
    "\n",
    "copy(ch::Chain) = deepcopy(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "revolutionary-dryer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                  abstol = Inf\n",
       "                  reltol = Inf\n",
       "        successive_f_tol = 25\n",
       "              iterations = 200\n",
       "             store_trace = false\n",
       "              show_trace = false\n",
       "              show_every = 1\n",
       "                callback = nothing\n",
       "              time_limit = NaN\n",
       "         parallelization = serial\n",
       "                     rng = StableRNGs.LehmerRNG(state=0x00000000000000000000000000000055)\n"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opts = Evolutionary.Options(iterations=200, successive_f_tol=25, rng=StableRNG(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "hungarian-digit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1/1+1)-ES"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gaussian_mlp() function has been modified to fit into ES algorithm\n",
    "# acerage_mlp just choose AX function to create the offsprings.\n",
    "# strategy mutation and strategy recombination here i didn't defind, and i choose no strategy to optimize both for mutation and for recombiantions\n",
    "# Basic options set i choose the same as the GA algorithms\n",
    "algo = ES(\n",
    "        mutation =  gaussian_mlp(),\n",
    "        recombination = average_mlp,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "exempt-moderator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " * Status: success\n",
       "\n",
       " * Candidate solution\n",
       "    Minimizer:  Chain(Dense(21, 18, σ), Dense(18, 16, σ), Dense(16, 12, σ), Dense(12, 8, σ), Dense(8, 1, σ))\n",
       "    Minimum:    0.6868996388568545\n",
       "    Iterations: 57\n",
       "\n",
       " * Found with\n",
       "    Algorithm: (1/1+1)-ES\n",
       "\n",
       " * Convergence measures\n",
       "    |f(x) - f(x')| = 0.0 ≤ 1.0e-10\n",
       "\n",
       " * Work counters\n",
       "    Seconds run:   5.133 (vs limit Inf)\n",
       "    Iterations:    57\n",
       "    f(x) calls:    58\n"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = Evolutionary.optimize(fitness, base_list[10], algo, opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "electrical-sculpture",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: MLP\n",
      "│   loss = 0.6868996388568545\n",
      "│   accuracy = 0.5000203682581066\n",
      "└ @ Main In[174]:2\n"
     ]
    }
   ],
   "source": [
    "evomodel= Evolutionary.minimizer(res)\n",
    "@info \"MLP\" loss=loss(X_train_std,y_train, evomodel) accuracy = accuracy(X_train_std,y_train, evomodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "cardiovascular-panel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Any[]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "psychological-equilibrium",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Vector{Any}:\n",
       " Chain(Dense(21, 18, σ), Dense(18, 16, σ), Dense(16, 12, σ), Dense(12, 8, σ), Dense(8, 1, σ))  \u001b[90m# 1_017 parameters\u001b[39m\n",
       " Chain(Dense(21, 18, σ), Dense(18, 16, σ), Dense(16, 12, σ), Dense(12, 8, σ), Dense(8, 1, σ))  \u001b[90m# 1_017 parameters\u001b[39m\n",
       " Chain(Dense(21, 18, σ), Dense(18, 16, σ), Dense(16, 12, σ), Dense(12, 8, σ), Dense(8, 1, σ))  \u001b[90m# 1_017 parameters\u001b[39m\n",
       " Chain(Dense(21, 18, σ), Dense(18, 16, σ), Dense(16, 12, σ), Dense(12, 8, σ), Dense(8, 1, σ))  \u001b[90m# 1_017 parameters\u001b[39m\n",
       " Chain(Dense(21, 18, σ), Dense(18, 16, σ), Dense(16, 12, σ), Dense(12, 8, σ), Dense(8, 1, σ))  \u001b[90m# 1_017 parameters\u001b[39m\n",
       " Chain(Dense(21, 18, σ), Dense(18, 16, σ), Dense(16, 12, σ), Dense(12, 8, σ), Dense(8, 1, σ))  \u001b[90m# 1_017 parameters\u001b[39m\n",
       " Chain(Dense(21, 18, σ), Dense(18, 16, σ), Dense(16, 12, σ), Dense(12, 8, σ), Dense(8, 1, σ))  \u001b[90m# 1_017 parameters\u001b[39m\n",
       " Chain(Dense(21, 18, σ), Dense(18, 16, σ), Dense(16, 12, σ), Dense(12, 8, σ), Dense(8, 1, σ))  \u001b[90m# 1_017 parameters\u001b[39m\n",
       " Chain(Dense(21, 18, σ), Dense(18, 16, σ), Dense(16, 12, σ), Dense(12, 8, σ), Dense(8, 1, σ))  \u001b[90m# 1_017 parameters\u001b[39m\n",
       " Chain(Dense(21, 18, σ), Dense(18, 16, σ), Dense(16, 12, σ), Dense(12, 8, σ), Dense(8, 1, σ))  \u001b[90m# 1_017 parameters\u001b[39m"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "push!(model_list,evomodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "veterinary-formula",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy (generic function with 2 methods)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(x, y, i) = mean(vec(model_list[i](x) .> 0.5) .== y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "champion-february",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=[]\n",
    "for j in 1:10\n",
    "    push!(test,accuracy(X_train_std, y_train,j))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "elementary-calculator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip990\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip990)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip991\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip990)\" d=\"\n",
       "M186.76 1486.45 L2352.76 1486.45 L2352.76 47.2441 L186.76 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip992\">\n",
       "    <rect x=\"186\" y=\"47\" width=\"2167\" height=\"1440\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip992)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  475.105,1486.45 475.105,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip992)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  929.193,1486.45 929.193,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip992)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1383.28,1486.45 1383.28,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip992)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1837.37,1486.45 1837.37,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip992)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2291.45,1486.45 2291.45,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip990)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  186.76,1486.45 2352.76,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip990)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  475.105,1486.45 475.105,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip990)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  929.193,1486.45 929.193,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip990)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1383.28,1486.45 1383.28,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip990)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1837.37,1486.45 1837.37,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip990)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2291.45,1486.45 2291.45,1467.55 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip990)\" d=\"M469.758 1544.91 L486.078 1544.91 L486.078 1548.85 L464.133 1548.85 L464.133 1544.91 Q466.795 1542.16 471.379 1537.53 Q475.985 1532.88 477.166 1531.53 Q479.411 1529.01 480.291 1527.27 Q481.193 1525.51 481.193 1523.82 Q481.193 1521.07 479.249 1519.33 Q477.328 1517.6 474.226 1517.6 Q472.027 1517.6 469.573 1518.36 Q467.143 1519.13 464.365 1520.68 L464.365 1515.95 Q467.189 1514.82 469.643 1514.24 Q472.096 1513.66 474.133 1513.66 Q479.504 1513.66 482.698 1516.35 Q485.892 1519.03 485.892 1523.52 Q485.892 1525.65 485.082 1527.57 Q484.295 1529.47 482.189 1532.07 Q481.61 1532.74 478.508 1535.95 Q475.406 1539.15 469.758 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip990)\" d=\"M932.202 1518.36 L920.396 1536.81 L932.202 1536.81 L932.202 1518.36 M930.975 1514.29 L936.855 1514.29 L936.855 1536.81 L941.785 1536.81 L941.785 1540.7 L936.855 1540.7 L936.855 1548.85 L932.202 1548.85 L932.202 1540.7 L916.6 1540.7 L916.6 1536.19 L930.975 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip990)\" d=\"M1383.68 1529.7 Q1380.54 1529.7 1378.68 1531.86 Q1376.86 1534.01 1376.86 1537.76 Q1376.86 1541.49 1378.68 1543.66 Q1380.54 1545.82 1383.68 1545.82 Q1386.83 1545.82 1388.66 1543.66 Q1390.51 1541.49 1390.51 1537.76 Q1390.51 1534.01 1388.66 1531.86 Q1386.83 1529.7 1383.68 1529.7 M1392.97 1515.05 L1392.97 1519.31 Q1391.21 1518.48 1389.4 1518.04 Q1387.62 1517.6 1385.86 1517.6 Q1381.23 1517.6 1378.78 1520.72 Q1376.35 1523.85 1376 1530.17 Q1377.37 1528.15 1379.43 1527.09 Q1381.49 1526 1383.96 1526 Q1389.17 1526 1392.18 1529.17 Q1395.21 1532.32 1395.21 1537.76 Q1395.21 1543.08 1392.06 1546.3 Q1388.92 1549.52 1383.68 1549.52 Q1377.69 1549.52 1374.52 1544.94 Q1371.35 1540.33 1371.35 1531.6 Q1371.35 1523.41 1375.24 1518.55 Q1379.12 1513.66 1385.68 1513.66 Q1387.43 1513.66 1389.22 1514.01 Q1391.02 1514.36 1392.97 1515.05 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip990)\" d=\"M1837.37 1532.44 Q1834.03 1532.44 1832.11 1534.22 Q1830.21 1536 1830.21 1539.13 Q1830.21 1542.25 1832.11 1544.03 Q1834.03 1545.82 1837.37 1545.82 Q1840.7 1545.82 1842.62 1544.03 Q1844.54 1542.23 1844.54 1539.13 Q1844.54 1536 1842.62 1534.22 Q1840.72 1532.44 1837.37 1532.44 M1832.69 1530.45 Q1829.68 1529.7 1827.99 1527.64 Q1826.33 1525.58 1826.33 1522.62 Q1826.33 1518.48 1829.27 1516.07 Q1832.23 1513.66 1837.37 1513.66 Q1842.53 1513.66 1845.47 1516.07 Q1848.41 1518.48 1848.41 1522.62 Q1848.41 1525.58 1846.72 1527.64 Q1845.05 1529.7 1842.07 1530.45 Q1845.45 1531.23 1847.32 1533.52 Q1849.22 1535.82 1849.22 1539.13 Q1849.22 1544.15 1846.14 1546.83 Q1843.08 1549.52 1837.37 1549.52 Q1831.65 1549.52 1828.57 1546.83 Q1825.52 1544.15 1825.52 1539.13 Q1825.52 1535.82 1827.41 1533.52 Q1829.31 1531.23 1832.69 1530.45 M1830.98 1523.06 Q1830.98 1525.75 1832.64 1527.25 Q1834.33 1528.76 1837.37 1528.76 Q1840.38 1528.76 1842.07 1527.25 Q1843.78 1525.75 1843.78 1523.06 Q1843.78 1520.38 1842.07 1518.87 Q1840.38 1517.37 1837.37 1517.37 Q1834.33 1517.37 1832.64 1518.87 Q1830.98 1520.38 1830.98 1523.06 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip990)\" d=\"M2266.14 1544.91 L2273.78 1544.91 L2273.78 1518.55 L2265.47 1520.21 L2265.47 1515.95 L2273.73 1514.29 L2278.41 1514.29 L2278.41 1544.91 L2286.05 1544.91 L2286.05 1548.85 L2266.14 1548.85 L2266.14 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip990)\" d=\"M2305.49 1517.37 Q2301.88 1517.37 2300.05 1520.93 Q2298.25 1524.47 2298.25 1531.6 Q2298.25 1538.71 2300.05 1542.27 Q2301.88 1545.82 2305.49 1545.82 Q2309.13 1545.82 2310.93 1542.27 Q2312.76 1538.71 2312.76 1531.6 Q2312.76 1524.47 2310.93 1520.93 Q2309.13 1517.37 2305.49 1517.37 M2305.49 1513.66 Q2311.3 1513.66 2314.36 1518.27 Q2317.44 1522.85 2317.44 1531.6 Q2317.44 1540.33 2314.36 1544.94 Q2311.3 1549.52 2305.49 1549.52 Q2299.68 1549.52 2296.6 1544.94 Q2293.55 1540.33 2293.55 1531.6 Q2293.55 1522.85 2296.6 1518.27 Q2299.68 1513.66 2305.49 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip992)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  186.76,1353.32 2352.76,1353.32 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip992)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  186.76,1075.57 2352.76,1075.57 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip992)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  186.76,797.825 2352.76,797.825 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip992)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  186.76,520.077 2352.76,520.077 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip992)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  186.76,242.329 2352.76,242.329 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip990)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  186.76,1486.45 186.76,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip990)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  186.76,1353.32 205.658,1353.32 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip990)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  186.76,1075.57 205.658,1075.57 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip990)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  186.76,797.825 205.658,797.825 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip990)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  186.76,520.077 205.658,520.077 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip990)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  186.76,242.329 205.658,242.329 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip990)\" d=\"M64.6495 1339.12 Q61.0384 1339.12 59.2097 1342.69 Q57.4041 1346.23 57.4041 1353.36 Q57.4041 1360.46 59.2097 1364.03 Q61.0384 1367.57 64.6495 1367.57 Q68.2837 1367.57 70.0892 1364.03 Q71.9179 1360.46 71.9179 1353.36 Q71.9179 1346.23 70.0892 1342.69 Q68.2837 1339.12 64.6495 1339.12 M64.6495 1335.42 Q70.4596 1335.42 73.5152 1340.02 Q76.5938 1344.61 76.5938 1353.36 Q76.5938 1362.08 73.5152 1366.69 Q70.4596 1371.27 64.6495 1371.27 Q58.8393 1371.27 55.7606 1366.69 Q52.7051 1362.08 52.7051 1353.36 Q52.7051 1344.61 55.7606 1340.02 Q58.8393 1335.42 64.6495 1335.42 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip990)\" d=\"M84.8114 1364.72 L89.6956 1364.72 L89.6956 1370.6 L84.8114 1370.6 L84.8114 1364.72 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip990)\" d=\"M99.927 1336.04 L118.283 1336.04 L118.283 1339.98 L104.209 1339.98 L104.209 1348.45 Q105.228 1348.1 106.246 1347.94 Q107.265 1347.75 108.283 1347.75 Q114.07 1347.75 117.45 1350.93 Q120.83 1354.1 120.83 1359.51 Q120.83 1365.09 117.358 1368.19 Q113.885 1371.27 107.566 1371.27 Q105.39 1371.27 103.121 1370.9 Q100.876 1370.53 98.4687 1369.79 L98.4687 1365.09 Q100.552 1366.23 102.774 1366.78 Q104.996 1367.34 107.473 1367.34 Q111.478 1367.34 113.816 1365.23 Q116.154 1363.12 116.154 1359.51 Q116.154 1355.9 113.816 1353.8 Q111.478 1351.69 107.473 1351.69 Q105.598 1351.69 103.723 1352.11 Q101.871 1352.52 99.927 1353.4 L99.927 1336.04 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip990)\" d=\"M130.853 1366.67 L138.492 1366.67 L138.492 1340.3 L130.182 1341.97 L130.182 1337.71 L138.445 1336.04 L143.121 1336.04 L143.121 1366.67 L150.76 1366.67 L150.76 1370.6 L130.853 1370.6 L130.853 1366.67 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip990)\" d=\"M62.9365 1061.37 Q59.3254 1061.37 57.4967 1064.94 Q55.6912 1068.48 55.6912 1075.61 Q55.6912 1082.71 57.4967 1086.28 Q59.3254 1089.82 62.9365 1089.82 Q66.5707 1089.82 68.3763 1086.28 Q70.205 1082.71 70.205 1075.61 Q70.205 1068.48 68.3763 1064.94 Q66.5707 1061.37 62.9365 1061.37 M62.9365 1057.67 Q68.7467 1057.67 71.8022 1062.27 Q74.8809 1066.86 74.8809 1075.61 Q74.8809 1084.33 71.8022 1088.94 Q68.7467 1093.52 62.9365 1093.52 Q57.1264 1093.52 54.0477 1088.94 Q50.9921 1084.33 50.9921 1075.61 Q50.9921 1066.86 54.0477 1062.27 Q57.1264 1057.67 62.9365 1057.67 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip990)\" d=\"M83.0984 1086.97 L87.9827 1086.97 L87.9827 1092.85 L83.0984 1092.85 L83.0984 1086.97 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip990)\" d=\"M98.2141 1058.29 L116.57 1058.29 L116.57 1062.23 L102.496 1062.23 L102.496 1070.7 Q103.515 1070.35 104.534 1070.19 Q105.552 1070.01 106.571 1070.01 Q112.358 1070.01 115.737 1073.18 Q119.117 1076.35 119.117 1081.77 Q119.117 1087.34 115.645 1090.45 Q112.172 1093.52 105.853 1093.52 Q103.677 1093.52 101.409 1093.15 Q99.1632 1092.78 96.7558 1092.04 L96.7558 1087.34 Q98.8391 1088.48 101.061 1089.03 Q103.284 1089.59 105.76 1089.59 Q109.765 1089.59 112.103 1087.48 Q114.441 1085.38 114.441 1081.77 Q114.441 1078.15 112.103 1076.05 Q109.765 1073.94 105.76 1073.94 Q103.885 1073.94 102.01 1074.36 Q100.159 1074.77 98.2141 1075.65 L98.2141 1058.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip990)\" d=\"M141.177 1062.37 L129.371 1080.82 L141.177 1080.82 L141.177 1062.37 M139.95 1058.29 L145.83 1058.29 L145.83 1080.82 L150.76 1080.82 L150.76 1084.71 L145.83 1084.71 L145.83 1092.85 L141.177 1092.85 L141.177 1084.71 L125.575 1084.71 L125.575 1080.19 L139.95 1058.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip990)\" d=\"M64.3254 783.624 Q60.7143 783.624 58.8856 787.189 Q57.0801 790.73 57.0801 797.86 Q57.0801 804.966 58.8856 808.531 Q60.7143 812.073 64.3254 812.073 Q67.9596 812.073 69.7652 808.531 Q71.5939 804.966 71.5939 797.86 Q71.5939 790.73 69.7652 787.189 Q67.9596 783.624 64.3254 783.624 M64.3254 779.92 Q70.1355 779.92 73.1911 784.527 Q76.2698 789.11 76.2698 797.86 Q76.2698 806.587 73.1911 811.193 Q70.1355 815.776 64.3254 815.776 Q58.5152 815.776 55.4365 811.193 Q52.381 806.587 52.381 797.86 Q52.381 789.11 55.4365 784.527 Q58.5152 779.92 64.3254 779.92 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip990)\" d=\"M84.4873 809.225 L89.3715 809.225 L89.3715 815.105 L84.4873 815.105 L84.4873 809.225 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip990)\" d=\"M99.603 780.545 L117.959 780.545 L117.959 784.48 L103.885 784.48 L103.885 792.952 Q104.904 792.605 105.922 792.443 Q106.941 792.258 107.959 792.258 Q113.746 792.258 117.126 795.429 Q120.506 798.601 120.506 804.017 Q120.506 809.596 117.033 812.698 Q113.561 815.776 107.242 815.776 Q105.066 815.776 102.797 815.406 Q100.552 815.036 98.1447 814.295 L98.1447 809.596 Q100.228 810.73 102.45 811.286 Q104.672 811.841 107.149 811.841 Q111.154 811.841 113.492 809.735 Q115.83 807.628 115.83 804.017 Q115.83 800.406 113.492 798.3 Q111.154 796.193 107.149 796.193 Q105.274 796.193 103.399 796.61 Q101.547 797.026 99.603 797.906 L99.603 780.545 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip990)\" d=\"M128.538 780.545 L150.76 780.545 L150.76 782.536 L138.214 815.105 L133.33 815.105 L145.135 784.48 L128.538 784.48 L128.538 780.545 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip990)\" d=\"M63.4226 505.876 Q59.8115 505.876 57.9828 509.44 Q56.1773 512.982 56.1773 520.112 Q56.1773 527.218 57.9828 530.783 Q59.8115 534.324 63.4226 534.324 Q67.0569 534.324 68.8624 530.783 Q70.6911 527.218 70.6911 520.112 Q70.6911 512.982 68.8624 509.44 Q67.0569 505.876 63.4226 505.876 M63.4226 502.172 Q69.2328 502.172 72.2883 506.778 Q75.367 511.362 75.367 520.112 Q75.367 528.838 72.2883 533.445 Q69.2328 538.028 63.4226 538.028 Q57.6125 538.028 54.5338 533.445 Q51.4782 528.838 51.4782 520.112 Q51.4782 511.362 54.5338 506.778 Q57.6125 502.172 63.4226 502.172 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip990)\" d=\"M83.5845 531.477 L88.4688 531.477 L88.4688 537.357 L83.5845 537.357 L83.5845 531.477 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip990)\" d=\"M109.233 518.213 Q106.084 518.213 104.233 520.366 Q102.404 522.519 102.404 526.269 Q102.404 529.996 104.233 532.172 Q106.084 534.324 109.233 534.324 Q112.381 534.324 114.209 532.172 Q116.061 529.996 116.061 526.269 Q116.061 522.519 114.209 520.366 Q112.381 518.213 109.233 518.213 M118.515 503.561 L118.515 507.82 Q116.756 506.987 114.95 506.547 Q113.168 506.107 111.408 506.107 Q106.779 506.107 104.325 509.232 Q101.895 512.357 101.547 518.676 Q102.913 516.663 104.973 515.598 Q107.033 514.51 109.51 514.51 Q114.719 514.51 117.728 517.681 Q120.76 520.829 120.76 526.269 Q120.76 531.593 117.612 534.811 Q114.464 538.028 109.233 538.028 Q103.237 538.028 100.066 533.445 Q96.8947 528.838 96.8947 520.112 Q96.8947 511.917 100.784 507.056 Q104.672 502.172 111.223 502.172 Q112.983 502.172 114.765 502.519 Q116.57 502.866 118.515 503.561 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip990)\" d=\"M138.816 505.876 Q135.205 505.876 133.376 509.44 Q131.57 512.982 131.57 520.112 Q131.57 527.218 133.376 530.783 Q135.205 534.324 138.816 534.324 Q142.45 534.324 144.256 530.783 Q146.084 527.218 146.084 520.112 Q146.084 512.982 144.256 509.44 Q142.45 505.876 138.816 505.876 M138.816 502.172 Q144.626 502.172 147.681 506.778 Q150.76 511.362 150.76 520.112 Q150.76 528.838 147.681 533.445 Q144.626 538.028 138.816 538.028 Q133.006 538.028 129.927 533.445 Q126.871 528.838 126.871 520.112 Q126.871 511.362 129.927 506.778 Q133.006 502.172 138.816 502.172 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip990)\" d=\"M64.0708 228.127 Q60.4597 228.127 58.631 231.692 Q56.8254 235.234 56.8254 242.363 Q56.8254 249.47 58.631 253.035 Q60.4597 256.576 64.0708 256.576 Q67.705 256.576 69.5105 253.035 Q71.3392 249.47 71.3392 242.363 Q71.3392 235.234 69.5105 231.692 Q67.705 228.127 64.0708 228.127 M64.0708 224.424 Q69.8809 224.424 72.9365 229.03 Q76.0151 233.613 76.0151 242.363 Q76.0151 251.09 72.9365 255.697 Q69.8809 260.28 64.0708 260.28 Q58.2606 260.28 55.1819 255.697 Q52.1264 251.09 52.1264 242.363 Q52.1264 233.613 55.1819 229.03 Q58.2606 224.424 64.0708 224.424 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip990)\" d=\"M84.2327 253.729 L89.1169 253.729 L89.1169 259.609 L84.2327 259.609 L84.2327 253.729 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip990)\" d=\"M109.881 240.465 Q106.733 240.465 104.881 242.618 Q103.052 244.771 103.052 248.521 Q103.052 252.248 104.881 254.423 Q106.733 256.576 109.881 256.576 Q113.029 256.576 114.858 254.423 Q116.709 252.248 116.709 248.521 Q116.709 244.771 114.858 242.618 Q113.029 240.465 109.881 240.465 M119.163 225.813 L119.163 230.072 Q117.404 229.238 115.598 228.799 Q113.816 228.359 112.057 228.359 Q107.427 228.359 104.973 231.484 Q102.543 234.609 102.196 240.928 Q103.561 238.914 105.621 237.849 Q107.682 236.762 110.158 236.762 Q115.367 236.762 118.376 239.933 Q121.408 243.081 121.408 248.521 Q121.408 253.845 118.26 257.062 Q115.112 260.28 109.881 260.28 Q103.885 260.28 100.714 255.697 Q97.5428 251.09 97.5428 242.363 Q97.5428 234.169 101.432 229.308 Q105.321 224.424 111.871 224.424 Q113.631 224.424 115.413 224.771 Q117.219 225.118 119.163 225.813 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip990)\" d=\"M143.631 240.974 Q146.987 241.692 148.862 243.961 Q150.76 246.229 150.76 249.562 Q150.76 254.678 147.242 257.479 Q143.723 260.28 137.242 260.28 Q135.066 260.28 132.751 259.84 Q130.459 259.423 128.006 258.567 L128.006 254.053 Q129.95 255.187 132.265 255.766 Q134.58 256.345 137.103 256.345 Q141.501 256.345 143.793 254.609 Q146.107 252.873 146.107 249.562 Q146.107 246.507 143.955 244.794 Q141.825 243.058 138.006 243.058 L133.978 243.058 L133.978 239.215 L138.191 239.215 Q141.64 239.215 143.468 237.849 Q145.297 236.461 145.297 233.868 Q145.297 231.206 143.399 229.794 Q141.524 228.359 138.006 228.359 Q136.084 228.359 133.885 228.775 Q131.686 229.192 129.047 230.072 L129.047 225.905 Q131.709 225.164 134.024 224.794 Q136.362 224.424 138.422 224.424 Q143.746 224.424 146.848 226.854 Q149.95 229.262 149.95 233.382 Q149.95 236.252 148.306 238.243 Q146.663 240.211 143.631 240.974 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip992)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  248.062,643.329 475.105,1077.62 702.149,739.88 929.193,1311.64 1156.24,811.915 1383.28,87.9763 1610.32,1425.73 1837.37,116.828 2064.41,892.06 2291.45,1445.72 \n",
       "  \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip990)\" d=\"\n",
       "M1877.06 198.898 L2280.56 198.898 L2280.56 95.2176 L1877.06 95.2176  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip990)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1877.06,198.898 2280.56,198.898 2280.56,95.2176 1877.06,95.2176 1877.06,198.898 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip990)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1901.06,147.058 2045.06,147.058 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip990)\" d=\"M2069.06 128.319 L2078.88 128.319 L2078.88 131.629 L2073.32 131.629 L2073.32 167.277 L2078.88 167.277 L2078.88 170.588 L2069.06 170.588 L2069.06 128.319 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip990)\" d=\"M2091.98 129.778 L2091.98 142.625 L2088.04 142.625 L2088.04 129.778 L2091.98 129.778 M2100.73 129.778 L2100.73 142.625 L2096.79 142.625 L2096.79 129.778 L2100.73 129.778 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip990)\" d=\"M2113.97 131.051 L2113.97 138.412 L2122.74 138.412 L2122.74 141.722 L2113.97 141.722 L2113.97 155.796 Q2113.97 158.967 2114.83 159.87 Q2115.7 160.773 2118.37 160.773 L2122.74 160.773 L2122.74 164.338 L2118.37 164.338 Q2113.44 164.338 2111.56 162.509 Q2109.69 160.657 2109.69 155.796 L2109.69 141.722 L2106.56 141.722 L2106.56 138.412 L2109.69 138.412 L2109.69 131.051 L2113.97 131.051 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip990)\" d=\"M2150.52 150.31 L2150.52 152.393 L2130.94 152.393 Q2131.21 156.791 2133.58 159.106 Q2135.96 161.398 2140.2 161.398 Q2142.65 161.398 2144.94 160.796 Q2147.26 160.194 2149.52 158.99 L2149.52 163.018 Q2147.23 163.99 2144.83 164.5 Q2142.42 165.009 2139.94 165.009 Q2133.74 165.009 2130.1 161.398 Q2126.49 157.787 2126.49 151.629 Q2126.49 145.264 2129.92 141.537 Q2133.37 137.787 2139.2 137.787 Q2144.43 137.787 2147.46 141.166 Q2150.52 144.523 2150.52 150.31 M2146.26 149.06 Q2146.21 145.565 2144.29 143.481 Q2142.39 141.398 2139.25 141.398 Q2135.68 141.398 2133.53 143.412 Q2131.4 145.426 2131.08 149.083 L2146.26 149.06 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip990)\" d=\"M2174.04 139.176 L2174.04 143.203 Q2172.23 142.277 2170.29 141.815 Q2168.34 141.352 2166.26 141.352 Q2163.09 141.352 2161.49 142.324 Q2159.92 143.296 2159.92 145.24 Q2159.92 146.722 2161.05 147.578 Q2162.19 148.412 2165.61 149.176 L2167.07 149.5 Q2171.61 150.472 2173.51 152.254 Q2175.43 154.014 2175.43 157.185 Q2175.43 160.796 2172.56 162.902 Q2169.71 165.009 2164.71 165.009 Q2162.63 165.009 2160.36 164.592 Q2158.11 164.199 2155.61 163.388 L2155.61 158.99 Q2157.97 160.217 2160.26 160.842 Q2162.56 161.444 2164.8 161.444 Q2167.81 161.444 2169.43 160.426 Q2171.05 159.384 2171.05 157.509 Q2171.05 155.773 2169.87 154.847 Q2168.71 153.921 2164.76 153.064 L2163.27 152.717 Q2159.32 151.884 2157.56 150.171 Q2155.8 148.435 2155.8 145.426 Q2155.8 141.768 2158.39 139.778 Q2160.98 137.787 2165.75 137.787 Q2168.11 137.787 2170.2 138.134 Q2172.28 138.481 2174.04 139.176 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip990)\" d=\"M2186.42 131.051 L2186.42 138.412 L2195.2 138.412 L2195.2 141.722 L2186.42 141.722 L2186.42 155.796 Q2186.42 158.967 2187.28 159.87 Q2188.16 160.773 2190.82 160.773 L2195.2 160.773 L2195.2 164.338 L2190.82 164.338 Q2185.89 164.338 2184.01 162.509 Q2182.14 160.657 2182.14 155.796 L2182.14 141.722 L2179.01 141.722 L2179.01 138.412 L2182.14 138.412 L2182.14 131.051 L2186.42 131.051 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip990)\" d=\"M2204.82 129.778 L2204.82 142.625 L2200.89 142.625 L2200.89 129.778 L2204.82 129.778 M2213.57 129.778 L2213.57 142.625 L2209.64 142.625 L2209.64 129.778 L2213.57 129.778 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip990)\" d=\"M2232.56 128.319 L2232.56 170.588 L2222.74 170.588 L2222.74 167.277 L2228.27 167.277 L2228.27 131.629 L2222.74 131.629 L2222.74 128.319 L2232.56 128.319 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plots.plot(train_acc_list,label=[\"train\"])\n",
    "Plots.plot!(test,label=[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "marine-committee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix of test data in best model:\n",
      "true_true_result->12014,  true_false_result->7599\n",
      "false_false_result->9225,   false_true_result->9053\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    In order to compute for confusion matrix\n",
    "    Just from hw1\n",
    "\"\"\"\n",
    "#TT\n",
    "TT=sum(vec(evomodel(X_test_std) .> 0.5) .== 1) \n",
    "#TF\n",
    "TF=sum(vec(evomodel(X_test_std) .> 0.5) .== 0) \n",
    "#FT\n",
    "FT=sum(vec(evomodel(X_test_std) .< 0.5) .== 1) \n",
    "#FF\n",
    "FF=sum(vec(evomodel(X_test_std) .< 0.5) .== 0) \n",
    "println(\"confusion matrix of test data in best model:\")\n",
    "println(\"true_true_result->$TT,  true_false_result->$TF\")\n",
    "println(\"false_false_result->$FF,   false_true_result->$FT\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.1",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
