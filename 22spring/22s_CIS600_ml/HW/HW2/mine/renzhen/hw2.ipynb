{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "utility-south",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Evolutionary\n",
    "using Flux\n",
    "using Flux: onehot, onecold, logitcrossentropy #, throttle, @epochs\n",
    "using MLDatasets\n",
    "using Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "outdoor-moscow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>70,692 rows × 22 columns (omitted printing of 14 columns)</p><table class=\"data-frame\"><thead><tr><th></th><th>Diabetes_binary</th><th>HighBP</th><th>HighChol</th><th>CholCheck</th><th>BMI</th><th>Smoker</th><th>Stroke</th><th>HeartDiseaseorAttack</th></tr><tr><th></th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th></tr></thead><tbody><tr><th>1</th><td>0.0</td><td>0.0</td><td>1.0</td><td>1.0</td><td>25.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>2</th><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>25.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>3</th><td>0.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>29.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>4</th><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>26.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>5</th><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>29.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>6</th><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>24.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>7</th><td>0.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>36.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>8</th><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>26.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>9</th><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>21.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>10</th><td>0.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>23.0</td><td>1.0</td><td>0.0</td><td>1.0</td></tr><tr><th>11</th><td>0.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>27.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>12</th><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>24.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>13</th><td>0.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>25.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>14</th><td>0.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>30.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>15</th><td>0.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>31.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>16</th><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>24.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>17</th><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>26.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>18</th><td>0.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>26.0</td><td>1.0</td><td>0.0</td><td>1.0</td></tr><tr><th>19</th><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>35.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>20</th><td>0.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>35.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>21</th><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>31.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>22</th><td>0.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>33.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>23</th><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>25.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>24</th><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>21.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>25</th><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>37.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>26</th><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>23.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>27</th><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>22.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>28</th><td>0.0</td><td>0.0</td><td>1.0</td><td>1.0</td><td>29.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>29</th><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>26.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>30</th><td>0.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>32.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccccc}\n",
       "\t& Diabetes\\_binary & HighBP & HighChol & CholCheck & BMI & Smoker & Stroke & HeartDiseaseorAttack & \\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 0.0 & 0.0 & 1.0 & 1.0 & 25.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t2 & 0.0 & 0.0 & 0.0 & 0.0 & 25.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t3 & 0.0 & 1.0 & 1.0 & 1.0 & 29.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t4 & 0.0 & 0.0 & 0.0 & 1.0 & 26.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t5 & 0.0 & 0.0 & 0.0 & 1.0 & 29.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t6 & 0.0 & 0.0 & 0.0 & 0.0 & 24.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t7 & 0.0 & 1.0 & 1.0 & 1.0 & 36.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t8 & 0.0 & 0.0 & 0.0 & 1.0 & 26.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t9 & 0.0 & 0.0 & 0.0 & 1.0 & 21.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t10 & 0.0 & 1.0 & 1.0 & 1.0 & 23.0 & 1.0 & 0.0 & 1.0 & $\\dots$ \\\\\n",
       "\t11 & 0.0 & 1.0 & 1.0 & 1.0 & 27.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t12 & 0.0 & 0.0 & 0.0 & 0.0 & 24.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t13 & 0.0 & 1.0 & 1.0 & 1.0 & 25.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t14 & 0.0 & 1.0 & 1.0 & 1.0 & 30.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t15 & 0.0 & 1.0 & 1.0 & 1.0 & 31.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t16 & 0.0 & 0.0 & 0.0 & 1.0 & 24.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t17 & 0.0 & 0.0 & 0.0 & 1.0 & 26.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t18 & 0.0 & 1.0 & 1.0 & 1.0 & 26.0 & 1.0 & 0.0 & 1.0 & $\\dots$ \\\\\n",
       "\t19 & 0.0 & 0.0 & 0.0 & 1.0 & 35.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t20 & 0.0 & 1.0 & 0.0 & 1.0 & 35.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t21 & 0.0 & 0.0 & 0.0 & 1.0 & 31.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t22 & 0.0 & 1.0 & 1.0 & 1.0 & 33.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t23 & 0.0 & 0.0 & 0.0 & 1.0 & 25.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t24 & 0.0 & 0.0 & 0.0 & 1.0 & 21.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t25 & 0.0 & 0.0 & 0.0 & 1.0 & 37.0 & 1.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t26 & 0.0 & 0.0 & 0.0 & 1.0 & 23.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t27 & 0.0 & 0.0 & 0.0 & 1.0 & 22.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t28 & 0.0 & 0.0 & 1.0 & 1.0 & 29.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t29 & 0.0 & 0.0 & 0.0 & 1.0 & 26.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t30 & 0.0 & 1.0 & 1.0 & 1.0 & 32.0 & 0.0 & 0.0 & 0.0 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m70692×22 DataFrame\u001b[0m\n",
       "\u001b[1m   Row \u001b[0m│\u001b[1m Diabetes_binary \u001b[0m\u001b[1m HighBP  \u001b[0m\u001b[1m HighChol \u001b[0m\u001b[1m CholCheck \u001b[0m\u001b[1m BMI     \u001b[0m\u001b[1m Smoker  \u001b[0m\u001b[1m Stro\u001b[0m ⋯\n",
       "\u001b[1m       \u001b[0m│\u001b[90m Float64         \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m Float64   \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Floa\u001b[0m ⋯\n",
       "───────┼────────────────────────────────────────────────────────────────────────\n",
       "     1 │             0.0      0.0       1.0        1.0     25.0      1.0       ⋯\n",
       "     2 │             0.0      0.0       0.0        0.0     25.0      1.0\n",
       "     3 │             0.0      1.0       1.0        1.0     29.0      1.0\n",
       "     4 │             0.0      0.0       0.0        1.0     26.0      1.0\n",
       "     5 │             0.0      0.0       0.0        1.0     29.0      1.0       ⋯\n",
       "     6 │             0.0      0.0       0.0        0.0     24.0      0.0\n",
       "     7 │             0.0      1.0       1.0        1.0     36.0      0.0\n",
       "     8 │             0.0      0.0       0.0        1.0     26.0      1.0\n",
       "     9 │             0.0      0.0       0.0        1.0     21.0      0.0       ⋯\n",
       "    10 │             0.0      1.0       1.0        1.0     23.0      1.0\n",
       "    11 │             0.0      1.0       1.0        1.0     27.0      0.0\n",
       "   ⋮   │        ⋮            ⋮        ⋮          ⋮         ⋮        ⋮        ⋮ ⋱\n",
       " 70683 │             1.0      1.0       0.0        1.0     37.0      0.0\n",
       " 70684 │             1.0      1.0       0.0        1.0     28.0      0.0       ⋯\n",
       " 70685 │             1.0      1.0       1.0        1.0     27.0      0.0\n",
       " 70686 │             1.0      1.0       0.0        1.0     38.0      0.0\n",
       " 70687 │             1.0      0.0       1.0        1.0     27.0      0.0\n",
       " 70688 │             1.0      0.0       1.0        1.0     37.0      0.0       ⋯\n",
       " 70689 │             1.0      0.0       1.0        1.0     29.0      1.0\n",
       " 70690 │             1.0      1.0       1.0        1.0     25.0      0.0\n",
       " 70691 │             1.0      1.0       1.0        1.0     18.0      0.0\n",
       " 70692 │             1.0      1.0       1.0        1.0     25.0      0.0       ⋯\n",
       "\u001b[36m                                               16 columns and 70671 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using ZipFile, CSV, DataFrames, Random, StatsBase , Plots, Statistics\n",
    "\n",
    "# read file from zip archive\n",
    "\n",
    "z = ZipFile.Reader(\"results.zip\")\n",
    "\n",
    "# identify the right file in zip\n",
    "\n",
    "# The diabetes dataset I found through kaggle have done split into 2 classifiers and select 50 percents of result from each \n",
    "# label. So i think there is more work in my dataset\n",
    "\n",
    "a_file_in_zip = filter(x->x.name == \"diabetes_binary_5050split_health_indicators_BRFSS2015.csv\", z.files)[1]\n",
    "\n",
    "#avoid changing the original files in the zip file. However, the dataset will not change but whatever.\n",
    "\n",
    "a_copy = CSV.File(a_file_in_zip) |> DataFrame\n",
    "\n",
    "close(z)\n",
    "\n",
    "#show the dataset\n",
    "\n",
    "a_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "proprietary-defeat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35346×22 Matrix{Float64}:\n",
       " 1.0  1.0  1.0  1.0  30.0  1.0  0.0  1.0  …  30.0  1.0  0.0   9.0  5.0  1.0\n",
       " 1.0  0.0  0.0  1.0  25.0  1.0  0.0  0.0      0.0  0.0  1.0  13.0  6.0  8.0\n",
       " 1.0  1.0  1.0  1.0  28.0  0.0  0.0  0.0      0.0  1.0  0.0  11.0  4.0  6.0\n",
       " 1.0  0.0  0.0  1.0  23.0  1.0  0.0  0.0      0.0  0.0  1.0   7.0  5.0  6.0\n",
       " 1.0  1.0  0.0  1.0  27.0  0.0  0.0  0.0      0.0  0.0  0.0  13.0  5.0  4.0\n",
       " 1.0  1.0  1.0  1.0  37.0  1.0  1.0  1.0  …   0.0  1.0  1.0  10.0  6.0  5.0\n",
       " 1.0  1.0  1.0  1.0  28.0  1.0  0.0  1.0      0.0  0.0  1.0  12.0  2.0  4.0\n",
       " 1.0  1.0  1.0  1.0  27.0  1.0  0.0  0.0     20.0  1.0  0.0   8.0  4.0  7.0\n",
       " 1.0  1.0  1.0  1.0  34.0  1.0  1.0  0.0      7.0  1.0  0.0   9.0  5.0  4.0\n",
       " 1.0  1.0  1.0  1.0  24.0  1.0  0.0  0.0      0.0  0.0  0.0  12.0  3.0  3.0\n",
       " 1.0  1.0  0.0  1.0  31.0  0.0  0.0  0.0  …   5.0  0.0  0.0  13.0  4.0  4.0\n",
       " 1.0  1.0  1.0  1.0  33.0  1.0  0.0  0.0     30.0  1.0  0.0  11.0  4.0  2.0\n",
       " 1.0  1.0  1.0  1.0  27.0  1.0  0.0  0.0     30.0  1.0  0.0  10.0  4.0  5.0\n",
       " ⋮                         ⋮              ⋱                        ⋮    \n",
       " 1.0  1.0  1.0  1.0  30.0  0.0  0.0  0.0     30.0  1.0  0.0  11.0  2.0  2.0\n",
       " 1.0  0.0  1.0  1.0  19.0  0.0  0.0  0.0  …   2.0  0.0  0.0   7.0  6.0  6.0\n",
       " 1.0  1.0  0.0  1.0  37.0  0.0  0.0  0.0     30.0  1.0  0.0   9.0  2.0  1.0\n",
       " 1.0  1.0  0.0  1.0  28.0  0.0  0.0  0.0      0.0  0.0  0.0  10.0  4.0  3.0\n",
       " 1.0  1.0  1.0  1.0  27.0  0.0  0.0  1.0      5.0  0.0  1.0   9.0  4.0  5.0\n",
       " 1.0  1.0  0.0  1.0  38.0  0.0  0.0  0.0      0.0  0.0  0.0   7.0  6.0  2.0\n",
       " 1.0  0.0  1.0  1.0  27.0  0.0  0.0  0.0  …  30.0  0.0  1.0  11.0  2.0  3.0\n",
       " 1.0  0.0  1.0  1.0  37.0  0.0  0.0  0.0      0.0  0.0  0.0   6.0  4.0  1.0\n",
       " 1.0  0.0  1.0  1.0  29.0  1.0  0.0  1.0      0.0  1.0  1.0  10.0  3.0  6.0\n",
       " 1.0  1.0  1.0  1.0  25.0  0.0  0.0  1.0      0.0  1.0  0.0  13.0  6.0  4.0\n",
       " 1.0  1.0  1.0  1.0  18.0  0.0  0.0  0.0      0.0  1.0  0.0  11.0  2.0  4.0\n",
       " 1.0  1.0  1.0  1.0  25.0  0.0  0.0  1.0  …   0.0  0.0  0.0   9.0  6.0  2.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transfer DataFrame to matrix form\n",
    "\n",
    "df=a_copy|>Tables.matrix\n",
    "\n",
    "# Transfer the dataset to 2-classifiers. df_0 represents the result is 0, df_1 represents the result is 1.\n",
    "# Due to my datasset is binary problems, and each result is 50 percents of the whole dataset. So i didn't add any other pre-actions for dataset. \n",
    "\n",
    "df_0 = df[df[:,1] .== 0, :]\n",
    "df_1 = df[df[:,1] .== 1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "grave-embassy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20570×22 Matrix{Float64}:\n",
       " 0.0  0.0  0.0  0.0  24.0  0.0  0.0  0.0  …   0.0  0.0  1.0   7.0  5.0  8.0\n",
       " 0.0  1.0  1.0  1.0  36.0  0.0  0.0  0.0      2.0  0.0  1.0  11.0  6.0  8.0\n",
       " 0.0  0.0  0.0  1.0  21.0  0.0  0.0  0.0      0.0  0.0  0.0   8.0  5.0  6.0\n",
       " 0.0  1.0  1.0  1.0  23.0  1.0  0.0  1.0      0.0  0.0  0.0   6.0  4.0  6.0\n",
       " 0.0  1.0  1.0  1.0  31.0  1.0  0.0  0.0      0.0  0.0  1.0   8.0  4.0  8.0\n",
       " 0.0  0.0  0.0  1.0  35.0  0.0  0.0  0.0  …   0.0  0.0  1.0   7.0  4.0  7.0\n",
       " 0.0  0.0  0.0  1.0  37.0  1.0  0.0  0.0      0.0  0.0  0.0   5.0  6.0  6.0\n",
       " 0.0  0.0  0.0  1.0  23.0  0.0  0.0  0.0      3.0  0.0  0.0   2.0  5.0  8.0\n",
       " 0.0  0.0  0.0  1.0  25.0  0.0  0.0  0.0      3.0  0.0  1.0   4.0  6.0  8.0\n",
       " 0.0  1.0  1.0  1.0  24.0  0.0  0.0  0.0     20.0  0.0  1.0  13.0  6.0  6.0\n",
       " 0.0  0.0  0.0  1.0  26.0  1.0  0.0  0.0  …   0.0  0.0  0.0   5.0  6.0  8.0\n",
       " 0.0  1.0  0.0  1.0  22.0  1.0  0.0  0.0      0.0  0.0  0.0  11.0  5.0  7.0\n",
       " 0.0  0.0  0.0  1.0  30.0  1.0  0.0  0.0      4.0  0.0  1.0   3.0  5.0  8.0\n",
       " ⋮                         ⋮              ⋱                        ⋮    \n",
       " 1.0  1.0  0.0  1.0  45.0  1.0  0.0  0.0     30.0  0.0  1.0   9.0  6.0  6.0\n",
       " 1.0  0.0  1.0  1.0  35.0  0.0  0.0  0.0      6.0  1.0  0.0  10.0  6.0  5.0\n",
       " 1.0  1.0  0.0  1.0  26.0  0.0  0.0  0.0  …   0.0  0.0  0.0  13.0  6.0  6.0\n",
       " 1.0  1.0  1.0  1.0  32.0  0.0  0.0  0.0     30.0  1.0  0.0   9.0  4.0  2.0\n",
       " 1.0  1.0  1.0  1.0  36.0  1.0  0.0  0.0      0.0  0.0  1.0   6.0  4.0  1.0\n",
       " 1.0  1.0  0.0  1.0  39.0  0.0  0.0  0.0      0.0  0.0  0.0   8.0  4.0  4.0\n",
       " 1.0  1.0  1.0  1.0  36.0  0.0  0.0  0.0      0.0  0.0  0.0  10.0  4.0  1.0\n",
       " 1.0  1.0  1.0  1.0  24.0  0.0  0.0  1.0  …   0.0  0.0  1.0  11.0  6.0  8.0\n",
       " 1.0  1.0  1.0  1.0  32.0  1.0  0.0  1.0     30.0  1.0  1.0  10.0  3.0  2.0\n",
       " 1.0  1.0  1.0  1.0  30.0  1.0  0.0  1.0     30.0  0.0  1.0   9.0  4.0  1.0\n",
       " 1.0  1.0  0.0  1.0  24.0  0.0  0.0  0.0      0.0  0.0  1.0  12.0  3.0  4.0\n",
       " 1.0  1.0  0.0  1.0  24.0  0.0  0.0  1.0     30.0  1.0  1.0  12.0  4.0  4.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The columns of matrix is 35346(here just using 35000 is the same), using random sub-sequence to select 70 percents of \n",
    "# columns as the train data.\n",
    "\n",
    "sample = randsubseq(1:35000, 0.7)\n",
    "train_df = vcat(df_0[sample, :], df_1[sample, :])\n",
    "\n",
    "# Then from the not selected columns (which is 30 percents) to select the test data.\n",
    "\n",
    "notsample = [i for i in 1:35000 if isempty(searchsorted(sample, i))]\n",
    "test_df = vcat(df_0[notsample, :], df_1[notsample, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "identical-skirt",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20570-element Vector{Float64}:\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " ⋮\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Divide the columns into features and result. From my dataset, From 2 to 22 columns are the attributes of whether diabetes or not.\n",
    "\n",
    "X_train = train_df[:, 2:22]\n",
    "X_test = test_df[:, 2:22]\n",
    "\n",
    "y_train = train_df[:, 1]\n",
    "y_test = test_df[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "casual-tract",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([-1.1457331532225008 -1.1457331532225008 … 0.8727859245045625 0.8727859245045625; 0.9493971771738328 -1.053278641872066 … -1.053278641872066 0.9493971771738328; … ; 0.07122984250716069 1.0441204518271212 … 1.0441204518271212 -0.9016607668127998; 0.5959338525728632 1.0576786653744406 … -1.7127902114350237 -2.1745350242366013], [-1.1457331532225008 0.8727859245045625 … 0.8727859245045625 0.8727859245045625; -1.053278641872066 0.9493971771738328 … -1.053278641872066 -1.053278641872066; … ; 0.07122984250716069 1.0441204518271212 … -1.8745513761327606 -0.9016607668127998; 1.0576786653744406 1.0576786653744406 … -0.789300585831869 -0.789300585831869])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Distributions\n",
    "\n",
    "# Transfer the X_train to 1 diminension.\n",
    "\n",
    "dt = fit(ZScoreTransform, X_train, dims=1)\n",
    "\n",
    "# Using StateBase package to transfer X_train and X_test(make them standard) to the same formate as dt.\n",
    "\n",
    "X_train_std = StatsBase.transform(dt, X_train)\n",
    "X_test_std = StatsBase.transform(dt, X_test)\n",
    "\n",
    "# Transpose the X_train_std and X_test_std.\n",
    "    \n",
    "X_train_std, X_test_std= transpose(X_train_std), transpose(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bored-diploma",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "zip([-1.1457331532225008 0.8727859245045625 … 0.8727859245045625 0.8727859245045625; -1.053278641872066 0.9493971771738328 … -1.053278641872066 -1.053278641872066; … ; 0.07122984250716069 1.0441204518271212 … -1.8745513761327606 -0.9016607668127998; 1.0576786653744406 1.0576786653744406 … -0.789300585831869 -0.789300585831869], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data=zip(X_train_std,y_train)\n",
    "test_data=zip(X_test_std,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "alternative-aquarium",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_population (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create model list,each model represents an individual in population\n",
    "function model_population(size)\n",
    "    population = []\n",
    "    for i in 1:size\n",
    "        smodel = sigmoidmodel(Batch_size)\n",
    "        append!(population,[smodel])\n",
    "    end\n",
    "    return population\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "technical-delivery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #train models and get the accuracy list,sort them by accuracy\n",
    "# function train_models(model_list)\n",
    "#     model_mean_acc_list = []\n",
    "#     for model in model_list\n",
    "#         model_acc_list = []\n",
    "#         for (x,y) in train_data\n",
    "#             pred = model(x)\n",
    "#             ac = acc(pred,y)\n",
    "#             append!(model_acc_list,ac)\n",
    "#         end\n",
    "#         append!(model_mean_acc_list,mean(model_acc_list))\n",
    "#     end\n",
    "    \n",
    "#     index=reverse(sortperm(model_mean_acc_list))\n",
    "#     model_mean_acc_list=model_mean_acc_list[index]\n",
    "#     model_list=model_list[index]\n",
    "    \n",
    "#     return model_list,model_mean_acc_list\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "floating-matthew",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_models (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train models and get the accuracy list,sort them by accuracy\n",
    "function train_models(model_list)\n",
    "    model_mean_acc_list = []\n",
    "    i=1\n",
    "    for model in model_list\n",
    "        append!(model_mean_acc_list,mean(accuracy(X_train_std,y_train,i)))\n",
    "        i=i+1\n",
    "    end\n",
    "    \n",
    "    index=reverse(sortperm(model_mean_acc_list))\n",
    "    model_mean_acc_list=model_mean_acc_list[index]\n",
    "    model_list=model_list[index]\n",
    "    \n",
    "    return model_list,model_mean_acc_list\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "medium-bahrain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test_model (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function test_model(model)\n",
    "    model_acc_list=[]\n",
    "    return mean(accuracy(X_test_std,y_test))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "naughty-sunglasses",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function test_model(model)\n",
    "#     model_acc_list=[]\n",
    "#     for (x,y) in test_data\n",
    "#         pred=model(x)\n",
    "#         sacc=acc(x,y)\n",
    "#         push!(model_acc_list,sacc)\n",
    "#     end\n",
    "#     return mean(model_acc_list)\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "reverse-halifax",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "crossover (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Do Crossover here \n",
    "function crossover(father,mother)\n",
    "    nn=deepcopy(father)\n",
    "    for i in 1:layer\n",
    "        select_one_layer = shuffle(collect(1:layer))[1]\n",
    "        mother_bias=mother[select_one_layer].bias\n",
    "        picked_one_row=shuffle(collect(1:size(mother_bias)[1]))[1]\n",
    "        if rand() < Crossover_rate\n",
    "            nn[select_one_layer].bias[picked_one_row]=mother_bias[picked_one_row]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    for i in 1:layer\n",
    "        select_one_layer=shuffle(collect(1:layer))[1]\n",
    "        mother_weight=nn[select_one_layer].weight\n",
    "        picked_one_row=shuffle(collect(1:size(mother_weight)[1]))[1]\n",
    "        picked_one_col=shuffle(collect(1:size(mother_weight)[2]))[1]\n",
    "        if rand() < Crossover_rate\n",
    "            nn[select_one_layer].weight[picked_one_row,picked_one_col]=mother_weight[picked_one_row,picked_one_col]\n",
    "        end\n",
    "    end\n",
    "    return nn\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunrise-curtis",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do Crossover here \n",
    "function crossover(father,mother)\n",
    "    nn=deepcopy(father)\n",
    "    for i in 1:layer\n",
    "        select_one_layer = shuffle(collect(1:layer))[1]\n",
    "        mother_bias=mother[select_one_layer].bias\n",
    "        picked_one_row=shuffle(collect(1:size(mother_bias)[1]))[1]\n",
    "        if rand() < Crossover_rate\n",
    "            nn[select_one_layer].bias[picked_one_row]=mother_bias[picked_one_row]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    for i in 1:layer\n",
    "        select_one_layer=shuffle(collect(1:layer))[1]\n",
    "        mother_weight=nn[select_one_layer].weight\n",
    "        picked_one_row=shuffle(collect(1:size(mother_weight)[1]))[1]\n",
    "        picked_one_col=shuffle(collect(1:size(mother_weight)[2]))[1]\n",
    "        if rand() < Crossover_rate\n",
    "            nn[select_one_layer].weight[picked_one_row,picked_one_col]=mother_weight[picked_one_row,picked_one_col]\n",
    "        end\n",
    "    end\n",
    "    return nn\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "medium-layer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mutation (generic function with 1 method)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Do mutation here\n",
    "function mutation(new_child)\n",
    "    nn=deepcopy(new_child)\n",
    "    for i in 1:layer\n",
    "        select_one_layer = shuffle(collect(1:layer))[1]\n",
    "        bias=new_child[select_one_layer].bias\n",
    "        picked_one_row=shuffle(collect(1:size(bias)[1]))[1]\n",
    "        if rand() < Mutation_rate\n",
    "            nn[select_one_layer].bias[picked_one_row]+=rand(Uniform(-0.5,0.5),1)[1]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    for i in 1:layer\n",
    "        select_one_layer=shuffle(collect(1:layer))[1]\n",
    "        weight=nn[select_one_layer].weight\n",
    "        picked_one_row=shuffle(collect(1:size(weight)[1]))[1]\n",
    "        picked_one_col=shuffle(collect(1:size(weight)[2]))[1]\n",
    "        if rand() < Mutation_rate\n",
    "            nn[select_one_layer].weight[picked_one_row,picked_one_col]+=rand(Uniform(-0.5,0.5),1)[1]\n",
    "        end\n",
    "    end\n",
    "    return nn\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retained-collection",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do mutation here\n",
    "function mutation(new_child)\n",
    "    nn=deepcopy(new_child)\n",
    "    for i in 1:layer\n",
    "        select_one_layer = shuffle(collect(1:layer))[1]\n",
    "        bias=new_child[select_one_layer].bias\n",
    "        picked_one_row=shuffle(collect(1:size(bias)[1]))[1]\n",
    "        if rand() < Mutation_rate\n",
    "            nn[select_one_layer].bias[picked_one_row]+=rand(Uniform(-0.5,0.5),1)[1]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    for i in 1:layer\n",
    "        select_one_layer=shuffle(collect(1:layer))[1]\n",
    "        weight=nn[select_one_layer].weight\n",
    "        picked_one_row=shuffle(collect(1:size(weight)[1]))[1]\n",
    "        picked_one_col=shuffle(collect(1:size(weight)[2]))[1]\n",
    "        if rand() < Mutation_rate\n",
    "            nn[select_one_layer].weight[picked_one_row,picked_one_col]+=rand(Uniform(-0.5,0.5),1)[1]\n",
    "        end\n",
    "    end\n",
    "    return nn\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "committed-radio",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#parameters:\n",
    "Batch_size = 21\n",
    "Pop_size = 300\n",
    "Mutation_rate = 0.5\n",
    "Crossover_rate = 0.4\n",
    "Retain_rate = 0.4\n",
    "iteration = 30\n",
    "layer = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "modern-symposium",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sigmoidmodel (generic function with 1 method)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#build the model using sigmoid as Activation Function\n",
    "#The input dim is 12 as 12 features and the output dim is 2 represent A and B\n",
    "function sigmoidmodel(input_dim)\n",
    "    model = Chain(Dense(21, 8, sigmoid), Dense(8, 1, sigmoid))\n",
    "    return model\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "entertaining-nature",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Dense(21, 8, σ),                      \u001b[90m# 176 parameters\u001b[39m\n",
       "  Dense(8, 1, σ),                       \u001b[90m# 9 parameters\u001b[39m\n",
       ")\u001b[90m                   # Total: 4 arrays, \u001b[39m185 parameters, 996 bytes."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model=Chain(Dense(21, 8, sigmoid), Dense(8, 1, sigmoid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "collaborative-professor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300-element Vector{Any}:\n",
       " Chain(Dense(21, 8, σ), Dense(8, 1, σ))  \u001b[90m# 185 parameters\u001b[39m\n",
       " Chain(Dense(21, 8, σ), Dense(8, 1, σ))  \u001b[90m# 185 parameters\u001b[39m\n",
       " Chain(Dense(21, 8, σ), Dense(8, 1, σ))  \u001b[90m# 185 parameters\u001b[39m\n",
       " Chain(Dense(21, 8, σ), Dense(8, 1, σ))  \u001b[90m# 185 parameters\u001b[39m\n",
       " Chain(Dense(21, 8, σ), Dense(8, 1, σ))  \u001b[90m# 185 parameters\u001b[39m\n",
       " Chain(Dense(21, 8, σ), Dense(8, 1, σ))  \u001b[90m# 185 parameters\u001b[39m\n",
       " Chain(Dense(21, 8, σ), Dense(8, 1, σ))  \u001b[90m# 185 parameters\u001b[39m\n",
       " Chain(Dense(21, 8, σ), Dense(8, 1, σ))  \u001b[90m# 185 parameters\u001b[39m\n",
       " Chain(Dense(21, 8, σ), Dense(8, 1, σ))  \u001b[90m# 185 parameters\u001b[39m\n",
       " Chain(Dense(21, 8, σ), Dense(8, 1, σ))  \u001b[90m# 185 parameters\u001b[39m\n",
       " Chain(Dense(21, 8, σ), Dense(8, 1, σ))  \u001b[90m# 185 parameters\u001b[39m\n",
       " Chain(Dense(21, 8, σ), Dense(8, 1, σ))  \u001b[90m# 185 parameters\u001b[39m\n",
       " Chain(Dense(21, 8, σ), Dense(8, 1, σ))  \u001b[90m# 185 parameters\u001b[39m\n",
       " ⋮\n",
       " Chain(Dense(21, 8, σ), Dense(8, 1, σ))  \u001b[90m# 185 parameters\u001b[39m\n",
       " Chain(Dense(21, 8, σ), Dense(8, 1, σ))  \u001b[90m# 185 parameters\u001b[39m\n",
       " Chain(Dense(21, 8, σ), Dense(8, 1, σ))  \u001b[90m# 185 parameters\u001b[39m\n",
       " Chain(Dense(21, 8, σ), Dense(8, 1, σ))  \u001b[90m# 185 parameters\u001b[39m\n",
       " Chain(Dense(21, 8, σ), Dense(8, 1, σ))  \u001b[90m# 185 parameters\u001b[39m\n",
       " Chain(Dense(21, 8, σ), Dense(8, 1, σ))  \u001b[90m# 185 parameters\u001b[39m\n",
       " Chain(Dense(21, 8, σ), Dense(8, 1, σ))  \u001b[90m# 185 parameters\u001b[39m\n",
       " Chain(Dense(21, 8, σ), Dense(8, 1, σ))  \u001b[90m# 185 parameters\u001b[39m\n",
       " Chain(Dense(21, 8, σ), Dense(8, 1, σ))  \u001b[90m# 185 parameters\u001b[39m\n",
       " Chain(Dense(21, 8, σ), Dense(8, 1, σ))  \u001b[90m# 185 parameters\u001b[39m\n",
       " Chain(Dense(21, 8, σ), Dense(8, 1, σ))  \u001b[90m# 185 parameters\u001b[39m\n",
       " Chain(Dense(21, 8, σ), Dense(8, 1, σ))  \u001b[90m# 185 parameters\u001b[39m"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get Model List\n",
    "model_list = model_population(Pop_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "abroad-decimal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20-element Vector{Any}:\n",
       " Chain(Dense(21, 8, σ), Dense(8, 1, σ))  \u001b[90m# 185 parameters\u001b[39m\n",
       " Chain(Dense(21, 8, σ), Dense(8, 1, σ))  \u001b[90m# 185 parameters\u001b[39m\n",
       " Chain(Dense(21, 8, σ), Dense(8, 1, σ))  \u001b[90m# 185 parameters\u001b[39m\n",
       " Chain(Dense(21, 8, σ), Dense(8, 1, σ))  \u001b[90m# 185 parameters\u001b[39m\n",
       " Chain(Dense(21, 8, σ), Dense(8, 1, σ))  \u001b[90m# 185 parameters\u001b[39m\n",
       " Chain(Dense(21, 8, σ), Dense(8, 1, σ))  \u001b[90m# 185 parameters\u001b[39m\n",
       " Chain(Dense(21, 8, σ), Dense(8, 1, σ))  \u001b[90m# 185 parameters\u001b[39m\n",
       " Chain(Dense(21, 8, σ), Dense(8, 1, σ))  \u001b[90m# 185 parameters\u001b[39m\n",
       " Chain(Dense(21, 8, σ), Dense(8, 1, σ))  \u001b[90m# 185 parameters\u001b[39m\n",
       " Chain(Dense(21, 8, σ), Dense(8, 1, σ))  \u001b[90m# 185 parameters\u001b[39m\n",
       " Chain(Dense(21, 8, σ), Dense(8, 1, σ))  \u001b[90m# 185 parameters\u001b[39m\n",
       " Chain(Dense(21, 8, σ), Dense(8, 1, σ))  \u001b[90m# 185 parameters\u001b[39m\n",
       " Chain(Dense(21, 8, σ), Dense(8, 1, σ))  \u001b[90m# 185 parameters\u001b[39m\n",
       " Chain(Dense(21, 8, σ), Dense(8, 1, σ))  \u001b[90m# 185 parameters\u001b[39m\n",
       " Chain(Dense(21, 8, σ), Dense(8, 1, σ))  \u001b[90m# 185 parameters\u001b[39m\n",
       " Chain(Dense(21, 8, σ), Dense(8, 1, σ))  \u001b[90m# 185 parameters\u001b[39m\n",
       " Chain(Dense(21, 8, σ), Dense(8, 1, σ))  \u001b[90m# 185 parameters\u001b[39m\n",
       " Chain(Dense(21, 8, σ), Dense(8, 1, σ))  \u001b[90m# 185 parameters\u001b[39m\n",
       " Chain(Dense(21, 8, σ), Dense(8, 1, σ))  \u001b[90m# 185 parameters\u001b[39m\n",
       " Chain(Dense(21, 8, σ), Dense(8, 1, σ))  \u001b[90m# 185 parameters\u001b[39m"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using BSON: @load\n",
    "using Zygote \n",
    "using Flux\n",
    "\n",
    "@load string(\"mymode_\",(1),\".bson\") base_model\n",
    "push!(model_list,base_model)\n",
    "@load string(\"mymode_\",(2),\".bson\") base_model\n",
    "push!(model_list,base_model)\n",
    "@load string(\"mymode_\",(3),\".bson\") base_model\n",
    "push!(model_list,base_model)\n",
    "@load string(\"mymode_\",(4),\".bson\") base_model\n",
    "push!(model_list,base_model)\n",
    "@load string(\"mymode_\",(5),\".bson\") base_model\n",
    "push!(model_list,base_model)\n",
    "@load string(\"mymode_\",(6),\".bson\") base_model\n",
    "push!(model_list,base_model)\n",
    "@load string(\"mymode_\",(7),\".bson\") base_model\n",
    "push!(model_list,base_model)\n",
    "@load string(\"mymode_\",(8),\".bson\") base_model\n",
    "push!(model_list,base_model)\n",
    "@load string(\"mymode_\",(9),\".bson\") base_model\n",
    "push!(model_list,base_model)\n",
    "@load string(\"mymode_\",(10),\".bson\") base_model\n",
    "push!(model_list,base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "moving-brighton",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Any[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_acc_list = []\n",
    "test_acc_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "raising-struggle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12-element Vector{Any}:\n",
       " Chain(Dense(21, 8, σ), Dense(8, 1, σ))  \u001b[90m# 185 parameters\u001b[39m\n",
       " Chain(Dense(21, 8, σ), Dense(8, 1, σ))  \u001b[90m# 185 parameters\u001b[39m\n",
       " Chain(Dense(21, 8, σ), Dense(8, 1, σ))  \u001b[90m# 185 parameters\u001b[39m\n",
       " Chain(Dense(21, 8, σ), Dense(8, 1, σ))  \u001b[90m# 185 parameters\u001b[39m\n",
       " Chain(Dense(21, 8, σ), Dense(8, 1, σ))  \u001b[90m# 185 parameters\u001b[39m\n",
       " Chain(Dense(21, 8, σ), Dense(8, 1, σ))  \u001b[90m# 185 parameters\u001b[39m\n",
       " Chain(Dense(21, 8, σ), Dense(8, 1, σ))  \u001b[90m# 185 parameters\u001b[39m\n",
       " Chain(Dense(21, 8, σ), Dense(8, 1, σ))  \u001b[90m# 185 parameters\u001b[39m\n",
       " Chain(Dense(21, 8, σ), Dense(8, 1, σ))  \u001b[90m# 185 parameters\u001b[39m\n",
       " Chain(Dense(21, 8, σ), Dense(8, 1, σ))  \u001b[90m# 185 parameters\u001b[39m\n",
       " Chain(Dense(21, 8, σ), Dense(8, 1, σ))  \u001b[90m# 185 parameters\u001b[39m\n",
       " Chain(Dense(21, 8, σ), Dense(8, 1, σ))  \u001b[90m# 185 parameters\u001b[39m"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "streaming-scope",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trial\n",
      "0.5460246813675905\n",
      "0.5989884685413717\n",
      "0.5345741452559175\n",
      "0.49755209387011934\n",
      "0.5467732146469755\n",
      "0.4742464090633219\n",
      "0.49609548856969454\n",
      "0.6092656281610358\n",
      "0.5357272911187538\n",
      "0.574711713534291\n",
      "0.4428484725874975\n",
      "0.5033178231843011\n",
      "0.5128059882662351\n",
      "0.4918875177018005\n",
      "0.44659113898442243\n",
      "0.4873356261379729\n",
      "0.44626744891766135\n",
      "0.496682176815699\n",
      "0.5769370827432733\n",
      "0.5\n",
      "0.5\n",
      "0.5197450940724256\n",
      "0.5000202306291726\n",
      "0.5292130285251871\n",
      "0.5049160428889339\n",
      "0.4934452761480882\n",
      "0.5742464090633219\n",
      "0.4540764717782723\n",
      "0.5\n",
      "0.5\n",
      "new\n",
      "0.6602265830467328\n",
      "0.6445276148088206\n",
      "0.6408254096702407\n",
      "0.6268865061703419\n",
      "0.6256524377908153\n",
      "0.6250657495448109\n",
      "0.624216063119563\n",
      "0.6222739227189965\n",
      "0.6133522152538944\n",
      "0.6132510621080316\n",
      "0.611733764920089\n",
      "0.60977139389035\n",
      "0.6092656281610358\n",
      "0.609164475015173\n",
      "0.6041675096095489\n",
      "0.6034392069593364\n",
      "0.6024479061298806\n",
      "0.6019016791422214\n",
      "0.5989884685413717\n",
      "0.5989884685413717\n",
      "0.5973700182075663\n",
      "0.5953064940319643\n",
      "0.5942342706858184\n",
      "0.5924337446894599\n",
      "0.589338458426057\n",
      "0.5830871940117338\n",
      "0.5826218895407648\n",
      "0.5797289095690876\n",
      "0.5786971474812866\n",
      "0.5769370827432733\n"
     ]
    }
   ],
   "source": [
    "using Flux\n",
    "using Flux: logitbinarycrossentropy\n",
    "using BSON: @save\n",
    "\n",
    "accuracy(x, y) = mean(vec(model_list[1](x) .> 0.5) .== y)\n",
    "accuracy(x, y, i) = mean(vec(model_list[i](x) .> 0.5) .== y)\n",
    "model,score = train_models(model_list)\n",
    "#erase models with low accuracy\n",
    "model_list = model_list[1:Int(size(model_list)[1]*Retain_rate)]\n",
    "test_acc=test_model(model_list[1])\n",
    "\n",
    "append!(train_acc_list,score[1])\n",
    "append!(test_acc_list,test_acc)\n",
    "\n",
    "println(\"\\nTrial\") \n",
    "for i in 1:30\n",
    "    println(accuracy(X_train_std, y_train,i))\n",
    "end\n",
    "while size(model_list)[1]<Pop_size\n",
    "    #pick up object to do crossover\n",
    "    model_mean_acc_list = []\n",
    "    i=1\n",
    "    for model in model_list\n",
    "        append!(model_mean_acc_list,mean(accuracy(X_train_std,y_train,i)))\n",
    "        i=i+1\n",
    "    end\n",
    "\n",
    "    index=reverse(sortperm(model_mean_acc_list))\n",
    "    model_mean_acc_list=model_mean_acc_list[index]\n",
    "    model_list=model_list[index]\n",
    "    idx=collect(1:size(model_list)[1])\n",
    "    idx=shuffle(idx)\n",
    "    father=model_list[idx[1]]\n",
    "    mother=model_list[idx[2]]\n",
    "\n",
    "    new_child=crossover(father,mother)\n",
    "    new_child=mutation(new_child)\n",
    "    append!(model_list,[new_child])\n",
    "end\n",
    "println(\"new\")\n",
    "for j in 1:30\n",
    "    println(accuracy(X_train_std, y_train,j))\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "occupied-delaware",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=[]\n",
    "for j in 1:30\n",
    "    push!(test,accuracy(X_train_std, y_train,j))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "noted-speaker",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip420\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip420)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip421\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip420)\" d=\"\n",
       "M216.436 1486.45 L2352.76 1486.45 L2352.76 47.2441 L216.436 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip422\">\n",
       "    <rect x=\"216\" y=\"47\" width=\"2137\" height=\"1440\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip422)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  554.883,1486.45 554.883,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip422)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  902.366,1486.45 902.366,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip422)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1249.85,1486.45 1249.85,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip422)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1597.33,1486.45 1597.33,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip422)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1944.81,1486.45 1944.81,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip422)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2292.29,1486.45 2292.29,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip420)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  216.436,1486.45 2352.76,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip420)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  554.883,1486.45 554.883,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip420)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  902.366,1486.45 902.366,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip420)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1249.85,1486.45 1249.85,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip420)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1597.33,1486.45 1597.33,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip420)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1944.81,1486.45 1944.81,1467.55 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip420)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2292.29,1486.45 2292.29,1467.55 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip420)\" d=\"M545.161 1514.29 L563.518 1514.29 L563.518 1518.22 L549.444 1518.22 L549.444 1526.7 Q550.462 1526.35 551.481 1526.19 Q552.499 1526 553.518 1526 Q559.305 1526 562.684 1529.17 Q566.064 1532.34 566.064 1537.76 Q566.064 1543.34 562.592 1546.44 Q559.12 1549.52 552.8 1549.52 Q550.624 1549.52 548.356 1549.15 Q546.11 1548.78 543.703 1548.04 L543.703 1543.34 Q545.786 1544.47 548.008 1545.03 Q550.231 1545.58 552.708 1545.58 Q556.712 1545.58 559.05 1543.48 Q561.388 1541.37 561.388 1537.76 Q561.388 1534.15 559.05 1532.04 Q556.712 1529.94 552.708 1529.94 Q550.833 1529.94 548.958 1530.35 Q547.106 1530.77 545.161 1531.65 L545.161 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip420)\" d=\"M877.053 1544.91 L884.692 1544.91 L884.692 1518.55 L876.382 1520.21 L876.382 1515.95 L884.646 1514.29 L889.322 1514.29 L889.322 1544.91 L896.961 1544.91 L896.961 1548.85 L877.053 1548.85 L877.053 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip420)\" d=\"M916.405 1517.37 Q912.794 1517.37 910.965 1520.93 Q909.16 1524.47 909.16 1531.6 Q909.16 1538.71 910.965 1542.27 Q912.794 1545.82 916.405 1545.82 Q920.039 1545.82 921.845 1542.27 Q923.673 1538.71 923.673 1531.6 Q923.673 1524.47 921.845 1520.93 Q920.039 1517.37 916.405 1517.37 M916.405 1513.66 Q922.215 1513.66 925.271 1518.27 Q928.349 1522.85 928.349 1531.6 Q928.349 1540.33 925.271 1544.94 Q922.215 1549.52 916.405 1549.52 Q910.595 1549.52 907.516 1544.94 Q904.46 1540.33 904.46 1531.6 Q904.46 1522.85 907.516 1518.27 Q910.595 1513.66 916.405 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip420)\" d=\"M1225.03 1544.91 L1232.67 1544.91 L1232.67 1518.55 L1224.36 1520.21 L1224.36 1515.95 L1232.63 1514.29 L1237.3 1514.29 L1237.3 1544.91 L1244.94 1544.91 L1244.94 1548.85 L1225.03 1548.85 L1225.03 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip420)\" d=\"M1254.43 1514.29 L1272.79 1514.29 L1272.79 1518.22 L1258.71 1518.22 L1258.71 1526.7 Q1259.73 1526.35 1260.75 1526.19 Q1261.77 1526 1262.79 1526 Q1268.57 1526 1271.95 1529.17 Q1275.33 1532.34 1275.33 1537.76 Q1275.33 1543.34 1271.86 1546.44 Q1268.39 1549.52 1262.07 1549.52 Q1259.89 1549.52 1257.63 1549.15 Q1255.38 1548.78 1252.97 1548.04 L1252.97 1543.34 Q1255.06 1544.47 1257.28 1545.03 Q1259.5 1545.58 1261.98 1545.58 Q1265.98 1545.58 1268.32 1543.48 Q1270.66 1541.37 1270.66 1537.76 Q1270.66 1534.15 1268.32 1532.04 Q1265.98 1529.94 1261.98 1529.94 Q1260.1 1529.94 1258.23 1530.35 Q1256.38 1530.77 1254.43 1531.65 L1254.43 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip420)\" d=\"M1576.1 1544.91 L1592.42 1544.91 L1592.42 1548.85 L1570.48 1548.85 L1570.48 1544.91 Q1573.14 1542.16 1577.72 1537.53 Q1582.33 1532.88 1583.51 1531.53 Q1585.76 1529.01 1586.64 1527.27 Q1587.54 1525.51 1587.54 1523.82 Q1587.54 1521.07 1585.59 1519.33 Q1583.67 1517.6 1580.57 1517.6 Q1578.37 1517.6 1575.92 1518.36 Q1573.49 1519.13 1570.71 1520.68 L1570.71 1515.95 Q1573.53 1514.82 1575.99 1514.24 Q1578.44 1513.66 1580.48 1513.66 Q1585.85 1513.66 1589.04 1516.35 Q1592.24 1519.03 1592.24 1523.52 Q1592.24 1525.65 1591.43 1527.57 Q1590.64 1529.47 1588.53 1532.07 Q1587.95 1532.74 1584.85 1535.95 Q1581.75 1539.15 1576.1 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip420)\" d=\"M1612.24 1517.37 Q1608.63 1517.37 1606.8 1520.93 Q1604.99 1524.47 1604.99 1531.6 Q1604.99 1538.71 1606.8 1542.27 Q1608.63 1545.82 1612.24 1545.82 Q1615.87 1545.82 1617.68 1542.27 Q1619.51 1538.71 1619.51 1531.6 Q1619.51 1524.47 1617.68 1520.93 Q1615.87 1517.37 1612.24 1517.37 M1612.24 1513.66 Q1618.05 1513.66 1621.1 1518.27 Q1624.18 1522.85 1624.18 1531.6 Q1624.18 1540.33 1621.1 1544.94 Q1618.05 1549.52 1612.24 1549.52 Q1606.43 1549.52 1603.35 1544.94 Q1600.29 1540.33 1600.29 1531.6 Q1600.29 1522.85 1603.35 1518.27 Q1606.43 1513.66 1612.24 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip420)\" d=\"M1924.08 1544.91 L1940.4 1544.91 L1940.4 1548.85 L1918.46 1548.85 L1918.46 1544.91 Q1921.12 1542.16 1925.7 1537.53 Q1930.31 1532.88 1931.49 1531.53 Q1933.74 1529.01 1934.62 1527.27 Q1935.52 1525.51 1935.52 1523.82 Q1935.52 1521.07 1933.57 1519.33 Q1931.65 1517.6 1928.55 1517.6 Q1926.35 1517.6 1923.9 1518.36 Q1921.47 1519.13 1918.69 1520.68 L1918.69 1515.95 Q1921.51 1514.82 1923.97 1514.24 Q1926.42 1513.66 1928.46 1513.66 Q1933.83 1513.66 1937.02 1516.35 Q1940.22 1519.03 1940.22 1523.52 Q1940.22 1525.65 1939.41 1527.57 Q1938.62 1529.47 1936.51 1532.07 Q1935.93 1532.74 1932.83 1535.95 Q1929.73 1539.15 1924.08 1544.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip420)\" d=\"M1950.26 1514.29 L1968.62 1514.29 L1968.62 1518.22 L1954.55 1518.22 L1954.55 1526.7 Q1955.56 1526.35 1956.58 1526.19 Q1957.6 1526 1958.62 1526 Q1964.41 1526 1967.79 1529.17 Q1971.17 1532.34 1971.17 1537.76 Q1971.17 1543.34 1967.69 1546.44 Q1964.22 1549.52 1957.9 1549.52 Q1955.73 1549.52 1953.46 1549.15 Q1951.21 1548.78 1948.8 1548.04 L1948.8 1543.34 Q1950.89 1544.47 1953.11 1545.03 Q1955.33 1545.58 1957.81 1545.58 Q1961.81 1545.58 1964.15 1543.48 Q1966.49 1541.37 1966.49 1537.76 Q1966.49 1534.15 1964.15 1532.04 Q1961.81 1529.94 1957.81 1529.94 Q1955.93 1529.94 1954.06 1530.35 Q1952.21 1530.77 1950.26 1531.65 L1950.26 1514.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip420)\" d=\"M2281.14 1530.21 Q2284.49 1530.93 2286.37 1533.2 Q2288.27 1535.47 2288.27 1538.8 Q2288.27 1543.92 2284.75 1546.72 Q2281.23 1549.52 2274.75 1549.52 Q2272.57 1549.52 2270.26 1549.08 Q2267.97 1548.66 2265.51 1547.81 L2265.51 1543.29 Q2267.46 1544.43 2269.77 1545.01 Q2272.09 1545.58 2274.61 1545.58 Q2279.01 1545.58 2281.3 1543.85 Q2283.61 1542.11 2283.61 1538.8 Q2283.61 1535.75 2281.46 1534.03 Q2279.33 1532.3 2275.51 1532.3 L2271.48 1532.3 L2271.48 1528.45 L2275.7 1528.45 Q2279.15 1528.45 2280.97 1527.09 Q2282.8 1525.7 2282.8 1523.11 Q2282.8 1520.45 2280.91 1519.03 Q2279.03 1517.6 2275.51 1517.6 Q2273.59 1517.6 2271.39 1518.01 Q2269.19 1518.43 2266.55 1519.31 L2266.55 1515.14 Q2269.22 1514.4 2271.53 1514.03 Q2273.87 1513.66 2275.93 1513.66 Q2281.25 1513.66 2284.35 1516.09 Q2287.46 1518.5 2287.46 1522.62 Q2287.46 1525.49 2285.81 1527.48 Q2284.17 1529.45 2281.14 1530.21 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip420)\" d=\"M2307.13 1517.37 Q2303.52 1517.37 2301.69 1520.93 Q2299.89 1524.47 2299.89 1531.6 Q2299.89 1538.71 2301.69 1542.27 Q2303.52 1545.82 2307.13 1545.82 Q2310.77 1545.82 2312.57 1542.27 Q2314.4 1538.71 2314.4 1531.6 Q2314.4 1524.47 2312.57 1520.93 Q2310.77 1517.37 2307.13 1517.37 M2307.13 1513.66 Q2312.94 1513.66 2316 1518.27 Q2319.08 1522.85 2319.08 1531.6 Q2319.08 1540.33 2316 1544.94 Q2312.94 1549.52 2307.13 1549.52 Q2301.32 1549.52 2298.24 1544.94 Q2295.19 1540.33 2295.19 1531.6 Q2295.19 1522.85 2298.24 1518.27 Q2301.32 1513.66 2307.13 1513.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip422)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  216.436,1186.04 2352.76,1186.04 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip422)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  216.436,863.939 2352.76,863.939 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip422)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  216.436,541.838 2352.76,541.838 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip422)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  216.436,219.736 2352.76,219.736 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip420)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  216.436,1486.45 216.436,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip420)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  216.436,1186.04 235.334,1186.04 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip420)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  216.436,863.939 235.334,863.939 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip420)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  216.436,541.838 235.334,541.838 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip420)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  216.436,219.736 235.334,219.736 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip420)\" d=\"M63.9319 1171.84 Q60.3208 1171.84 58.4921 1175.4 Q56.6865 1178.95 56.6865 1186.08 Q56.6865 1193.18 58.4921 1196.75 Q60.3208 1200.29 63.9319 1200.29 Q67.5661 1200.29 69.3717 1196.75 Q71.2004 1193.18 71.2004 1186.08 Q71.2004 1178.95 69.3717 1175.4 Q67.5661 1171.84 63.9319 1171.84 M63.9319 1168.14 Q69.742 1168.14 72.7976 1172.74 Q75.8763 1177.33 75.8763 1186.08 Q75.8763 1194.8 72.7976 1199.41 Q69.742 1203.99 63.9319 1203.99 Q58.1217 1203.99 55.043 1199.41 Q51.9875 1194.8 51.9875 1186.08 Q51.9875 1177.33 55.043 1172.74 Q58.1217 1168.14 63.9319 1168.14 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip420)\" d=\"M84.0938 1197.44 L88.978 1197.44 L88.978 1203.32 L84.0938 1203.32 L84.0938 1197.44 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip420)\" d=\"M99.2095 1168.76 L117.566 1168.76 L117.566 1172.7 L103.492 1172.7 L103.492 1181.17 Q104.51 1180.82 105.529 1180.66 Q106.547 1180.47 107.566 1180.47 Q113.353 1180.47 116.733 1183.64 Q120.112 1186.82 120.112 1192.23 Q120.112 1197.81 116.64 1200.91 Q113.168 1203.99 106.848 1203.99 Q104.672 1203.99 102.404 1203.62 Q100.159 1203.25 97.7511 1202.51 L97.7511 1197.81 Q99.8345 1198.95 102.057 1199.5 Q104.279 1200.06 106.756 1200.06 Q110.76 1200.06 113.098 1197.95 Q115.436 1195.84 115.436 1192.23 Q115.436 1188.62 113.098 1186.52 Q110.76 1184.41 106.756 1184.41 Q104.881 1184.41 103.006 1184.83 Q101.154 1185.24 99.2095 1186.12 L99.2095 1168.76 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip420)\" d=\"M128.144 1168.76 L150.367 1168.76 L150.367 1170.75 L137.82 1203.32 L132.936 1203.32 L144.742 1172.7 L128.144 1172.7 L128.144 1168.76 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip420)\" d=\"M159.533 1168.76 L177.89 1168.76 L177.89 1172.7 L163.816 1172.7 L163.816 1181.17 Q164.834 1180.82 165.853 1180.66 Q166.871 1180.47 167.89 1180.47 Q173.677 1180.47 177.056 1183.64 Q180.436 1186.82 180.436 1192.23 Q180.436 1197.81 176.964 1200.91 Q173.491 1203.99 167.172 1203.99 Q164.996 1203.99 162.728 1203.62 Q160.482 1203.25 158.075 1202.51 L158.075 1197.81 Q160.158 1198.95 162.38 1199.5 Q164.603 1200.06 167.079 1200.06 Q171.084 1200.06 173.422 1197.95 Q175.76 1195.84 175.76 1192.23 Q175.76 1188.62 173.422 1186.52 Q171.084 1184.41 167.079 1184.41 Q165.204 1184.41 163.329 1184.83 Q161.478 1185.24 159.533 1186.12 L159.533 1168.76 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip420)\" d=\"M62.9365 849.738 Q59.3254 849.738 57.4967 853.303 Q55.6912 856.844 55.6912 863.974 Q55.6912 871.08 57.4967 874.645 Q59.3254 878.187 62.9365 878.187 Q66.5707 878.187 68.3763 874.645 Q70.205 871.08 70.205 863.974 Q70.205 856.844 68.3763 853.303 Q66.5707 849.738 62.9365 849.738 M62.9365 846.034 Q68.7467 846.034 71.8022 850.641 Q74.8809 855.224 74.8809 863.974 Q74.8809 872.701 71.8022 877.307 Q68.7467 881.89 62.9365 881.89 Q57.1264 881.89 54.0477 877.307 Q50.9921 872.701 50.9921 863.974 Q50.9921 855.224 54.0477 850.641 Q57.1264 846.034 62.9365 846.034 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip420)\" d=\"M83.0984 875.339 L87.9827 875.339 L87.9827 881.219 L83.0984 881.219 L83.0984 875.339 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip420)\" d=\"M108.746 862.076 Q105.598 862.076 103.746 864.228 Q101.918 866.381 101.918 870.131 Q101.918 873.858 103.746 876.034 Q105.598 878.187 108.746 878.187 Q111.895 878.187 113.723 876.034 Q115.575 873.858 115.575 870.131 Q115.575 866.381 113.723 864.228 Q111.895 862.076 108.746 862.076 M118.029 847.423 L118.029 851.682 Q116.27 850.849 114.464 850.409 Q112.682 849.969 110.922 849.969 Q106.293 849.969 103.839 853.094 Q101.409 856.219 101.061 862.539 Q102.427 860.525 104.487 859.46 Q106.547 858.372 109.024 858.372 Q114.233 858.372 117.242 861.543 Q120.274 864.691 120.274 870.131 Q120.274 875.455 117.126 878.673 Q113.978 881.89 108.746 881.89 Q102.751 881.89 99.5798 877.307 Q96.4085 872.701 96.4085 863.974 Q96.4085 855.779 100.297 850.918 Q104.186 846.034 110.737 846.034 Q112.496 846.034 114.279 846.381 Q116.084 846.729 118.029 847.423 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip420)\" d=\"M138.33 849.738 Q134.719 849.738 132.89 853.303 Q131.084 856.844 131.084 863.974 Q131.084 871.08 132.89 874.645 Q134.719 878.187 138.33 878.187 Q141.964 878.187 143.769 874.645 Q145.598 871.08 145.598 863.974 Q145.598 856.844 143.769 853.303 Q141.964 849.738 138.33 849.738 M138.33 846.034 Q144.14 846.034 147.195 850.641 Q150.274 855.224 150.274 863.974 Q150.274 872.701 147.195 877.307 Q144.14 881.89 138.33 881.89 Q132.519 881.89 129.441 877.307 Q126.385 872.701 126.385 863.974 Q126.385 855.224 129.441 850.641 Q132.519 846.034 138.33 846.034 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip420)\" d=\"M168.491 849.738 Q164.88 849.738 163.052 853.303 Q161.246 856.844 161.246 863.974 Q161.246 871.08 163.052 874.645 Q164.88 878.187 168.491 878.187 Q172.126 878.187 173.931 874.645 Q175.76 871.08 175.76 863.974 Q175.76 856.844 173.931 853.303 Q172.126 849.738 168.491 849.738 M168.491 846.034 Q174.302 846.034 177.357 850.641 Q180.436 855.224 180.436 863.974 Q180.436 872.701 177.357 877.307 Q174.302 881.89 168.491 881.89 Q162.681 881.89 159.603 877.307 Q156.547 872.701 156.547 863.974 Q156.547 855.224 159.603 850.641 Q162.681 846.034 168.491 846.034 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip420)\" d=\"M63.9319 527.636 Q60.3208 527.636 58.4921 531.201 Q56.6865 534.743 56.6865 541.872 Q56.6865 548.979 58.4921 552.544 Q60.3208 556.085 63.9319 556.085 Q67.5661 556.085 69.3717 552.544 Q71.2004 548.979 71.2004 541.872 Q71.2004 534.743 69.3717 531.201 Q67.5661 527.636 63.9319 527.636 M63.9319 523.933 Q69.742 523.933 72.7976 528.539 Q75.8763 533.122 75.8763 541.872 Q75.8763 550.599 72.7976 555.206 Q69.742 559.789 63.9319 559.789 Q58.1217 559.789 55.043 555.206 Q51.9875 550.599 51.9875 541.872 Q51.9875 533.122 55.043 528.539 Q58.1217 523.933 63.9319 523.933 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip420)\" d=\"M84.0938 553.238 L88.978 553.238 L88.978 559.118 L84.0938 559.118 L84.0938 553.238 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip420)\" d=\"M109.742 539.974 Q106.594 539.974 104.742 542.127 Q102.913 544.28 102.913 548.03 Q102.913 551.757 104.742 553.932 Q106.594 556.085 109.742 556.085 Q112.89 556.085 114.719 553.932 Q116.57 551.757 116.57 548.03 Q116.57 544.28 114.719 542.127 Q112.89 539.974 109.742 539.974 M119.024 525.322 L119.024 529.581 Q117.265 528.747 115.459 528.308 Q113.677 527.868 111.918 527.868 Q107.288 527.868 104.834 530.993 Q102.404 534.118 102.057 540.437 Q103.422 538.423 105.483 537.358 Q107.543 536.271 110.02 536.271 Q115.228 536.271 118.237 539.442 Q121.27 542.59 121.27 548.03 Q121.27 553.354 118.121 556.571 Q114.973 559.789 109.742 559.789 Q103.746 559.789 100.575 555.206 Q97.4039 550.599 97.4039 541.872 Q97.4039 533.678 101.293 528.817 Q105.182 523.933 111.733 523.933 Q113.492 523.933 115.274 524.28 Q117.08 524.627 119.024 525.322 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip420)\" d=\"M133.353 555.182 L149.672 555.182 L149.672 559.118 L127.728 559.118 L127.728 555.182 Q130.39 552.428 134.973 547.798 Q139.58 543.145 140.76 541.803 Q143.006 539.28 143.885 537.544 Q144.788 535.784 144.788 534.095 Q144.788 531.34 142.843 529.604 Q140.922 527.868 137.82 527.868 Q135.621 527.868 133.168 528.632 Q130.737 529.396 127.959 530.946 L127.959 526.224 Q130.783 525.09 133.237 524.511 Q135.691 523.933 137.728 523.933 Q143.098 523.933 146.293 526.618 Q149.487 529.303 149.487 533.794 Q149.487 535.923 148.677 537.845 Q147.89 539.743 145.783 542.335 Q145.205 543.007 142.103 546.224 Q139.001 549.419 133.353 555.182 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip420)\" d=\"M159.533 524.558 L177.89 524.558 L177.89 528.493 L163.816 528.493 L163.816 536.965 Q164.834 536.618 165.853 536.456 Q166.871 536.271 167.89 536.271 Q173.677 536.271 177.056 539.442 Q180.436 542.613 180.436 548.03 Q180.436 553.608 176.964 556.71 Q173.491 559.789 167.172 559.789 Q164.996 559.789 162.728 559.419 Q160.482 559.048 158.075 558.307 L158.075 553.608 Q160.158 554.743 162.38 555.298 Q164.603 555.854 167.079 555.854 Q171.084 555.854 173.422 553.747 Q175.76 551.641 175.76 548.03 Q175.76 544.419 173.422 542.312 Q171.084 540.206 167.079 540.206 Q165.204 540.206 163.329 540.622 Q161.478 541.039 159.533 541.919 L159.533 524.558 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip420)\" d=\"M62.9365 205.535 Q59.3254 205.535 57.4967 209.1 Q55.6912 212.641 55.6912 219.771 Q55.6912 226.877 57.4967 230.442 Q59.3254 233.984 62.9365 233.984 Q66.5707 233.984 68.3763 230.442 Q70.205 226.877 70.205 219.771 Q70.205 212.641 68.3763 209.1 Q66.5707 205.535 62.9365 205.535 M62.9365 201.831 Q68.7467 201.831 71.8022 206.438 Q74.8809 211.021 74.8809 219.771 Q74.8809 228.498 71.8022 233.104 Q68.7467 237.687 62.9365 237.687 Q57.1264 237.687 54.0477 233.104 Q50.9921 228.498 50.9921 219.771 Q50.9921 211.021 54.0477 206.438 Q57.1264 201.831 62.9365 201.831 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip420)\" d=\"M83.0984 231.137 L87.9827 231.137 L87.9827 237.016 L83.0984 237.016 L83.0984 231.137 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip420)\" d=\"M108.746 217.873 Q105.598 217.873 103.746 220.026 Q101.918 222.178 101.918 225.928 Q101.918 229.655 103.746 231.831 Q105.598 233.984 108.746 233.984 Q111.895 233.984 113.723 231.831 Q115.575 229.655 115.575 225.928 Q115.575 222.178 113.723 220.026 Q111.895 217.873 108.746 217.873 M118.029 203.22 L118.029 207.479 Q116.27 206.646 114.464 206.206 Q112.682 205.766 110.922 205.766 Q106.293 205.766 103.839 208.891 Q101.409 212.016 101.061 218.336 Q102.427 216.322 104.487 215.257 Q106.547 214.169 109.024 214.169 Q114.233 214.169 117.242 217.34 Q120.274 220.488 120.274 225.928 Q120.274 231.252 117.126 234.47 Q113.978 237.687 108.746 237.687 Q102.751 237.687 99.5798 233.104 Q96.4085 228.498 96.4085 219.771 Q96.4085 211.576 100.297 206.715 Q104.186 201.831 110.737 201.831 Q112.496 201.831 114.279 202.178 Q116.084 202.526 118.029 203.22 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip420)\" d=\"M128.376 202.456 L146.732 202.456 L146.732 206.391 L132.658 206.391 L132.658 214.864 Q133.677 214.516 134.695 214.354 Q135.714 214.169 136.732 214.169 Q142.519 214.169 145.899 217.34 Q149.279 220.512 149.279 225.928 Q149.279 231.507 145.806 234.609 Q142.334 237.687 136.015 237.687 Q133.839 237.687 131.57 237.317 Q129.325 236.947 126.918 236.206 L126.918 231.507 Q129.001 232.641 131.223 233.197 Q133.445 233.752 135.922 233.752 Q139.927 233.752 142.265 231.646 Q144.603 229.539 144.603 225.928 Q144.603 222.317 142.265 220.211 Q139.927 218.104 135.922 218.104 Q134.047 218.104 132.172 218.521 Q130.32 218.938 128.376 219.817 L128.376 202.456 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip420)\" d=\"M168.491 205.535 Q164.88 205.535 163.052 209.1 Q161.246 212.641 161.246 219.771 Q161.246 226.877 163.052 230.442 Q164.88 233.984 168.491 233.984 Q172.126 233.984 173.931 230.442 Q175.76 226.877 175.76 219.771 Q175.76 212.641 173.931 209.1 Q172.126 205.535 168.491 205.535 M168.491 201.831 Q174.302 201.831 177.357 206.438 Q180.436 211.021 180.436 219.771 Q180.436 228.498 177.357 233.104 Q174.302 237.687 168.491 237.687 Q162.681 237.687 159.603 233.104 Q156.547 228.498 156.547 219.771 Q156.547 211.021 159.603 206.438 Q162.681 201.831 168.491 201.831 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip422)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  276.898,1445.72 346.394,996.351 415.891,1112.6 485.387,87.9763 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip422)\" style=\"stroke:#e26f46; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  276.898,87.9763 346.394,290.243 415.891,337.942 485.387,517.532 554.883,533.432 624.38,540.991 693.876,551.938 763.373,576.961 832.869,691.908 902.366,693.212 \n",
       "  971.862,712.761 1041.36,738.044 1110.85,744.56 1180.35,745.863 1249.85,810.245 1319.34,819.628 1388.84,832.4 1458.34,839.438 1527.83,876.972 1597.33,876.972 \n",
       "  1666.83,897.824 1736.32,924.41 1805.82,938.225 1875.32,961.423 1944.81,1001.3 2014.31,1081.84 2083.8,1087.84 2153.3,1125.11 2222.8,1138.41 2292.29,1161.08 \n",
       "  \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip420)\" d=\"\n",
       "M1858.75 250.738 L2281.55 250.738 L2281.55 95.2176 L1858.75 95.2176  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip420)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1858.75,250.738 2281.55,250.738 2281.55,95.2176 1858.75,95.2176 1858.75,250.738 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip420)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1882.75,147.058 2026.75,147.058 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip420)\" d=\"M2050.75 128.319 L2060.56 128.319 L2060.56 131.629 L2055 131.629 L2055 167.277 L2060.56 167.277 L2060.56 170.588 L2050.75 170.588 L2050.75 128.319 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip420)\" d=\"M2073.66 129.778 L2073.66 142.625 L2069.73 142.625 L2069.73 129.778 L2073.66 129.778 M2082.41 129.778 L2082.41 142.625 L2078.48 142.625 L2078.48 129.778 L2082.41 129.778 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip420)\" d=\"M2095.65 131.051 L2095.65 138.412 L2104.43 138.412 L2104.43 141.722 L2095.65 141.722 L2095.65 155.796 Q2095.65 158.967 2096.51 159.87 Q2097.39 160.773 2100.05 160.773 L2104.43 160.773 L2104.43 164.338 L2100.05 164.338 Q2095.12 164.338 2093.25 162.509 Q2091.37 160.657 2091.37 155.796 L2091.37 141.722 L2088.25 141.722 L2088.25 138.412 L2091.37 138.412 L2091.37 131.051 L2095.65 131.051 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip420)\" d=\"M2125.05 142.393 Q2124.33 141.977 2123.48 141.791 Q2122.64 141.583 2121.62 141.583 Q2118.01 141.583 2116.07 143.944 Q2114.15 146.282 2114.15 150.68 L2114.15 164.338 L2109.87 164.338 L2109.87 138.412 L2114.15 138.412 L2114.15 142.44 Q2115.49 140.078 2117.64 138.944 Q2119.8 137.787 2122.87 137.787 Q2123.31 137.787 2123.85 137.856 Q2124.38 137.903 2125.03 138.018 L2125.05 142.393 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip420)\" d=\"M2141.3 151.305 Q2136.14 151.305 2134.15 152.486 Q2132.16 153.666 2132.16 156.514 Q2132.16 158.782 2133.64 160.125 Q2135.14 161.444 2137.71 161.444 Q2141.25 161.444 2143.38 158.944 Q2145.54 156.421 2145.54 152.254 L2145.54 151.305 L2141.3 151.305 M2149.8 149.546 L2149.8 164.338 L2145.54 164.338 L2145.54 160.402 Q2144.08 162.763 2141.9 163.898 Q2139.73 165.009 2136.58 165.009 Q2132.6 165.009 2130.24 162.787 Q2127.9 160.541 2127.9 156.791 Q2127.9 152.416 2130.81 150.194 Q2133.75 147.972 2139.56 147.972 L2145.54 147.972 L2145.54 147.555 Q2145.54 144.615 2143.59 143.018 Q2141.67 141.398 2138.18 141.398 Q2135.95 141.398 2133.85 141.93 Q2131.74 142.463 2129.8 143.527 L2129.8 139.592 Q2132.13 138.69 2134.33 138.25 Q2136.53 137.787 2138.62 137.787 Q2144.24 137.787 2147.02 140.703 Q2149.8 143.62 2149.8 149.546 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip420)\" d=\"M2158.57 138.412 L2162.83 138.412 L2162.83 164.338 L2158.57 164.338 L2158.57 138.412 M2158.57 128.319 L2162.83 128.319 L2162.83 133.713 L2158.57 133.713 L2158.57 128.319 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip420)\" d=\"M2193.29 148.689 L2193.29 164.338 L2189.03 164.338 L2189.03 148.828 Q2189.03 145.148 2187.6 143.319 Q2186.16 141.49 2183.29 141.49 Q2179.84 141.49 2177.85 143.69 Q2175.86 145.889 2175.86 149.685 L2175.86 164.338 L2171.58 164.338 L2171.58 138.412 L2175.86 138.412 L2175.86 142.44 Q2177.39 140.102 2179.45 138.944 Q2181.53 137.787 2184.24 137.787 Q2188.71 137.787 2191 140.565 Q2193.29 143.319 2193.29 148.689 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip420)\" d=\"M2205.81 129.778 L2205.81 142.625 L2201.88 142.625 L2201.88 129.778 L2205.81 129.778 M2214.56 129.778 L2214.56 142.625 L2210.63 142.625 L2210.63 129.778 L2214.56 129.778 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip420)\" d=\"M2233.55 128.319 L2233.55 170.588 L2223.73 170.588 L2223.73 167.277 L2229.26 167.277 L2229.26 131.629 L2223.73 131.629 L2223.73 128.319 L2233.55 128.319 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip420)\" style=\"stroke:#e26f46; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1882.75,198.898 2026.75,198.898 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip420)\" d=\"M2050.75 180.159 L2060.56 180.159 L2060.56 183.469 L2055 183.469 L2055 219.117 L2060.56 219.117 L2060.56 222.428 L2050.75 222.428 L2050.75 180.159 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip420)\" d=\"M2073.66 181.618 L2073.66 194.465 L2069.73 194.465 L2069.73 181.618 L2073.66 181.618 M2082.41 181.618 L2082.41 194.465 L2078.48 194.465 L2078.48 181.618 L2082.41 181.618 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip420)\" d=\"M2095.65 182.891 L2095.65 190.252 L2104.43 190.252 L2104.43 193.562 L2095.65 193.562 L2095.65 207.636 Q2095.65 210.807 2096.51 211.71 Q2097.39 212.613 2100.05 212.613 L2104.43 212.613 L2104.43 216.178 L2100.05 216.178 Q2095.12 216.178 2093.25 214.349 Q2091.37 212.497 2091.37 207.636 L2091.37 193.562 L2088.25 193.562 L2088.25 190.252 L2091.37 190.252 L2091.37 182.891 L2095.65 182.891 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip420)\" d=\"M2132.2 202.15 L2132.2 204.233 L2112.62 204.233 Q2112.9 208.631 2115.26 210.946 Q2117.64 213.238 2121.88 213.238 Q2124.33 213.238 2126.62 212.636 Q2128.94 212.034 2131.21 210.83 L2131.21 214.858 Q2128.92 215.83 2126.51 216.34 Q2124.1 216.849 2121.62 216.849 Q2115.42 216.849 2111.79 213.238 Q2108.18 209.627 2108.18 203.469 Q2108.18 197.104 2111.6 193.377 Q2115.05 189.627 2120.88 189.627 Q2126.12 189.627 2129.15 193.006 Q2132.2 196.363 2132.2 202.15 M2127.94 200.9 Q2127.9 197.405 2125.98 195.321 Q2124.08 193.238 2120.93 193.238 Q2117.37 193.238 2115.21 195.252 Q2113.08 197.266 2112.76 200.923 L2127.94 200.9 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip420)\" d=\"M2155.72 191.016 L2155.72 195.043 Q2153.92 194.117 2151.97 193.655 Q2150.03 193.192 2147.94 193.192 Q2144.77 193.192 2143.18 194.164 Q2141.6 195.136 2141.6 197.08 Q2141.6 198.562 2142.74 199.418 Q2143.87 200.252 2147.3 201.016 L2148.75 201.34 Q2153.29 202.312 2155.19 204.094 Q2157.11 205.854 2157.11 209.025 Q2157.11 212.636 2154.24 214.742 Q2151.39 216.849 2146.39 216.849 Q2144.31 216.849 2142.04 216.432 Q2139.8 216.039 2137.3 215.228 L2137.3 210.83 Q2139.66 212.057 2141.95 212.682 Q2144.24 213.284 2146.49 213.284 Q2149.49 213.284 2151.12 212.266 Q2152.74 211.224 2152.74 209.349 Q2152.74 207.613 2151.55 206.687 Q2150.4 205.761 2146.44 204.904 L2144.96 204.557 Q2141 203.724 2139.24 202.011 Q2137.48 200.275 2137.48 197.266 Q2137.48 193.608 2140.07 191.618 Q2142.67 189.627 2147.43 189.627 Q2149.8 189.627 2151.88 189.974 Q2153.96 190.321 2155.72 191.016 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip420)\" d=\"M2168.11 182.891 L2168.11 190.252 L2176.88 190.252 L2176.88 193.562 L2168.11 193.562 L2168.11 207.636 Q2168.11 210.807 2168.96 211.71 Q2169.84 212.613 2172.5 212.613 L2176.88 212.613 L2176.88 216.178 L2172.5 216.178 Q2167.57 216.178 2165.7 214.349 Q2163.82 212.497 2163.82 207.636 L2163.82 193.562 L2160.7 193.562 L2160.7 190.252 L2163.82 190.252 L2163.82 182.891 L2168.11 182.891 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip420)\" d=\"M2186.51 181.618 L2186.51 194.465 L2182.57 194.465 L2182.57 181.618 L2186.51 181.618 M2195.26 181.618 L2195.26 194.465 L2191.32 194.465 L2191.32 181.618 L2195.26 181.618 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip420)\" d=\"M2214.24 180.159 L2214.24 222.428 L2204.43 222.428 L2204.43 219.117 L2209.96 219.117 L2209.96 183.469 L2204.43 183.469 L2204.43 180.159 L2214.24 180.159 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Plots.plot(train_acc_list,label=[\"train\"])\n",
    "Plots.plot!(test,label=[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "handy-steering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix of test data in best model:\n",
      "true_true_result->5422,  true_false_result->15148\n",
      "false_false_result->5422,   false_true_result->FT\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    In order to compute for confusion matrix\n",
    "\"\"\"\n",
    "#TT\n",
    "TT=sum(vec(model_list[1](X_test_std) .> 0.5) .== 1)\n",
    "#TF\n",
    "TF=sum(vec(model_list[1](X_test_std) .> 0.5) .== 0)\n",
    "#FT\n",
    "FT=sum(vec(model_list[1](X_test_std) .< 0.5) .== 1)\n",
    "#FF\n",
    "FF=sum(vec(model_list[1](X_test_std) .< 0.5) .== 0)\n",
    "println(\"confusion matrix of test data in best model:\")\n",
    "println(\"true_true_result->$TT,  true_false_result->$TF\")\n",
    "println(\"false_false_result->$FF,   false_true_result->FT\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.1",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
