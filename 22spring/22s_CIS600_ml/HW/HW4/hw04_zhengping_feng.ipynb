{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baf1bf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the packet\n",
    "using Plots\n",
    "using ProgressBars\n",
    "using Flux\n",
    "using Flux: onehot\n",
    "using Flux: Data.DataLoader\n",
    "using Flux: onehotbatch, onecold, crossentropy\n",
    "using Flux: @epochs\n",
    "using Statistics\n",
    "using MLDatasets\n",
    "using CSV\n",
    "using DataFrames\n",
    "using Random:shuffle\n",
    "using EvalMetrics\n",
    "using Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f489fda0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#parameters:\n",
    "Batch_size = 12\n",
    "#there will be 100 models\n",
    "Pop_size = 100 \n",
    "#iteration times\n",
    "iteration = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a03291a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>1,599 rows × 12 columns (omitted printing of 6 columns)</p><table class=\"data-frame\"><thead><tr><th></th><th>fixedacidity</th><th>volatileacidity</th><th>citricacid</th><th>residualsugar</th><th>chlorides</th><th>freesulfurdioxide</th></tr><tr><th></th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th></tr></thead><tbody><tr><th>1</th><td>7.0</td><td>0.27</td><td>0.36</td><td>20.7</td><td>0.045</td><td>45.0</td></tr><tr><th>2</th><td>6.3</td><td>0.3</td><td>0.34</td><td>1.6</td><td>0.049</td><td>14.0</td></tr><tr><th>3</th><td>8.1</td><td>0.28</td><td>0.4</td><td>6.9</td><td>0.05</td><td>30.0</td></tr><tr><th>4</th><td>7.2</td><td>0.23</td><td>0.32</td><td>8.5</td><td>0.058</td><td>47.0</td></tr><tr><th>5</th><td>7.2</td><td>0.23</td><td>0.32</td><td>8.5</td><td>0.058</td><td>47.0</td></tr><tr><th>6</th><td>8.1</td><td>0.28</td><td>0.4</td><td>6.9</td><td>0.05</td><td>30.0</td></tr><tr><th>7</th><td>6.2</td><td>0.32</td><td>0.16</td><td>7.0</td><td>0.045</td><td>30.0</td></tr><tr><th>8</th><td>7.0</td><td>0.27</td><td>0.36</td><td>20.7</td><td>0.045</td><td>45.0</td></tr><tr><th>9</th><td>6.3</td><td>0.3</td><td>0.34</td><td>1.6</td><td>0.049</td><td>14.0</td></tr><tr><th>10</th><td>8.1</td><td>0.22</td><td>0.43</td><td>1.5</td><td>0.044</td><td>28.0</td></tr><tr><th>11</th><td>8.1</td><td>0.27</td><td>0.41</td><td>1.45</td><td>0.033</td><td>11.0</td></tr><tr><th>12</th><td>8.6</td><td>0.23</td><td>0.4</td><td>4.2</td><td>0.035</td><td>17.0</td></tr><tr><th>13</th><td>7.9</td><td>0.18</td><td>0.37</td><td>1.2</td><td>0.04</td><td>16.0</td></tr><tr><th>14</th><td>6.6</td><td>0.16</td><td>0.4</td><td>1.5</td><td>0.044</td><td>48.0</td></tr><tr><th>15</th><td>8.3</td><td>0.42</td><td>0.62</td><td>19.25</td><td>0.04</td><td>41.0</td></tr><tr><th>16</th><td>6.6</td><td>0.17</td><td>0.38</td><td>1.5</td><td>0.032</td><td>28.0</td></tr><tr><th>17</th><td>6.3</td><td>0.48</td><td>0.04</td><td>1.1</td><td>0.046</td><td>30.0</td></tr><tr><th>18</th><td>6.2</td><td>0.66</td><td>0.48</td><td>1.2</td><td>0.029</td><td>29.0</td></tr><tr><th>19</th><td>7.4</td><td>0.34</td><td>0.42</td><td>1.1</td><td>0.033</td><td>17.0</td></tr><tr><th>20</th><td>6.5</td><td>0.31</td><td>0.14</td><td>7.5</td><td>0.044</td><td>34.0</td></tr><tr><th>21</th><td>6.2</td><td>0.66</td><td>0.48</td><td>1.2</td><td>0.029</td><td>29.0</td></tr><tr><th>22</th><td>6.4</td><td>0.31</td><td>0.38</td><td>2.9</td><td>0.038</td><td>19.0</td></tr><tr><th>23</th><td>6.8</td><td>0.26</td><td>0.42</td><td>1.7</td><td>0.049</td><td>41.0</td></tr><tr><th>24</th><td>7.6</td><td>0.67</td><td>0.14</td><td>1.5</td><td>0.074</td><td>25.0</td></tr><tr><th>25</th><td>6.6</td><td>0.27</td><td>0.41</td><td>1.3</td><td>0.052</td><td>16.0</td></tr><tr><th>26</th><td>7.0</td><td>0.25</td><td>0.32</td><td>9.0</td><td>0.046</td><td>56.0</td></tr><tr><th>27</th><td>6.9</td><td>0.24</td><td>0.35</td><td>1.0</td><td>0.052</td><td>35.0</td></tr><tr><th>28</th><td>7.0</td><td>0.28</td><td>0.39</td><td>8.7</td><td>0.051</td><td>32.0</td></tr><tr><th>29</th><td>7.4</td><td>0.27</td><td>0.48</td><td>1.1</td><td>0.047</td><td>17.0</td></tr><tr><th>30</th><td>7.2</td><td>0.32</td><td>0.36</td><td>2.0</td><td>0.033</td><td>37.0</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& fixedacidity & volatileacidity & citricacid & residualsugar & chlorides & freesulfurdioxide & \\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 7.0 & 0.27 & 0.36 & 20.7 & 0.045 & 45.0 & $\\dots$ \\\\\n",
       "\t2 & 6.3 & 0.3 & 0.34 & 1.6 & 0.049 & 14.0 & $\\dots$ \\\\\n",
       "\t3 & 8.1 & 0.28 & 0.4 & 6.9 & 0.05 & 30.0 & $\\dots$ \\\\\n",
       "\t4 & 7.2 & 0.23 & 0.32 & 8.5 & 0.058 & 47.0 & $\\dots$ \\\\\n",
       "\t5 & 7.2 & 0.23 & 0.32 & 8.5 & 0.058 & 47.0 & $\\dots$ \\\\\n",
       "\t6 & 8.1 & 0.28 & 0.4 & 6.9 & 0.05 & 30.0 & $\\dots$ \\\\\n",
       "\t7 & 6.2 & 0.32 & 0.16 & 7.0 & 0.045 & 30.0 & $\\dots$ \\\\\n",
       "\t8 & 7.0 & 0.27 & 0.36 & 20.7 & 0.045 & 45.0 & $\\dots$ \\\\\n",
       "\t9 & 6.3 & 0.3 & 0.34 & 1.6 & 0.049 & 14.0 & $\\dots$ \\\\\n",
       "\t10 & 8.1 & 0.22 & 0.43 & 1.5 & 0.044 & 28.0 & $\\dots$ \\\\\n",
       "\t11 & 8.1 & 0.27 & 0.41 & 1.45 & 0.033 & 11.0 & $\\dots$ \\\\\n",
       "\t12 & 8.6 & 0.23 & 0.4 & 4.2 & 0.035 & 17.0 & $\\dots$ \\\\\n",
       "\t13 & 7.9 & 0.18 & 0.37 & 1.2 & 0.04 & 16.0 & $\\dots$ \\\\\n",
       "\t14 & 6.6 & 0.16 & 0.4 & 1.5 & 0.044 & 48.0 & $\\dots$ \\\\\n",
       "\t15 & 8.3 & 0.42 & 0.62 & 19.25 & 0.04 & 41.0 & $\\dots$ \\\\\n",
       "\t16 & 6.6 & 0.17 & 0.38 & 1.5 & 0.032 & 28.0 & $\\dots$ \\\\\n",
       "\t17 & 6.3 & 0.48 & 0.04 & 1.1 & 0.046 & 30.0 & $\\dots$ \\\\\n",
       "\t18 & 6.2 & 0.66 & 0.48 & 1.2 & 0.029 & 29.0 & $\\dots$ \\\\\n",
       "\t19 & 7.4 & 0.34 & 0.42 & 1.1 & 0.033 & 17.0 & $\\dots$ \\\\\n",
       "\t20 & 6.5 & 0.31 & 0.14 & 7.5 & 0.044 & 34.0 & $\\dots$ \\\\\n",
       "\t21 & 6.2 & 0.66 & 0.48 & 1.2 & 0.029 & 29.0 & $\\dots$ \\\\\n",
       "\t22 & 6.4 & 0.31 & 0.38 & 2.9 & 0.038 & 19.0 & $\\dots$ \\\\\n",
       "\t23 & 6.8 & 0.26 & 0.42 & 1.7 & 0.049 & 41.0 & $\\dots$ \\\\\n",
       "\t24 & 7.6 & 0.67 & 0.14 & 1.5 & 0.074 & 25.0 & $\\dots$ \\\\\n",
       "\t25 & 6.6 & 0.27 & 0.41 & 1.3 & 0.052 & 16.0 & $\\dots$ \\\\\n",
       "\t26 & 7.0 & 0.25 & 0.32 & 9.0 & 0.046 & 56.0 & $\\dots$ \\\\\n",
       "\t27 & 6.9 & 0.24 & 0.35 & 1.0 & 0.052 & 35.0 & $\\dots$ \\\\\n",
       "\t28 & 7.0 & 0.28 & 0.39 & 8.7 & 0.051 & 32.0 & $\\dots$ \\\\\n",
       "\t29 & 7.4 & 0.27 & 0.48 & 1.1 & 0.047 & 17.0 & $\\dots$ \\\\\n",
       "\t30 & 7.2 & 0.32 & 0.36 & 2.0 & 0.033 & 37.0 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m1599×12 DataFrame\u001b[0m\n",
       "\u001b[1m  Row \u001b[0m│\u001b[1m fixedacidity \u001b[0m\u001b[1m volatileacidity \u001b[0m\u001b[1m citricacid \u001b[0m\u001b[1m residualsugar \u001b[0m\u001b[1m chlorides \u001b[0m\u001b[1m f\u001b[0m ⋯\n",
       "\u001b[1m      \u001b[0m│\u001b[90m Float64      \u001b[0m\u001b[90m Float64         \u001b[0m\u001b[90m Float64    \u001b[0m\u001b[90m Float64       \u001b[0m\u001b[90m Float64   \u001b[0m\u001b[90m F\u001b[0m ⋯\n",
       "──────┼─────────────────────────────────────────────────────────────────────────\n",
       "    1 │          7.0             0.27        0.36          20.7       0.045    ⋯\n",
       "    2 │          6.3             0.3         0.34           1.6       0.049\n",
       "    3 │          8.1             0.28        0.4            6.9       0.05\n",
       "    4 │          7.2             0.23        0.32           8.5       0.058\n",
       "    5 │          7.2             0.23        0.32           8.5       0.058    ⋯\n",
       "    6 │          8.1             0.28        0.4            6.9       0.05\n",
       "    7 │          6.2             0.32        0.16           7.0       0.045\n",
       "    8 │          7.0             0.27        0.36          20.7       0.045\n",
       "    9 │          6.3             0.3         0.34           1.6       0.049    ⋯\n",
       "   10 │          8.1             0.22        0.43           1.5       0.044\n",
       "   11 │          8.1             0.27        0.41           1.45      0.033\n",
       "  ⋮   │      ⋮               ⋮             ⋮             ⋮            ⋮        ⋱\n",
       " 1590 │          7.0             0.27        0.74           1.5       0.036\n",
       " 1591 │          7.9             0.14        0.74           1.2       0.028    ⋯\n",
       " 1592 │          6.4             0.12        0.49           6.4       0.042\n",
       " 1593 │          6.8             0.21        0.74           1.2       0.047\n",
       " 1594 │          8.6             0.16        0.49           7.3       0.043\n",
       " 1595 │          7.0             0.29        0.49           3.8       0.047    ⋯\n",
       " 1596 │          6.4             0.27        0.49           7.3       0.046\n",
       " 1597 │          6.6             0.55        0.01           2.7       0.034\n",
       " 1598 │          6.4             0.27        0.49           7.3       0.046\n",
       " 1599 │          6.3             0.24        0.74           1.4       0.172    ⋯\n",
       "\u001b[36m                                                 7 columns and 1578 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import the dataset\n",
    "#do 2-class classification:\n",
    "#decide the wine is red or white\n",
    "df_red = CSV.read(\"winequality-red.csv\",DataFrame)\n",
    "df_white = CSV.read(\"winequality-white.csv\",DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "434d1c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sigmoidmodel (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#build the model using sigmoid as Activation Function\n",
    "#The input dim is 12 as 12 features and the output dim is 2 represent A and B\n",
    "function sigmoidmodel(input_dim)\n",
    "    model = Chain(\n",
    "        Dense(input_dim,16,relu),\n",
    "        Dense(16,64,relu),\n",
    "        Dense(64,32,relu),\n",
    "        Dense(32,2),\n",
    "        softmax\n",
    "    )\n",
    "    return model\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "617ecc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read In the data from the dataframe\n",
    "csv_mat = [[r.fixedacidity,r.volatileacidity,r.citricacid,r.residualsugar,r.chlorides,r.freesulfurdioxide\n",
    "        ,r.totalsulfurdioxide,r.density,r.pH,r.sulphates,r.alcohol,r.quality] for r in eachrow(df_red)]\n",
    "x_redwines = rand(size(csv_mat)[1],12)\n",
    "for i in 1:size(csv_mat)[1]\n",
    "    x_redwines[i,1]=csv_mat[i][1]\n",
    "    x_redwines[i,2]=csv_mat[i][2]\n",
    "end\n",
    "\n",
    "csv_mat = [[r.fixedacidity,r.volatileacidity,r.citricacid,r.residualsugar,r.chlorides,r.freesulfurdioxide\n",
    "        ,r.totalsulfurdioxide,r.density,r.pH,r.sulphates,r.alcohol,r.quality] for r in eachrow(df_white)]\n",
    "x_whitewines = rand(size(csv_mat)[1],12)\n",
    "for i in 1:size(csv_mat)[1]\n",
    "    x_whitewines[i,1]=csv_mat[i][1]\n",
    "    x_whitewines[i,2]=csv_mat[i][2]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a4c9249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×3198 Matrix{Int64}:\n",
       " 1  1  1  1  1  1  1  1  1  1  1  1  1  …  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0     1  1  1  1  1  1  1  1  1  1  1  1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the matrix\n",
    "xs = [x_redwines;x_whitewines]\n",
    "xs = transpose(xs)\n",
    "ys = [fill(0,size(x_redwines)[1]);fill(1,size(x_whitewines)[1])]\n",
    "#trun label into 0:1 onthot-bat\n",
    "ys = Flux.onehotbatch(ys,0:1)\n",
    "ys = Int.(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bce2966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataLoader{Tuple{Matrix{Float64}, Matrix{Int64}}, Random._GLOBAL_RNG}(([6.4 6.8 … 6.8 8.6; 0.595 0.25 … 0.19 0.2; … ; 0.4687831178013747 0.8140574985267094 … 0.335552603556837 0.03321845872278617; 0.8231076583230601 0.9469178335927186 … 0.7160569794491978 0.8490811024457356], [0 0 … 0 0; 1 1 … 1 1]), 20, 2199, true, 2199, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10  …  2190, 2191, 2192, 2193, 2194, 2195, 2196, 2197, 2198, 2199], true, Random._GLOBAL_RNG())"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shuffle the data randomly\n",
    "datalength = size(xs)[2]\n",
    "index = shuffle(collect(1:datalength))\n",
    "\n",
    "xs = xs[:,index]\n",
    "ys = ys[:,index]\n",
    "\n",
    "#split the train data and test data\n",
    "train_data = Flux.DataLoader((xs[:,1:1000],ys[:,1:1000]),batchsize=20,shuffle=true)\n",
    "test_data = Flux.DataLoader((xs[:,1000:end],ys[:,1000:end]),batchsize=20,shuffle=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9654beca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "acc (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accurate Function\n",
    "function acc(x,y)\n",
    "    x = transpose(x)\n",
    "    y = transpose(y)\n",
    "    p=[i[2] for i in argmax(x,dims=2)]\n",
    "    l=[i[2] for i in argmax(y,dims=2)]\n",
    "    p = reshape(p,size(p)[1])\n",
    "    l = reshape(l,size(l)[1])\n",
    "    correct=sum(p.==1)\n",
    "    len=size(x)[1]\n",
    "    acc=correct/len\n",
    "    return acc\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ed6eb3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generatePop (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generate population\n",
    "function generatePop(size)\n",
    "    population = []\n",
    "    for i in 1:size\n",
    "        smodel = sigmoidmodel(Batch_size)\n",
    "        append!(population,[smodel])\n",
    "    end\n",
    "    return population\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdf1f678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_model (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train models and get the accuracy list\n",
    "function train_model(model)\n",
    "    model_acc_list = []\n",
    "    for (x,y) in train_data\n",
    "        pred = model(x)\n",
    "        ac = acc(pred,y)\n",
    "        append!(model_acc_list,ac)\n",
    "    end\n",
    "    meanac = mean(model_acc_list)\n",
    "    return meanac\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34910426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test_model (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train models and get the accuracy list\n",
    "function test_model(model)\n",
    "    model_acc_list = []\n",
    "    for (x,y) in test_data\n",
    "        pred = model(x)\n",
    "        ac = acc(pred,y)\n",
    "        append!(model_acc_list,ac)\n",
    "    end\n",
    "    meanac = mean(model_acc_list)\n",
    "    return meanac\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfcabc3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "parameter_absract (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#parameters do add\n",
    "function parameter_absract(a,b)\n",
    "    result=Flux.params([i-j for (i,j) in zip(a,b)])\n",
    "    return result\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcb1e2cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "parameter_add (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#parameters do substract\n",
    "function parameter_add(a,b)\n",
    "    result=Flux.params([i+j for (i,j) in zip(a,b)])\n",
    "    return result\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "122e9aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#do iteration here\n",
    "model_train_mean_acc = []\n",
    "model_test_mean_acc = []\n",
    "model_list = generatePop(Pop_size)\n",
    "\n",
    "gbestTrainList = zeros(Pop_size)\n",
    "gbestTestList = zeros(Pop_size)\n",
    "\n",
    "gbestTrainparas = []\n",
    "gbestTestParas = []\n",
    "\n",
    "for i in 1:Pop_size\n",
    "    append!(gbestTrainparas,[Flux.params(model_list[i])])\n",
    "    append!(gbestTestParas,[Flux.params(model_list[i])])\n",
    "end\n",
    "\n",
    "#get the copy of parameters\n",
    "velocit_train=deepcopy(gbestTrainparas)\n",
    "velocit_test=deepcopy(gbestTestParas)\n",
    "\n",
    "for i in 1:iteration\n",
    "    model_train_acc = []\n",
    "    model_test_acc = []\n",
    "    \n",
    "    pbestTrainList = []\n",
    "    pbestTestList = []\n",
    "    \n",
    "    #train models with gbest and pbest\n",
    "    for j in 1:Pop_size\n",
    "        trainac = train_model(model_list[j])\n",
    "        testac = test_model(model_list[j])\n",
    "        if gbestTrainList[j] < trainac\n",
    "            gbestTrainList[j] = trainac\n",
    "            gbestTrainparas[j] = Flux.params(model_list[j])\n",
    "        end\n",
    "        \n",
    "        if gbestTestList[j] < testac\n",
    "            gbestTestList[j] = testac\n",
    "            gbestTestParas[j] = Flux.params(model_list[j])\n",
    "        end\n",
    "        #get max\n",
    "        append!(model_train_acc,trainac)\n",
    "        append!(model_test_acc,testac)\n",
    "        append!(pbestTrainList,trainac)\n",
    "        append!(pbestTestList,testac)\n",
    "    end\n",
    "    append!(model_train_mean_acc,mean(model_train_acc))\n",
    "    append!(model_test_mean_acc,mean(model_test_acc))\n",
    "    \n",
    "    #get max pbest and gbest\n",
    "    pTrainBest = 0\n",
    "    pTestBest = 0\n",
    "    pTrainBestparas = Flux.params(model_list[1])\n",
    "    pTestBestparas = Flux.params(model_list[1])\n",
    "    \n",
    "    for k in 1:Pop_size\n",
    "        if pbestTrainList[k] > pTrainBest\n",
    "            pTrainBest = pbestTrainList[k]\n",
    "            pTrainBestparas = Flux.params(model_list[k])\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    for k in 1:Pop_size\n",
    "        if pbestTestList[k] > pTestBest\n",
    "            pTestBest = pbestTestList[k]\n",
    "            pTestBestparas = Flux.params(model_list[k])\n",
    "        end\n",
    "    end\n",
    "    #do PSO and update the parameters\n",
    "    for (id,m) in enumerate(model_list)\n",
    "        #train\n",
    "        trainlocalup=parameter_absract(gbestTrainparas[id],Flux.params(m))\n",
    "        trainglobalup=parameter_absract(pTrainBestparas,Flux.params(m))\n",
    "        trainvup=parameter_add(trainlocalup,trainglobalup)\n",
    "        velocit_train[id]=parameter_add(velocit_train[id],trainvup)\n",
    "        velocit_train[id]=parameter_add(Flux.params(m),velocit_train[id])\n",
    "        \n",
    "        #test\n",
    "        testlocalup=parameter_absract(gbestTestParas[id],Flux.params(m))\n",
    "        testglobalup=parameter_absract(pTestBestparas,Flux.params(m))\n",
    "        testvup=parameter_add(testlocalup,testglobalup)\n",
    "        velocit_test[id]=parameter_add(velocit_test[id],testvup)\n",
    "        velocit_test[id]=parameter_add(Flux.params(m),velocit_test[id])\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f38f8a7f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any[0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001, 0.5513600000000001]Any[0.5508894736842107, 0.5508892344497608, 0.5508918660287082, 0.5508911483253589, 0.550892105263158, 0.5508923444976078, 0.5508916267942583, 0.5508916267942585, 0.5508913875598087, 0.5508916267942585, 0.5508906698564594, 0.5508901913875599, 0.5508944976076555, 0.5508885167464116, 0.5508923444976078, 0.5508928229665073, 0.5508913875598086, 0.5508904306220096, 0.5508909090909091, 0.5508904306220097, 0.5508885167464114, 0.5508913875598087, 0.55088995215311, 0.5508928229665072, 0.5508894736842106, 0.5508930622009569, 0.5508928229665072, 0.5508906698564595, 0.5508933014354068, 0.5508909090909092, 0.5508894736842105, 0.5508935406698565, 0.5508889952153111, 0.5508904306220095, 0.5508940191387561, 0.5508913875598087, 0.5508885167464117, 0.5508935406698566, 0.5508901913875599, 0.5508877990430623, 0.5508897129186603, 0.5508933014354068, 0.5508911483253588, 0.5508942583732057, 0.5508899521531101, 0.5508933014354068, 0.5508911483253588, 0.550888995215311, 0.5508901913875599, 0.5508897129186604, 0.5508901913875599, 0.5508918660287082, 0.5508925837320576, 0.550891866028708, 0.5508901913875599, 0.5508918660287081, 0.5508897129186604, 0.5508913875598086, 0.5508894736842106, 0.5508909090909091, 0.5508911483253588, 0.5508906698564594, 0.5508923444976077, 0.550887081339713, 0.5508925837320575, 0.5508918660287083, 0.5508909090909091, 0.5508928229665071, 0.5508882775119618, 0.5508918660287083, 0.550893062200957, 0.5508906698564594, 0.5508925837320575, 0.5508906698564593, 0.5508909090909092, 0.5508909090909091, 0.5508916267942583, 0.5508911483253589, 0.5508899521531102, 0.550892105263158, 0.550893062200957, 0.550894019138756, 0.5508921052631579, 0.5508923444976077, 0.5508913875598087, 0.5508928229665072, 0.5508909090909091, 0.5508904306220097, 0.5508923444976077, 0.5508952153110048, 0.5508923444976076, 0.5508887559808613, 0.5508918660287082, 0.5508921052631579, 0.5508901913875597, 0.5508901913875599, 0.5508911483253589, 0.5508933014354068, 0.5508906698564594, 0.5508904306220096]"
     ]
    }
   ],
   "source": [
    "#draw graph\n",
    "model_train_mean_acc = round.(model_train_mean_acc,digits=3)\n",
    "model_test_mean_acc = round.(model_test_mean_acc,digits=3)\n",
    "#print(model_train_mean_acc)\n",
    "#print(model_test_mean_acc)\n",
    "x = 1:iteration\n",
    "x = [log(i) for i in x]\n",
    "y = hcat(model_train_mean_acc,model_test_mean_acc)\n",
    "plot(x,y,title=\"accuracy\",label=[\"Traning\" \"Testing\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16574ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "#confusion matrix\n",
    "#set the matrix\n",
    "confusion = zeros(2,2)\n",
    "for (x,y) in test_data\n",
    "    pred = model_list[1](x)\n",
    "    pred = transpose(pred)\n",
    "    label= transpose(y)\n",
    "    \n",
    "    p = [i[2] for i in argmax(pred,dims=2)]\n",
    "    l = [i[2] for i in argmax(label,dims=2)]\n",
    "    \n",
    "    for (i,j) in zip(l,p)\n",
    "        confusion[i,j]+=1\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96b8b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output the confusion matrix\n",
    "print(confusion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.1",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
